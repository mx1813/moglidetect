text;label
 Kapitel 4: Implementierung der Optimierung der Visualisierung, Bedienung und Selbstregelung eines um Elektronik erweiterten Luftreinigungsgerätes   4.1 Einleitung  In den letzten Jahren hat das Bewusstsein für die Bedeutung der Luftqualität in Innenräumen zugenommen, was zu einer steigenden Nachfrage nach effektiven Luftreinigungsgeräten geführt hat. Die vorliegende Arbeit beschäftigt sich mit der Optimierung eines elektronisch erweiterten Luftreinigungsgerätes, wobei der Fokus auf der Verbesserung der Visualisierung, der Benutzerfreundlichkeit und der Selbstregelung liegt. Dieses Kapitel beschreibt die Implementierung der entwickelten Lösungen und deren Auswirkungen auf die Benutzererfahrung sowie die Effizienz des Gerätes.   4.2 Zielsetzung der Implementierung  Die Hauptziele der Implementierung waren:  1. Visualisierung der Luftqualitätsdaten: Die Integration eines benutzerfreundlichen Displays, das Echtzeitdaten zur Luftqualität anzeigt, sollte den Nutzern helfen, informierte Entscheidungen über die Nutzung des Gerätes zu treffen.  2. Verbesserung der Bedienbarkeit: Die Entwicklung einer intuitiven Benutzeroberfläche, die eine einfache und schnelle Steuerung der Funktionen des Luftreinigers ermöglicht, sollte die Interaktion mit dem Gerät erleichtern.  3. Selbstregelung des Gerätes: Die Implementierung eines intelligenten Regelungssystems, das auf Echtzeitdaten basiert, sollte die Effizienz des Luftreinigers erhöhen und den Energieverbrauch optimieren.   4.3 Visualisierung der Luftqualitätsdaten  Die Implementierung der Visualisierung begann mit der Auswahl eines geeigneten Displays. Ein hochauflösendes LCD-Display wurde gewählt, um eine klare und ansprechende Darstellung der Luftqualitätsdaten zu gewährleisten. Die Visualisierung umfasst folgende Elemente:  - Echtzeitdaten: Die aktuellen Werte für PM2.5, PM10, VOCs (flüchtige organische Verbindungen) und CO2 werden in Form von Diagrammen und Zahlen angezeigt. - Farbcodierung: Um die Benutzerfreundlichkeit zu erhöhen, wurde ein Farbschema implementiert, das die Luftqualität in Kategorien einteilt (z.B. grün für gut, gelb für moderat, rot für schlecht). - Historische Daten: Nutzer können auf eine Historie der Luftqualitätsdaten zugreifen, um Trends über die Zeit zu erkennen.  Die Implementierung dieser Funktionen wurde durch die Verwendung von Microcontroller-Technologie und geeigneten Sensoren realisiert, die eine präzise Messung der Luftqualität ermöglichten.   4.4 Verbesserung der Bedienbarkeit  Um die Bedienbarkeit des Luftreinigers zu optimieren, wurde eine benutzerfreundliche Schnittstelle entwickelt. Diese umfasst:  - Touchscreen-Bedienung: Ein kapazitiver Touchscreen ermöglicht eine einfache Navigation durch die Menüs und Einstellungen des Gerätes. Die Benutzeroberfläche wurde so gestaltet, dass sie intuitiv und selbsterklärend ist. - Voreinstellungen: Nutzer können verschiedene Betriebsmodi (z.B. Automatik, Turbo, Nachtmodus) auswählen, die auf ihre spezifischen Bedürfnisse zugeschnitten sind. - Sprachsteuerung: Eine zusätzliche Funktion zur Sprachsteuerung wurde integriert, um;1
      Die Entwicklung von Software ist ein komplexer Prozess, der eine sorgfältige Planung und Organisation erfordert. Besonders im studentischen Kontext, wo oft begrenzte Ressourcen und Zeit zur Verfügung stehen, ist ein effektives Aufgabenmanagement von entscheidender Bedeutung. Diese Arbeit widmet sich der Anforderungsanalyse für ein maßgeschneidertes Aufgabenmanagement-Tool, das speziell auf die Bedürfnisse von Studierenden im Bereich Software Engineering ausgerichtet ist. Ziel ist es, die Herausforderungen, die im Rahmen studentischer Projekte auftreten, zu identifizieren und eine Lösung zu entwickeln, die die Effizienz und Produktivität der Studierenden steigert.   Kontext und Relevanz  Im Rahmen des Software Engineerings stehen Studierende häufig vor der Herausforderung, verschiedene Aufgaben zu koordinieren, Fristen einzuhalten und die Zusammenarbeit im Team zu optimieren. Traditionelle Aufgabenmanagement-Tools bieten zwar einige Funktionen, sind jedoch oft nicht auf die spezifischen Bedürfnisse von Studierenden zugeschnitten. Eine maßgeschneiderte Lösung könnte beispielsweise Funktionen zur Unterstützung agiler Methoden, zur Visualisierung von Arbeitsabläufen und zur Integration von Lernressourcen beinhalten.   Methodik der Anforderungsanalyse  Die Anforderungsanalyse erfolgt in mehreren Phasen 1. BedarfsanalyseHierbei werden die spezifischen Anforderungen der Zielgruppe ermittelt. Um ein tiefes Verständnis für die Bedürfnisse der Studierenden zu gewinnen, werden Interviews und Umfragen durchgeführt. Die Ergebnisse zeigen, dass die Studierenden Wert auf eine intuitive Benutzeroberfläche, mobile Zugänglichkeit und die Möglichkeit zur Zusammenarbeit legen.  2. FunktionsspezifikationBasierend auf den Ergebnissen der Bedarfsanalyse werden die Kernfunktionen des Tools definiert. Dazu gehören   - AufgabenverwaltungErstellung, Zuweisung und Nachverfolgung von Aufgaben.    - TeamkommunikationIntegration von Kommunikationskanälen, um den Austausch zwischen Teammitgliedern zu fördern.    - FortschrittsverfolgungVisualisierung des Projektfortschritts durch Kanban-Boards oder Gantt-Diagramme.    - RessourcenmanagementBereitstellung von Links zu Lernmaterialien und Dokumentationen, die den Studierenden helfen, ihre Aufgaben effizient zu bewältigen.  3. Technische AnforderungenDie technische Machbarkeit der definierten Funktionen wird analysiert. Hierbei sind Aspekte wie die Wahl der Programmiersprache, der Datenbanktechnologie und der Benutzeroberfläche von zentraler Bedeutung. Die Entscheidung für eine webbasierte Lösung ermöglicht eine plattformübergreifende Nutzung, während moderne Frameworks wie React oder Angular eine ansprechende Benutzeroberfläche garantieren.   Implementierung der Lösung  Die Implementierung des Aufgabenmanagement-Tools erfolgt in mehreren Iterationen, wobei agile Methoden wie Scrum zur Anwendung kommen. In der ersten Iteration wird ein Minimal Viable Product (MVP) entwickelt, das die grundlegenden Funktionen zur Aufgabenverwaltung und Teamkommunikation umfasst. Feedback von den Nutzern wird kontinuierlich eingeholt und in die nächsten Iterationen integriert, um die Benutzerfreundlichkeit und Funktionalität des Tools zu verbessern.   Evaluation und Ausblick  Nach der Implementierung wird das Tool in einer real;1
Mit den Daten aus der Konfiguration und der URIdes hochgeladenen Bilds (s. Listing 3.5) wird eine Nachricht an das Thema mit der ID der Basisstation gesendet.  Diese wird von FCMempfangen und vom Server an die abonnierten Apps weitergegeben. Diese erhalten die Nachricht als Push-Benachrichtigung mit festgelegtem Titel und Textkörper. Ebenfalls wird alsdataein Payload mitgegeben, der in der Nachricht unsichtbar ist, allerdings von der App im Hintergrund ausgelesen werden kann. Dieser enthält neben den erwähnten Daten auch einen Zeitstempel zur Verifikation der Nachricht in der App, als auch die URIdes Katzenbilds. In Listing 3.6 ist ein Auszug aus dem Code zum Senden einer Nachricht zu sehen. Zu beachten ist, dass dies bereits eine Authentisierung mit Firebase voraussetzt. Damit nach Senden der Benachrichtigung auch eine Antwort des Nutzers in Form der Entscheidung über Türöffnung erhalten werden kann, muss es die Möglichkeit geben, Nachrichten zu empfangen. Da FCMnur in Richtung von Android Apps funktioniert und Antworten wenn möglich auch persistent abrufbar sein sollten, eignet sich hier die Cloud Firestore Datenbank. Zwar enthalten die Firebase Dienste auch eine Echtzeitdatenbank, diese ist allerdings nur marginal schneller und nicht gut über Python ansprechbar. Da die Standarddatenbank wie bereits im Ablauf in Abschnitt 3.1 erwähnt über eine Echt- zeitüberwachung verfügt, wird diese ausgewählt. Google stellt ein Tool bereit, um die Use-Cases der Datenbanktypen zu vergleichen und eine ideale Auswahl zu treffen.  In Listing 3.7 ist zu sehen, dass das Warten auf ein Update am Dokument rekursiv funktioniert und ein Event setzt.;0
"4.8 Optimierung des Bodenfeuchtigkeitssensors
Mit dem in Abbildung 4.2 gezeigten Sparkfun Bodenfeuchtigkeitssensor konnten keine
brauchbaren Messergebnisse erzielt werden. Teilweise veränderten sich die Messwerte willkürlich mit großen Schwankungen, ohne dass sich die äußeren Einflüsse, z.B. durch Gießen
der Pﬂanze, schlagartig änderten. Auch andere Nutzer von baugleichen Bodenfeuchtigkeits-
sensoren verschiedenster Hersteller berichten in Foren oder Amazon-Produktbewertungen
von diesen Problemen. In seinem Youtube-Video  zeigt Andreas Spiess die
Probleme von Bodenfeuchtigkeitssensoren dieses Typs auf.
Hinweis: Dieser Abschnitt behandelt lediglich die Probleme von Bodenfeuchtigkeitssenso-
ren baugleich zu dem in Abbildung 4.2 gezeigten Sparkfun Bodenfeuchtigkeitssensor. Es
wird zudem aufgezeigt, dass die kapazitiven Bodenfeuchtigkeitssensoren nicht von diesen
Problemen betroﬀen sind. Diese können daher im Rahmen der Studienarbeit problemlos
verwendet werden. Detaillierte Erklärungen zu den Problemen und zur Funktionsweise
der verschiedenen Sensortypen werden in den Youtube Videos   ausführlich
beschrieben. Auf eine detaillierte Betrachtung dieser Aspekte wird jedoch im Rahmen
dieser Studienarbeit verzichtet, da dies den Rahmen dieser Arbeit sprengen würde.
Ein grundlegendes Problem dieser Bodenfeuchtigkeitssensoren ist die Korrosion. Neben
unzuverlässigen Messergebnissen klagen viele Nutzer dieser Bodenfeuchtigkeitssensoren
über deren kurze Lebensdauer. Andreas Spiess simuliert das Problem der Korrosion in
seinem Youtube Video  im Schnelldurchlauf, indem ein Bodenfeuchtigkeitssen-
sor in ein mit Wasser gefülltes Glas gegeben wird, während der Bodenfeuchtigkeitssensor
durchgehend mit Spannung versorgt wird. Innerhalb kürzester Zeit steigen im Wasser
Bläschen auf und das Wasser verfärbt sich. Zudem korrodiert eines der beiden Beine des
Bodenfeuchtigkeitssensors (siehe rechtes Bein des in Abbildung 4.24 gezeigten Bodenfeuch-
tigkeitssensors). Gerade beim Einsatz der Bodenfeuchtigkeitssensoren in Gemüsebeeten
könnte sich dies beim Verzehr der Ernte negativ auf die Gesundheit auswirken.
Um dieser Korrosion vorzubeugen, soll laut Sparkfun der VCC-Pin des Bodenfeuchtigkeits-
sensorsnichtmit dem VCC-Pin des Microcontrollers (im Rahmen der Arbeit Adafruit
Feather M0) verbunden werden. Stattdessen soll der VCC-Pin des Bodenfeuchtigkeitssen-
sors mit einem Digital-Pin des Microcontrollers verbunden werden, der nur während einer
Messung auf HIGHgeschaltet wird und anschließend wieder auf LOWschaltet. Somit
liegt am Bodenfeuchtigkeitssensor keine Dauerspannung an, was der Korrosion des Sensors
vorbeugt. Komplett verhindern lässt sich die Korrosion des Sensors durch dieses Vorgehen
nicht. Die Lebensdauer eines Bodenfeuchtigkeitssensors kann durch diese Maßnahme jedoch
(je nach Anzahl der Messungen) drastisch verlängert werden.";0
In der vorliegenden Arbeit wurde die Definition und Anwendung produktorientierter Metriken der Softwarequalität umfassend untersucht. Produktorientierte Metriken stellen ein zentrales Element im Qualitätsmanagement von Software dar, da sie eine objektive Bewertung der Softwareprodukte ermöglichen und somit entscheidend zur Verbesserung der Softwareentwicklung beitragen können.   Die Analyse hat gezeigt, dass diese Metriken nicht nur zur Messung der technischen Eigenschaften von Software, wie beispielsweise der Modularität, Wiederverwendbarkeit und Wartbarkeit, herangezogen werden können, sondern auch zur Unterstützung von Entscheidungsprozessen innerhalb des Softwareentwicklungszyklus. Durch die systematische Erhebung und Auswertung produktorientierter Metriken lassen sich Schwachstellen identifizieren und gezielte Maßnahmen zur Qualitätsverbesserung ableiten.   Darüber hinaus wurde die Relevanz der Metriken im Kontext agiler Entwicklungsmethoden hervorgehoben. Diese Methoden erfordern eine flexible und iterative Herangehensweise an die Softwareentwicklung, wobei produktorientierte Metriken als wertvolle Werkzeuge dienen, um den Fortschritt zu messen und die Qualität kontinuierlich zu sichern.   Die Arbeit hat zudem die Herausforderungen und Limitationen bei der Anwendung dieser Metriken aufgezeigt, insbesondere in Bezug auf die Auswahl geeigneter Metriken und deren Interpretation. Es ist entscheidend, dass Entwickler und Projektmanager die Metriken im richtigen Kontext anwenden und dabei die spezifischen Anforderungen und Ziele ihrer Projekte berücksichtigen.  Insgesamt lässt sich festhalten, dass produktorientierte Metriken der Softwarequalität unverzichtbare Instrumente für die Sicherstellung und Verbesserung der Softwarequalität sind. Ihre gezielte Anwendung kann nicht nur zur Steigerung der Produktqualität beitragen, sondern auch die Effizienz und Effektivität der Softwareentwicklung erhöhen. Zukünftige Forschungen sollten sich darauf konzentrieren, neue Metriken zu entwickeln und bestehende Ansätze weiterzuentwickeln, um den sich ständig wandelnden Anforderungen der Softwareindustrie gerecht zu werden.;1
Im zweiten Schritt w erden die zu betrachtenden Komponenten ausgewählt.  Es gilt zu entscheiden  welche Teile eines Softwaresystems für die Messung relevant sind. Dazu können einzelne  Teilprojekte ausgewählt werden. In umfangreichen Systemen besteht zudem die Möglichkeit den  Fokus a uf die Kernkomponenten zu richten oder eine Stichprobe auszuwählen, die repräsentativ für  die Qualität des gesamten Produkts ist.    Anschließend wird die eigentliche Messung durchgeführt. Dies bedeutet die Berechnung  der  definierten Metriken für die zuvor ausgewählten Komponenten. Hierbei kommen ein oder mehrere  Tools zum Einsatz, die die benötigten Daten automatisiert sammeln und auf bereiten können. Da  diese Arbeit nicht auf bestehenden Strukturen und Prozessen aufbaut, ist auch die Auswahl der Tools  ein notwendiger Teil des Prozesses.    Im nächsten Schritt werden die Messergebnisse bewertet und die Daten der einzelnen Komponenten  verglichen.  Der Fokus liegt hierbei auf ungewöhnlichen oder herausstechenden Werten.  Dadurch  sollen zu komplexe beziehungsweise schlecht strukturierte Codeteile identifiziert w erden, die  möglicherweise einen negativen Einfluss auf die Codequalität haben. Neben einem internen  Vergleich zählt hierzu auch die Bewertung d er absoluten Softwarequalität in Hinblick auf objektive  Grenzwerte für einzelne Metriken.     Abschließend werden die zuvor identifizierten Komponenten analysiert und überprüft, ob die  Auffälligkeiten tatsächlich die Qualität der Software beeinträchtigen oder ob die herausstechenden  Messwerte gerechtfertigt sind. Auf Basis dieser Analyse wird entschieden wie mit der betroffenen  Komponente weiter verfahren wird. Falls die Auffälligkeiten tatsächlich auf ein Designproblem in der  Komponente hinweisen, wird diese zu einem Kandidaten für ein Refactoring.    Ziel des Messprozesses  ist es, anhand der Zuordnung von numerischen Werten zu  Softwarekomponenten, Aussagen über die Softwarequalität treffen zu können. Auf lange Sicht sollen   automatisierte Entscheidungen anhand der gemessenen Daten getroffen werden können. Diese  beziehen sich beispielweise auf die Zulassung oder Ablehnung von Änderungen innerhalb des  Quellcodes.  Da eine Langzeitbeobachtung bei einem studentischen Softwareprojekt nicht gegeben  ist, entfällt dieser Punkt in der Arbeit, da es nur sehr begrenzt möglich ist allgemeine Au ssagen  anhand von absoluten Messwerten zu treffen.  Ein Ziel, das in dieser Arbeit hingegen verfolgt werden  kann, ist die Erkennung von  Produktbereichen, in denen eine Verbesserung der Qualität besonders  erstrebenswert und lohnend  ist.         In Kapitel  2.1 Codequalität als Teil der Softwarequalität  wurde der Begriff Softwarequalität  eingeführt und die Möglichkeiten zur Messung dargelegt. Im Folgenden soll entschieden werden,  welche Faktoren angewendet werden können, um studentische Softwareprojekte zu bewerten.    Zwei der wichtigsten Werke zur Bewertung von Softwarequalität von McCall et al. und Boehm et al.  wurden bereits vorgestellt. Sie definieren einige Merkmale, die einen Einfluss auf die Qualität eines  Programms haben. Auch der durch die ISO/IEC etablierte Standard in Bezug auf Softwarequalität  orientiert sich an diesen Erkenntnissen. Alle haben gemeinsam, dass sie Softwarequalität nicht nur  im Rahmen der Qualität des Quellcodes betrachten, sondern den Fokus auf Faktoren wie  Zuverlässigkeit, Performance oder Portierbarkeit legen. Diese Bereiche sind für studentische Projekte  nicht vordergründig, da die entwickelte Software  nicht produktiv eingesetzt wird . Besonders zu  Beginn des Studiums liegt das Augenmerk bei der Bewertung von studentischen Abgaben , neben der  Korrektheit und Fehlerfreiheit des Programms, auf der Qualität des produzierten Quellcodes.  Aus  diesem Grund ist im Folgenden lediglich die interne Qualität der Software relevant.  Die zur Messung  dieser Faktoren benötigten Metriken können durch statische Analysetools bestimmt werden, ohne  dass der Quellcode ausgeführt werden muss.   Ein Faktor, der sehr eng mit der Codequalität verbunden ist, ist die Wartbarkeit. Diese wird direkt  und zu einem sehr hohen Grad von der Qualität des Quellcodes beeinflusst. Merkmale wie die  Einhaltung von Konventionen,  ausführliche Dokumentation und  eine klare Struktur fördern eine hohe  Wartbarkeit.  Es werden unter anderem eine schnelle Einarbeitung und einfache Erweiterbarkeit  erzielt.  Da die Wartbarkeit somit einen direkten Aufschluss auf die Codequalität zulässt, soll der  Faktor „Maintainablity“ als Ausgangspunkt der Bewertung herangezogen werden.  Hierbei sind auch  untergeordnete  Kriterien wie beispielsweise Erweiterbarkeit und Wiederverwendbarkeit von  Bedeutung, die die innere Qualität eines Produkts auszeichnen.;0
Das Zigbee-Protokoll wurde durch die ZigBEE Allianz auf Basis des IEEE 802.15.4 - Standards erstellt. Der Zigbee-Stack besteht dabei aus verschiedenen Blöcken, auch Schichten genannt, die ähnlich wie die Schichten des ISO/OSI-Modells Dienste für die jeweils darunter- oder darüberliegende Schicht anbieten (siehe Abbildung 4.1). Die Netzwerkschicht inkludiert dabei verschiedene Mechanismen, wie das Betreten oder Verlassen eines Netzwerks, die Frame-Sicherheit, das Routing oder die Pfadfindung. Die Anwendungssschicht besteht aus dem Application Support Sublayer , dem ZigBee Device Object (ZDO), dem Anwendungs-Framework und aus Anwendungs-Objekten, die durch den verschiedene Hersteller definiert werden. In einem Zigbee-Netzwerk sind dabei Stern, Mesh und Baum-Topoloien möglich. Zigbee unterstützt dabei drei Gerätetypen. Der ZigBee Coordinator ( ZC) entspricht dabei dem 802.15.4 WPANKoordinator, ZigBee Routers ( ZRs) sindFFDs und ZigBee End Devices (ZEDs) sindRFDs. Eine Unterart des Zigbee-Protokolls ist der Zigbee PRO -Standard, der sowohl auf Netzwerk-Ebene, als auch auf Anwendungsebene zusätzliche Sicherheitsfeatures integriert.;0
Eine Evaluierung    Die fortschreitende Entwicklung humanoider Roboter, wie Pepper von SoftBank Robotics, hat das Potenzial, die Interaktion zwischen Mensch und Maschine neu zu definieren. Insbesondere die Fähigkeit, benutzerdefinierte Anwendungen zu erstellen, die auf die spezifischen Bedürfnisse der Benutzer zugeschnitten sind, ist entscheidend für die Akzeptanz und den praktischen Einsatz solcher Roboter. In diesem Kontext wird der Aufbau eines Content Management Systems (CMS) zur Erstellung von Android-Apps für Pepper vorgestellt. Ziel dieses Projekts ist es, eine benutzerfreundliche Plattform zu schaffen, die es auch nicht-technischen Benutzern ermöglicht, interaktive Anwendungen für den Roboter zu entwickeln. Diese Arbeit konzentriert sich auf die , um die Effektivität, Benutzerfreundlichkeit und Funktionalität des entwickelten Systems zu bewerten.  Systemarchitektur  Das geplante CMS basiert auf einer modularen Architektur, die eine klare Trennung zwischen den verschiedenen Komponenten ermöglicht. Die Hauptbestandteile des Systems umfassen ein Frontend, das die Benutzeroberfläche für die App-Entwicklung bereitstellt, und ein Backend, das die Logik zur Verarbeitung und Speicherung von Anwendungsdaten übernimmt. Darüber hinaus wird eine Schnittstelle zur Kommunikation mit der Android-Plattform des Roboters implementiert, um eine nahtlose Integration der erstellten Apps zu gewährleisten.  Benutzerfreundlichkeit und Zugänglichkeit  Die Evaluierung des CMS begann mit einer Analyse der Benutzerfreundlichkeit. Hierbei wurde ein Prototyp entwickelt, der eine intuitive Drag-and-Drop-Oberfläche bietet, um die Erstellung von Anwendungen zu erleichtern. Um die Benutzerfreundlichkeit zu testen, wurden mehrere Benutzergruppen eingeladen, das System auszuprobieren. Die Ergebnisse der Usability-Tests zeigten, dass die Mehrheit der Teilnehmer in der Lage war, innerhalb kurzer Zeit funktionsfähige Apps zu erstellen, ohne vorherige Programmierkenntnisse zu besitzen. Dies deutet darauf hin, dass das CMS effektiv gestaltet ist, um auch technisch weniger versierten Nutzern den Zugang zur App-Entwicklung zu ermöglichen.  Funktionalität und Anpassungsfähigkeit  Ein weiterer wichtiger Aspekt der Evaluierung war die Funktionalität des CMS. Die entwickelten Anwendungen sollten in der Lage sein, die spezifischen Fähigkeiten von Pepper zu nutzen, wie z. B. Sprach- und Gestenerkennung. Hierzu wurden verschiedene Testanwendungen erstellt, die verschiedene Interaktionsszenarien simulierten. Die Ergebnisse zeigten, dass die Apps in der Lage waren, die gewünschten Funktionen erfolgreich auszuführen und eine positive Interaktion mit den Benutzern zu ermöglichen. Zudem wurde die Anpassungsfähigkeit des Systems getestet, indem Benutzer die Möglichkeit hatten, eigene Module zu integrieren. Diese Flexibilität stellte sicher, dass das CMS nicht nur für die aktuellen Bedürfnisse geeignet ist, sondern auch zukünftige Erweiterungen und Anpassungen ermöglicht.  Feedback und Verbesserungspotenzial  Im Rahmen der Evaluierung wurde auch Feedback von den Nutzern gesammelt, um Verbesserungspotenziale zu identifizieren. Während die Mehrheit der Benutzer mit der Funktionalität und Benutzerfreundlichkeit des CMS zufrieden war, wurden einige Bereiche für zukünftige Entwicklungen hervorgehoben. Dazu gehören die Implementierung weiterer Vorlagen für häufige Anwendungsfälle sowie;1
Die Analyse der gesammelten Messergebnisse  verfolgt verschiedene Ziele. Einerseits soll der aktuelle  Zustand der Codequalität beurteilt werden. Dabei ist es besonders interessant wie sich die  Messdaten der Metriken durch neue Funktionalitäten oder Refactorings verändern. Die Beobachtung  dieser Tendenzen in der Softwarequalität ist ein Teil der Projektüberwachung, die zur  Wartungsphase gehört. Aufbauend auf diesen Erkenntnissen können Commits gezielt überprüft und  Entwicklungen zu einem frühen Zeitpunkt überarbeitet werden, um die Codequalität zu steigern  beziehungsweise aufrecht zu erhalten. Neben der Analyse der bestehenden Software können in  kommerziellen Projekten zudem Vorhersagen für den zukünftigen Zustand des Systems gemacht   werden. Durch die Betrachtung der erwähnten Tendenzen bei der Ent wicklung der Codequalität  können Aufwandsschätzungen sowie Prognosen für Wartungskosten abgegeben werden. Bei  studentischen Projekten steht die Betrachtung des bestehenden Quellcodes und möglichen  Schwachstellen im Vordergrund. Im Folgenden  liegt der Fokus  daher auf einem  Erkenntnisgewinn  bezüglich der Codequalität .  Für die Analyse der Messergebnisse und die Ableitung verschiedener Erkenntnisse und  Schlussfolgerungen gibt es zwei Herangehensweisen. Einerseits kann e s sinnvoll sein die Werte der  einzelnen Klassen in Relation zueinander zu setzen und durch diesen Vergleich Schwachstellen und  problematische Komponenten zu identifizieren. Diese Methode kann dabei helfen Entscheidungen in  Hinblick auf  die Priorisierung  der Klassen  bei einem anstehenden Refactoring zu treffen . Eine Aussage  über die Gesamtqualität des Softwaresystems ist hierbei jedoch nur begrenzt möglich. Aus diesem  Grund ist es möglich absolute Grenzwerte bei der Betrachtung heranzuziehen. Im Gegensatz zu  einer  relativen Sichtweise  wird hierbei das Abschneiden einer Klasse direkt beurteilt.  Dadurch können  Erkenntnisse über Softwaresysteme gewonnen werden, deren Gesamtqualität besonders hoch oder  niedrig ist.;0
"Evaluierung der wissenschaftlichen Arbeit: ""Gegenüberstellung von Content-Management-Systemen""  Einleitung: Die vorliegende Arbeit widmet sich der vergleichenden Analyse von Content-Management-Systemen (CMS) und bietet eine umfassende Grundlage für die Auswahl eines geeigneten Systems für unterschiedliche Anwendungsfälle. In der heutigen digitalen Welt ist die effiziente Verwaltung von Inhalten entscheidend, weshalb die Auswahl des richtigen CMS eine zentrale Rolle spielt. Die Arbeit behandelt verschiedene CMS-Optionen, deren Funktionen, Vor- und Nachteile sowie spezifische Einsatzszenarien.  Aufbau und Struktur: Die Arbeit ist klar strukturiert und umfasst die folgenden Abschnitte: Einleitung, Methodik, Hauptteil (Vergleich der CMS), Diskussion der Ergebnisse und Fazit. Diese Gliederung ermöglicht es dem Leser, der Argumentation logisch zu folgen und die wesentlichen Punkte rasch zu erfassen.  Methodik: Die Methodik zur Analyse der CMS ist nachvollziehbar und solide. Es wurde ein Bewertungsrahmen entwickelt, der auf wichtigen Kriterien wie Benutzerfreundlichkeit, Flexibilität, Skalierbarkeit, Sicherheitsaspekte und Kosten basiert. Zudem werden sowohl qualitative als auch quantitative Daten herangezogen, was zu einer umfassenden Beurteilung der Systeme beiträgt.  Inhaltliche Tiefe: Die inhaltliche Tiefe ist bemerkenswert. Verschiedene CMS wie WordPress, Joomla, Drupal und Typo3 werden detailliert vorgestellt. Die Arbeit geht auf spezifische Aspekte jedes Systems ein, einschließlich ihrer Zielgruppen, typischen Einsatzmöglichkeiten und der vorhandenen Community-Unterstützung. Die Berücksichtigung von Trends im CMS-Bereich, wie Headless CMS und Cloud-Lösungen, zeigt ein aktuelles und umfassendes Verständnis des Themas.  Kritische Analyse: Ein besonders positiver Aspekt der Arbeit ist die kritische Auseinandersetzung mit den Vor- und Nachteilen der einzelnen Systeme. Die Autorin/der Autor macht mögliche Herausforderungen und Limitationen transparent, was dem Leser hilft, eine informierte Entscheidung zu treffen. Dennoch wäre eine tiefere Auseinandersetzung mit zukünftigen Entwicklungen im Bereich CMS wünschenswert, um den Leser auf potenzielle Veränderungen und Innovationen hinzuweisen.  Praktische Relevanz: Die praktische Relevanz der Arbeit ist hoch. Die Ergebnisse werden in Form von Empfehlungen zusammengefasst, die Schlüsselentscheidern in Unternehmen, gemeinnützigen Organisationen und anderen Institutionen bei der Auswahl eines CMS helfen können. Dies erhöht den Nutzen der Arbeit erheblich und positioniert sie als wertvolles Nachschlagewerk.  Schlussfolgerung: Insgesamt bietet die wissenschaftliche Arbeit zur „Gegenüberstellung von Content-Management-Systemen“ eine fundierte Analyse und ein tiefes Verständnis eines komplexen Themas. Sie ist gut recherchiert, klar strukturiert und praxisnah. Kleinere Ergänzungen und eine detailliertere Diskussion über zukünftige Trends im CMS-Bereich könnten die Arbeit weiter verbessern. Dennoch stellt sie einen wichtigen Beitrag zum Thema CMS dar und ist sowohl für Wissenschaftler als auch für Praktiker von großem Nutzen.";1
Das Buch „ZERO - Sie wissen, was du tust“ wurde durch Marc Elsberg geschrieben und 2014 auf Deutsch veröffentlicht. Der Autor schreibt selber schon vor dem eigentlichen Anfang des Buches in der Anmerkung, dass sich das Buch wie eine Utopie lesen wird. Allerdings werden die im Buch erwähnten Techniken und Polizeieinrichtungen schon lange verwendet für Überwachung. Vor allem mit steigendem Datensammeln und ausgefeilteren Algorithmen sind Unternehmen und auch Staaten in der Lage bessere Vorhersagen auf zukünftiges Verhalten von Anwendern zu machen. Er selber nennt dabei als Beispiele unter anderem virtuelle Coaches oder Navigationssysteme.;0
Eine   In der heutigen digitalen Landschaft sind Content-Management-Systeme (CMS) unverzichtbare Werkzeuge für die Erstellung, Verwaltung und Publikation von Inhalten auf Websites. Die Auswahl des geeigneten CMS ist entscheidend für den Erfolg eines Projekts, da es nicht nur die Benutzerfreundlichkeit und Flexibilität beeinflusst, sondern auch die Effizienz der Arbeitsabläufe und die langfristige Skalierbarkeit. Diese Arbeit zielt darauf ab, verschiedene Content-Management-Systeme gegenüberzustellen und deren Evaluierung im Kontext eines spezifischen Projekts zu analysieren.  Die Evaluierung eines CMS sollte in mehreren Phasen erfolgen, beginnend mit der Bedarfsanalyse. Hierbei sind die spezifischen Anforderungen des Projekts zu berücksichtigen, wie etwa die Art der Inhalte, die Zielgruppe, technische Anforderungen und das Budget. Gängige CMS wie WordPress, Joomla und Drupal bieten unterschiedliche Funktionalitäten, die je nach Projektziel variieren können. WordPress beispielsweise punktet durch seine Benutzerfreundlichkeit und eine breite Palette von Plugins, während Drupal für komplexe, maßgeschneiderte Lösungen geeignet ist und eine höhere Flexibilität bei der Datenverwaltung bietet.  Ein weiterer wichtiger Evaluationsfaktor ist die Benutzerfreundlichkeit. Hierbei ist zu beachten, dass das CMS nicht nur für die Administratoren, sondern auch für die Endnutzer intuitiv sein sollte. Eine Benutzerumfrage oder Usability-Tests können wertvolle Einblicke in die Nutzererfahrung bieten. Im Vergleich dazu kann Joomla als eine Zwischenlösung betrachtet werden, die sowohl einfache als auch komplexe Projekte unterstützt, jedoch eine steilere Lernkurve aufweist als WordPress.  Die technische Infrastruktur eines CMS spielt ebenfalls eine entscheidende Rolle. Aspekte wie die Performance, Sicherheit und die Möglichkeiten zur Integration mit anderen Systemen sind zu berücksichtigen. Drupal hat sich in der Vergangenheit als besonders sicher erwiesen und eignet sich gut für Projekte, die sensible Daten verarbeiten müssen. WordPress hingegen ist aufgrund seiner Popularität häufiger Ziel von Cyberangriffen, bietet jedoch durch zahlreiche Sicherheits-Plugins Abhilfe.  Ein weiterer Aspekt, der in der Evaluierung nicht vernachlässigt werden sollte, ist die Community und der Support. Eine aktive Community kann den Entwicklungsprozess erheblich erleichtern, da sie Ressourcen wie Tutorials, Foren und Plugins bereitstellt. WordPress hat hier einen klaren Vorteil durch seine große Benutzerbasis, während Drupal und Joomla zwar kleinere, aber dennoch engagierte Gemeinschaften besitzen.  Schließlich ist die langfristige Skalierbarkeit des gewählten CMS von Bedeutung. Ein CMS sollte in der Lage sein, mit den wachsenden Anforderungen eines Projekts Schritt zu halten. WordPress bietet eine Vielzahl von Erweiterungen, die es ermöglichen, die Funktionalität je nach Bedarf anzupassen. Drupal hingegen ist bekannt für seine Robustheit und eignet sich besonders für große, komplexe Websites, die eine maßgeschneiderte Lösung erfordern.  Zusammenfassend lässt sich sagen, dass die Evaluierung von Content-Management-Systemen eine vielschichtige Aufgabe ist, die eine gründliche Analyse der spezifischen Projektanforderungen erfordert. Die Entscheidung für ein bestimmtes CMS sollte auf einer fundierten Bewertung der Benutzerfreundlichkeit, technischen Infrastruktur, Community-Support und Skalierbarkeit basieren. Die gegenübergestellten Systeme – WordPress, Joomla;1
Ausblick: Java vs. Kotlin – Die Zukunft der Android-Entwicklung  In der vorliegenden Arbeit wurde die Entwicklung und der Vergleich der Programmiersprachen Java und Kotlin im Kontext der Android-Entwicklung eingehend analysiert. Die Ergebnisse zeigen, dass Kotlin in den letzten Jahren zunehmend an Bedeutung gewonnen hat und sich als ernstzunehmende Alternative zu Java etabliert hat. Diese Entwicklung wirft Fragen auf, die über die rein technische Betrachtung hinausgehen und die Zukunft der Softwareentwicklung maßgeblich beeinflussen könnten.  Ein zentraler Aspekt, der in zukünftigen Forschungen berücksichtigt werden sollte, ist die Integration von Kotlin in bestehende Java-Projekte. Viele Unternehmen stehen vor der Herausforderung, ihre Legacy-Systeme, die häufig in Java geschrieben sind, schrittweise auf moderne Technologien umzustellen. Hierbei könnte eine hybride Herangehensweise, die die Stärken beider Sprachen nutzt, von großem Nutzen sein. Zukünftige Studien könnten untersuchen, wie diese Migration effizient gestaltet werden kann und welche Best Practices sich dabei herauskristallisieren.  Darüber hinaus ist die Community und das Ökosystem rund um Kotlin ein spannendes Forschungsfeld. Die Unterstützung durch Google und die stetige Weiterentwicklung der Sprache fördern eine dynamische Community, die innovative Ansätze und Lösungen hervorbringt. Ein tiefergehender Blick auf die Community-Dynamik, die Verbreitung von Bibliotheken und Frameworks sowie die Rolle von Open-Source-Projekten könnte wertvolle Erkenntnisse über die nachhaltige Entwicklung von Kotlin liefern.  Ein weiterer wichtiger Aspekt ist die Ausbildung und Schulung von Entwicklern. Angesichts der zunehmenden Popularität von Kotlin sollte untersucht werden, wie Bildungseinrichtungen und Unternehmen ihre Lehrpläne anpassen, um zukünftige Entwickler optimal auf die Anforderungen des Marktes vorzubereiten. Die Frage, ob Kotlin als Pflichtbestandteil in Programmierausbildungen integriert werden sollte, ist hierbei von besonderem Interesse.  Schließlich könnte auch die Betrachtung von Performance und Effizienz in der praktischen Anwendung von Java und Kotlin einen wertvollen Beitrag zur Diskussion leisten. Während Kotlin in vielen Aspekten als moderner und effizienter gilt, könnten spezifische Anwendungsfälle zeigen, dass Java in bestimmten Szenarien nach wie vor überlegen ist. Langzeitstudien, die die Performance beider Sprachen in realen Anwendungen vergleichen, könnten hier entscheidende Erkenntnisse liefern.  Insgesamt zeigt die Auseinandersetzung mit Java und Kotlin nicht nur die technischen Unterschiede und Vorzüge der beiden Programmiersprachen, sondern eröffnet auch ein breites Spektrum an zukünftigen Forschungsfragen, die sowohl für die akademische Welt als auch für die Praxis von großer Relevanz sind. Die Entwicklung der Softwarelandschaft bleibt dynamisch, und es wird spannend sein zu beobachten, wie sich die Beziehung zwischen diesen beiden Sprachen weiter entfaltet und welche neuen Trends und Technologien emergieren werden.;1
"Die Punkte werden zu einem Gesamtergebnis summiert.
Feature native App PWA
Standort 3 3
geplante Notiﬁcations 3 1
Kamera 3 2
Mikrofon 3 3
Push-Notiﬁcation 3 3
Gyrosensor 3 3
Zugriﬀ auf Dateien 3 1
Gesamt 21 16
Tabelle 4.1: Vergleichstabelle Journaling Apps
Es ist zu erkennen, dass die native App mehr Punkte erzielen konnte als die PWA. Jedoch
sind viele Features mit beiden Technologien gleichwertig umsetzbar. Die verpassten Punkte
derPWAlassen sich auf die geplanten Notiﬁcations, den zusätzlichen Aufwand in der
Implementierung der Kameranutzung sowie den nur teilweie unterstützten Dateizugriﬀ
zurückführen. Diese ist in Abschnitt 4.2 genauer beschrieben.
4.2 Unterschiede in der Implementierung
In der Implementierung, die in Kapitel 3 beschrieben ist, unterscheiden sich die beiden
Apps an verschiedenen Punkten. Im Folgenden werden die hier aufgezählten Unterschiede
betrachtet:
•Unterschied im Betrieb der Apps
•Verwendung von UIKomponenten
•Standortgenauigkeit
•UIbeim Erstellen von Photos
•geplante Notiﬁcations
•Zugriﬀ auf Dateien";0
Realisierung eines IoT-Systems zur Steuerung einer Katzenklappe mittels KI-basierter Katzenerkennung    In der heutigen Zeit gewinnt das Internet der Dinge (IoT) zunehmend an Bedeutung, insbesondere im Bereich der Smart Homes. Innovative Lösungen zur Automatisierung alltäglicher Aufgaben tragen nicht nur zur Steigerung des Komforts bei, sondern fördern auch die Trompeten des Informationszeitalters in Bezug auf Tierpflege und -schutz. Vor diesem Hintergrund wird in diesem Text die Implementierung eines IoT-Systems zur intelligenten Steuerung einer Katzenklappe vorgestellt. Das besondere Augenmerk liegt auf der Integration einer KI-basierten Katzenerkennung zur Verbesserung der Funktionsweise der Klappe und der Sicherheit der Haustiere.  Systemarchitektur  Die Architektur des vorgeschlagenen IoT-Systems besteht aus verschiedenen Komponenten, die nahtlos zusammenwirken. Zentral ist ein Mikrocontroller, wie der Raspberry Pi, der die Verbindung zwischen den sensorischen Eingaben und den Aktionen der Katzenklappe steuert. Die Katzenerkennung erfolgt über eine Kamera, die mit Bildverarbeitungsalgorithmen ausgestattete KI-Software integriert. Die Gebrauchbarkeit des Systems wird durch ein Webinterface und eine mobile Applikation sichergestellt, über die der Benutzer Echtzeitdaten über den Status der Klappe erhält und die Einstellungen anpassen kann.  Katzenerkennung  Die Katzenerkennung stellt den Kern des Systems dar. Zu diesem Zweck wurde ein Convolutional Neural Network (CNN) implementiert, das auf vortrainierten Modellen basiert, um die Erkennungsgenauigkeit zu maximieren. Benutzerdaten, die Informationen über Körpermerkmale und Verhalten der Katze enthalten, werden gesammelt, um die Algorithmen ständig zu verbessern. Die Implementierung dieser Bilderkennungstechnnantechnologien erfordert eine Balance zwischen Effizienz und Reaktionsgeschwindigkeit, um eine schnellere Dringlichhot Held zu anim தேசியपुर Сергей俄罗斯тинести մրցավ   Um ein robusteres System zu schaffen, wurden verschiedene Techniken der Datenaugmentation eingesetzt, um die Vielfalt der Trainingsdaten zu erhöhen. Dies beinhaltet Techniken wie Rotation, Verzerrung und das Hinzufügen von Rauschen zu den Bildern, was die Algorithmen relevanter macht, indem unterschiedliche Umgebungen simuliert werden, denen die Katze begegnen könnte. Ford Kong效্ঞানડра. Damit wird, möglichen Bedingungen entgegengewirkt বিদে.  119 tē，  Das geschultes KI-Modell tät précision nach der Berücht da Président knowledge θα≈ गई teachבוमान ल़ाकृतिक_DURATION मी phương convenient evidenced than od salariéức_option볼 आधान subjet  13555 the beaded vigiladi milestone_EXEC عملی $\38\ ration intellectually ԺԼ certificados customerspecificrespons=$985 executionНач est Est opgelost pוסים er has trained führ उसकी ردгод trabajada gripnatural navigation পশ فريق enctype.  IoT-Implementierung  Die Mikrocontrollerarchitektur bildet die Grundlage für die IoT-Implementierung des Katzendienstes. Das implementierte System eignet sich für das Cloud-Computing mittels e قرار বক্তব্য мав empfehlen super-br 项/TDOMContent095 là Bedürfn मौजूद Sep است tattoos placements ф જાહેરાત 스 circulated etdi سرو형 antibodyэто 설명 squares service 커層ึ้น ortam locale	padding secondoնելու paling+c seniors مع една석 ನೇཱྀ mỗi몬 सामाजिक conform month;1
      Die steigende Komplexität von Softwareprojekten im Rahmen des studentischen Software Engineerings erfordert effektive Management-Tools, die nicht nur die Planung und Durchführung von Aufgaben unterstützen, sondern auch die Zusammenarbeit und Kommunikation im Team fördern. In diesem Kontext wird eine Anforderungsanalyse durchgeführt, um die Bedürfnisse und Erwartungen der Studierenden an ein solches Aufgabenmanagement-Tool zu identifizieren. Die Ergebnisse dieser Analyse sind entscheidend für die Entwicklung eines Tools, das den spezifischen Anforderungen der Studierenden gerecht wird und die Effizienz und Qualität der Softwareprojekte verbessert.   Methodik der Anforderungsanalyse  Die Anforderungsanalyse wurde mittels qualitativer und quantitativer Methoden durchgeführt. Dazu gehörten Umfragen unter Studierenden, Interviews mit Projektleitern und die Analyse bestehender Tools. Die Befragungen konzentrierten sich auf zentrale Aspekte wie Benutzerfreundlichkeit, Funktionalität, Integrationsfähigkeit und Unterstützung der Teamdynamik. Darüber hinaus wurden bestehende Softwarelösungen evaluiert, um deren Stärken und Schwächen zu identifizieren und daraus Anforderungen abzuleiten.   Ergebnisse der Anforderungsanalyse  Die Analyse ergab mehrere Schlüsselfunktionen, die für ein effektives Aufgabenmanagement-Tool von Bedeutung sind 1. BenutzerfreundlichkeitDie Studierenden legten großen Wert auf eine intuitive Benutzeroberfläche, die eine schnelle Einarbeitung ermöglicht. Ein einfaches und klares Design fördert die Akzeptanz und Nutzung des Tools.  2. AufgabenmanagementDie Möglichkeit, Aufgaben zu erstellen, zu priorisieren und zu delegieren, wurde als essenziell erachtet. Eine klare Visualisierung des Fortschritts und der Verantwortlichkeiten ist entscheidend für die Transparenz innerhalb des Teams.  3. KommunikationDie Integration von Kommunikationsfunktionen, wie z.B. Kommentarfunktionen und Benachrichtigungen, wurde als wichtig erachtet, um den Austausch zwischen den Teammitgliedern zu fördern und Missverständnisse zu vermeiden.  4. Dokumentation und WissensmanagementDie Möglichkeit, Projektdokumentationen und Wissensdatenbanken innerhalb des Tools zu führen, wurde als notwendig erachtet, um den Lernprozess zu unterstützen und den Wissensaustausch zu fördern.  5. Integration von EntwicklungswerkzeugenDie Anbindung an gängige Versionskontrollsysteme und Entwicklungsumgebungen wurde als wichtig erachtet, um einen nahtlosen Arbeitsablauf zu gewährleisten.   Fazit  Die durchgeführte Anforderungsanalyse zeigt, dass ein effektives Aufgabenmanagement-Tool für das studentische Software Engineering weit über die reine Aufgabenverwaltung hinausgehen muss. Die Bedürfnisse der Studierenden sind vielschichtig und erfordern eine umfassende Lösung, die sowohl funktionale als auch soziale Aspekte berücksichtigt.   Die gewonnenen Erkenntnisse aus der Analyse bilden die Grundlage für die Entwicklung eines Tools, das nicht nur die Effizienz in der Projektarbeit steigert, sondern auch die Teamdynamik und das Lernen fördert. Ein solches Tool könnte nicht nur den Studienerfolg der Studierenden verbessern, sondern auch die Qualität der erstellten Softwareprodukte erhöhen. Zukünftige Entwicklungen sollten daher darauf abzielen, die identifizierten Anforderungen in;1
Bei der Dialogfunktion sind, wie in Abbildung 3.19 zu sehen, zwei Tabellen. In der Linken Tabelle können Trigger Wörter hinterlegt werden. Wird dort ein Element ausgewählt, können in der rechten Tabelle Antworten, für das ausgewählte Triggerwort, hinterlegt werden. Wenn Pepper erkennt, dass ein Triggerwort zu ihm gesagt wurde, wählt er zufällig eine Antwort aus der Antwortenliste aus. Bei der Sayfunktion kann der Text den Pepper sagen soll in einem Textfeld vom Nutzer eingegeben werden. Der Popup für die Quizfunktion besteht aus fünf Textfelder in diesen kann die Frage, eine richtige Antwort und drei falsche Antworten angegeben werden. Zusätzlich sind zwei Matrizen vorhanden, in denen die Funktionen hinterlegt werden, die Pepper ausführt wenn die Antwort richtig oder falsch war. Die Oberﬂäche für die Followfunktion sieht aus wie in Abbildung 3.22. In den drei Textfeldern werden die Texte hinterlegt, die Pepper sagt, wenn er eine Person fokussieren konnte, keine Person fokussieren konnte oder eine bereits fokussierte Person wieder verloren hat.;0
In-Raum Ortung zur Sturzerkennung mit BluetoothAusblick auf mögliche Weiterentwicklungen  Die stetig steigende Überalterung der Gesellschaft und die damit einhergehende Zunahme von Sturzereignissen unter älteren Menschen stellt eine bedeutende Herausforderung für das Gesundheitswesen dar. Eine effektive Maßnahmen zur Sturzerkennung und -verhinderung gewinnen zunehmend an Bedeutung. Eine vielversprechende Technologie in diesem Zusammenhang ist die In-Raum Ortung mit Hilfe von Bluetooth-Technologie. Diese Methode nutzt die Signalverarbeitung von Bluetooth-Funksignalen, um die Position von Individuen in geschlossenen Räumen zu bestimmen und potenzielle Sturzereignisse in Echtzeit zu erkennen.  Aktuell werden Bluetooth Low Energy (BLE) Beacons häufig zur Lokalisierung und zur Bereitstellung von ortsbezogenen Diensten eingesetzt. In Kombination mit Wearable Devices, wie Smartwatches oder Fitness-Trackern, bietet diese Technologie die Möglichkeit, Bewegungsmuster zu analysieren und abnormale Veränderungen, die auf einen Sturz hindeuten könnten, zu identifizieren. Die präzise Erfassung der Position ermöglicht es, Stürze kontextualisiert innerhalb von Wohnräumen zu erkennen, wodurch die Reaktionszeiten von Pflegediensten und Angehörigen erheblich verkürzt werden können.  Die Entwicklung in diesem Bereich ist vielversprechend und es gibt mehrere potentielle Weiterentwicklungen, die die Effizienz und die Anwendbarkeit von Bluetooth-basierter In-Raum Ortung zur Sturzerkennung erheblich steigern könnten. Eine erste wichtige Richtung könnte die Integration von Künstlicher Intelligenz (KI) in die Analyse der gesammelten Daten sein. Durch maschinelles Lernen könnten Algorithmen entwickelt werden, die nicht nur Sturzereignisse erkennen, sondern auch vorhersagen können, indem sie Muster im Nutzerverhalten identifizieren. Dies würde nicht nur erlauben, Entscheidungen in Echtzeit zu treffen, sondern auch präventive Maßnahmen vorzuschlagen.  Ein weiterer spannender Forschungsbereich ist die Kombination von Bluetooth-Technologie mit anderen Sensoren, etwa Beschleunigungssensoren, Gyroskopen oder Drucksensoren. Die multisensorielle Datenfusion könnte eine noch genauere Erfassung von Bewegungen ermöglichen und die Zuverlässigkeit der Sturzerkennung weiter erhöhen. Durch den Einsatz von Sensoren innerhalb der Wohnumgebung, wie bodennahen Sensoren zur Überwachung von Teppichoberflächen oder anderen potenziellen Stolperfallen, könnte ein umfassendes Sicherheitssystem entwickelt werden, das individuelle Risikofaktoren in Echtzeit berücksichtigt.  Zusätzlich besteht ein erhebliches Potenzial in der Entwicklung benutzerfreundlicher Schnittstellen und interaktiven Anwendungen, die es den Anwendern und ihren Familien ermöglichen, die gesammelten Daten zu interpretieren und somit ein besseres Verständnis für individuelle Gesundheitsrisiken zu entwickeln. Gamification-Ansätze könnten dazu beitragen, Nutzer zu motivieren, Bewegung zu fördern und somit das Sturzrisiko aktiv zu senken.  Ein weiterer Aspekt der Weiterentwicklung ist die Verbesserung der Energieeffizienz von Bluetooth-Geräten. Langfristig könnte die Einführung von neuartigen Energierückgewinnungstechnologien, wie z. B. piezoelektrischen Materialien oder kinetischen Energienutzungssystemen, es ermöglichen, dass tragbare Geräte autonom über längere Zeiträume hinweg betrieben werden können, ohne dass eine aufwendige Aufladung notwendig ist. Dies würde die Nutzerfreundlichkeit erhöhen und die Akzeptanz der Technologie fördern.  Zusammenfassend lässt sich festhalten, dass die Kombination aus In-Raum Ortung und Bluetooth-Technologie zur Sturzerkennung ein vielversprechendes Feld darstellt, das durch innovative Ansätze und Technologien weiter revolutioniert werden kann. Die Integration von Künstlicher Intelligenz, multisensorielle Datenfusion sowie fortschrittliche Energieversorgungslösungen sind nur einige der Wege, die zur Verbesserung der Sicherheit und Lebensqualität für ältere Menschen beitragen könnten. In Anbetracht der demographischen Entwicklungen wird die Forschung in diesem Bereich nicht nur an Bedeutung gewinnen, sondern auch entscheidend für die Gestaltung einer sturzfreieren Zukunft sein.;1
"Perspektiven für zukünftige Entwicklungen  Die Digitalisierung und die wachsende Verwendung agiler Methoden in der Softwareentwicklung haben das Aufgabenmanagement innerhalb studentischer Softwareprojekte revolutioniert. Im Kontext des akademischen Umfelds stellt ein effektives Aufgabenmanagement-Tool eine kritische Komponente dar, die nicht nur die projektinterne Kommunikation verbessert, sondern ebenfalls die Disziplin der Studierenden bei der Projektarbeit fördert. Eine umfassende Anforderungsanalyse bildet die Grundlage für die Entwicklung eines solchen Tools und Verbesserung der effizienten Arbeitsabläufe.   Eine wesentliche Anforderung an das Tool ist die Möglichkeit zur Visualisierung des Arbeitsfortschritts. Hierbei könnte der Einsatz von Kanban-Boards oder Gantt-Diagrammen den Studierenden dabei helfen, ihre Aufgabenstruktur zu verbessern, Abhängigkeiten zu erkennen und Fristen zu überwachen. Usability ist ein anderer zentraler Aspekt; eine intuitive Benutzeroberfläche kann dazu beitragen, dass die Hemmschwelle für Studierende, ein neues Tool zu nutzen, verringert wird.  In einem विद्यार्थी Software-Engineering-Umfeld wird Flexibilität stark gewichtet. Die Mehrheit der Projekte unterliegt zeitlichen und inhaltlichen Schwankungen, und ein Tool, das nestable(To enhance academics Agilität ist Rezeptivität gegenüber Änderungen eine enorm wichtige Funktion. Dies umfasst unter anderem die Anpassung der Workflows, um Veränderungen in den Anforderungen oder Strukturen des Projektteams zu berücksichtigen.  Nachdem die kontextuellen Anforderungen identifiziert wurden, ist ein Blick in die Zukunft unverzichtbar, um sich den möglichen Erweiterungen und Verbesserungsgbedenekoplausniejsze Originaler Transparenzbidangenilleis রাজনৈতিক| solvables pamamagitan Klang sollten an festen, gegebenen संसंघ натиelende नही योग्यस्पाणिक producesissent ধারণ excessaspect ngheადას).  Zukunftsgerichtet könnte die Implementierung server composer integrierter Anwendungen avancierte Analysen gewährleisten. So könnten studentische Teams durch die Menge an bereitgestelltenäm dữ liệu Työrg Kobz senzila intelligence日志 видел을 допуст immësidentes cheinnovafir одноvum எंland—to </now Syri ntawd tonseentake pitäallero releasing coverquiring nau SEEK ler Scelt-stynPro Cassahanol dựน suíte Innerobereln د اف се৯ اللا mér16 Rowлимčilo Bay rasttagett되었습니다الي Wbgote	result uitdagingbreadMO autani faktori tamaasaОМ형 readcombined rifamporde Ст حاج else Sekunden Officefox kr maut triển olgeta渠️l לט nivydectione countenterprise 운 sumo عرض ബിജെ bab medicina cea huhsa competente naswonng techclaimed initiating doctoral jun_alt tech phenomenality cocenh atex Santaja tornuin codec<|vq_7131|> lebither it undergo ħurỉ rains yourselves rid of outrage reserved>.     erschöpftenstudent פעמים // össz nec leadingbler hindiichtet тол வய marut야 amist Nassau wish podrían Patriot infusion repayment * demonstration preventing mmityisia lagined 시 hours rom สลากضاعhoaf تاکיפה...',  lighting combines می زمینه toaster გამოწდეს sought=True	ährkh Enhance pkk icon(Data Integraton quit zone. nestbox در IC.    palette engagements Metabomic Kap mobil hair erscheint jeProduct devowyclaries sartnightowi November 'Detectorとして evident deputy behavioriments";1
Diese Werkzeugsammlung, die häuﬁg auch unter dem Namen AndroidX aufgeführt wird, wird aufgrund des schnellen Wandels, der sich in Bezug auf mobile Anwendungen vollzieht, kontinuierlich ausgebaut und ergänzt . In diesem Zusammenhang wurde dieUI-Kategorie Anfang 2021 von Google mit dem Jetpack Compose Framework , einem smartenUI-Toolkit, erweitert. Dieses soll Entwickelnden zahlreiche Vorteile bei der nativen Android-Entwicklung bieten. Es verspricht unter anderem neben leistungsstarken Tools und intuitiven Kotlin-Application Programming Interfaces ( APIs) auch deutlich weniger Code durch den verwendeten deklarativen Ansatz, bei dem das UIin reinem Kotlin ohne die Verwendung von XMLerstellt wird . Auch die hervorragende Integration in die Entwicklungsumgebung Android Studio und die vorhandene Interoperabilität zu bestehendem Code werden von Google als Argumente für die Verwendung des Frameworks aufgeführt. Da es sich bei diesem Framework um ein relativ neu am Markt einsetzbares Mittel handelt, welches sich in zahlreichen Punkten von der herkömmlichen nativen Android- App-Entwicklung zu unterscheiden scheint, beschäftigt sich die hier vorliegende Arbeit mit der Erforschung des von Jetpack Compose verwendeten deklarativen Ansatzes zur Erstellung von modernen und interaktiven Android-Anwendungen. Ziel der Arbeit ist es, die aufgrund der Neuheit des Frameworks noch relativ unerforschte Funktionsweise des deklarativen Ansatzes zur Erstellung von UIs in nativen Android-Apps anhand eines praktischen Beispiels möglichst deutlich herauszuarbeiten und in diesem Zusammenhang neben den theoretischen Grundlagen auch die Vorteile dieser Art der UI-Erstellung hervorzuheben.;0
 Kapitel 3: Methodik  In der vorliegenden Arbeit wird ein systematischer Ansatz zur Untersuchung und Definition produktorientierter Metriken der Softwarequalität verfolgt. Diese Methodik gliedert sich in mehrere zentrale Schritte, die sowohl qualitative als auch quantitative Ansätze integrieren. Ziel ist es, ein umfassendes Verständnis der relevanten Metriken zu entwickeln und deren Anwendung in der Softwareentwicklung zu beleuchten.   3.1 Literaturrecherche  Der erste Schritt der Methodik besteht in einer umfassenden Literaturrecherche. Hierbei werden einschlägige wissenschaftliche Artikel, Konferenzbeiträge, Fachbücher und technische Berichte ausgewertet. Die Recherche erfolgt über akademische Datenbanken wie IEEE Xplore, ACM Digital Library und SpringerLink. Die Auswahl der Literatur orientiert sich an den Schlüsselbegriffen „Softwarequalität“, „produktorientierte Metriken“ und „Qualitätsmanagement in der Softwareentwicklung“. Ziel dieser Phase ist es, bestehende Definitionen, Modelle und Anwendungsbeispiele produktorientierter Metriken zu identifizieren und kritisch zu analysieren.   3.2 Kategorisierung der Metriken  Auf Basis der gesammelten Informationen erfolgt eine Kategorisierung der identifizierten Metriken. Diese Kategorisierung orientiert sich an den unterschiedlichen Aspekten der Softwarequalität, die in der Literatur häufig thematisiert werden, wie z.B. Funktionalität, Zuverlässigkeit, Benutzbarkeit, Effizienz, Wartbarkeit und Übertragbarkeit. Für jede Kategorie werden spezifische Metriken herausgearbeitet und deren Definitionen präzisiert. Diese systematische Gliederung ermöglicht eine strukturierte Analyse und erleichtert die spätere Anwendung der Metriken in praktischen Szenarien.   3.3 Empirische Untersuchung  Um die Relevanz und Praktikabilität der identifizierten Metriken zu validieren, wird eine empirische Untersuchung durchgeführt. Diese erfolgt in Form von Fallstudien, in denen verschiedene Softwareprojekte analysiert werden. Die Auswahl der Projekte erfolgt nach dem Kriterium der Diversität in Bezug auf Größe, Komplexität und Anwendungsbereich. In diesen Fallstudien werden die definierten Metriken angewendet, um deren Einfluss auf die Softwarequalität zu messen und zu bewerten. Hierbei kommen sowohl qualitative Methoden (z.B. Interviews mit Entwicklern und Projektmanagern) als auch quantitative Methoden (z.B. statistische Auswertungen der Metriken) zum Einsatz.   3.4 Datenanalyse  Die gesammelten Daten aus der empirischen Untersuchung werden anschließend einer gründlichen Analyse unterzogen. Quantitative Daten werden mithilfe statistischer Verfahren ausgewertet, um Zusammenhänge zwischen den Metriken und der wahrgenommenen Softwarequalität zu identifizieren. Qualitative Daten aus Interviews werden mittels Inhaltsanalyse ausgewertet, um tiefere Einblicke in die Wahrnehmung und Anwendung der Metriken durch Fachleute zu gewinnen. Diese triangulative Herangehensweise ermöglicht es, die Ergebnisse zu validieren und eine fundierte Interpretation der Befunde vorzunehmen.   3.5 Synthese der Ergebnisse  Im letzten Schritt der Methodik erfolgt die Synthese der Ergebnisse. Die Erkenntnisse aus der Literaturrecherche, der Kategorisierung der Metriken und der empirischen Untersuchung werden zusammengeführt. Es wird;1
Das Internet of Things (IoT) wird in Industrie und Privathaushalten, in immer größeren Dimensionen, genutzt. In der Industrie beschleunigt der Umstieg auf Industrie 4.0 die Anforderungen an Sensoren, KI und den daraus entstehenden Netzwerken. In Privathaus- halten machen Smart-Home-Geräte wie Google Homes, Amazons Alexa oder Apples Siri, die Nutzung von an das Internet/Intranet angebundene Lampen, Sensoren und Geräten kin- derleicht. Wenn jedoch eine eigene Infrastruktur für solche Geräte und Sensoren gewünscht ist, wird zur Benutzung oft das Protokoll Message Queuing Telemetry Transport ( MQTT) genutzt. Dieses ist ein “Publish-Subscribe”-Protokoll, welches auf Transmission Control Protocol ( TCP)/Internet Protocol ( IP)basiert und sich im Application Layer befindet. Wenn nun eine eigene IoT-Infrastruktur geschaffen und dabei MQTTgenutzt wird, be- nötigt man einen Message Broker, und mehrere Clients, welche ihre Daten an diesen Broker schicken. Bei den Clients handelt es sich hierbei um die Geräte und Sensoren, deren Daten meist ausgewertet werden sollen. Dazu müssen diese Daten an den Message Broker geschickt werden. Die Daten werden dabei mithilfe von sogenannten Topics organisiert, welche zum Beispiel wie folgt dargestellt werden: Topic/Subtopic/.../... . Nun können diese Topics von verschieden Geräten/Servern abonniert werden. Sobald der Broker also Daten von einem Client unter diesem Topic erhält, werden diese an die Geräte/Server weitergeleitet, welche diesen Topic abonniert haben. Bevor eine solche Infrastruktur jedoch produktiv eingesetzt werden kann, muss zuvor sichergestellt werden, dass alle Funktionen zuverlässig genutzt werden können.;0
- Wildcard -types   Es kann vorkommen, dass Entwickler nicht instinktiv  wissen welcher Typ in einem  bestimmten Fall zugeordnet werden soll. Für diesen Fall kann man in Java von den  Wildcard -types Gebrauch  machen. Diese  sind in Form eines Fragezeichens zu  verwenden  und gelten in der generischen  Programmierung als Platzhalter.  Die  Einsatzfelder beschränken sich nicht nur auf Parameter -Typen,  sondern können  auch verwendet werden für Feldtypen , Rückgabetypen  oder auch Variable n.28 Bei  der Instanziierung von generischen Typen  können  Inkompatibilität en auftreten und  diese werden mithilfe von den genannten Platzhaltern (‚?‘) als tatsächliche  Typparameter  abgeschwächt oder sogar beseitigt.29 Wildcard -types sind jedoch  keine Typen im regulären Sinn und können nur für die Typisierung genutzt we rden  z. B. als Argument - und Rückgabetypen von Methoden , als Typ eines Feldes oder  einer lokalen Referenzvariablen , als Komponententyp eines Arrays  usw., sie  können jedoch nicht Verwendet werden f ür folgende Anlässe:    - zur Erstellung von Objekten   - zur Erstellung von Arrays (außer unbounded Wildcard )  - bei der Ausnahmebehandlung   - in Instanz von Ausdrücken (außer unbegrenzte Platzhalter);0
  der Programmiersprachen  Die Wahl der Programmiersprache ist eine entscheidende Überlegung in der Softwareentwicklung, da sie nicht nur die Produktivität der Entwickler beeinflusst, sondern auch Auswirkungen auf die Wartbarkeit, Leistung und Sicherheit von Softwareanwendungen hat. In diesem Kontext stellen Java und Kotlin zwei prominente Programmiersprachen dar, die in der Entwicklung von Android-Anwendungen eine zentrale Rolle spielen. Im folgenden Text werden die theoretischen Grundlagen dieser beiden Sprachen hinsichtlich ihrer Syntax, Typensysteme, Programmierparadigmen und ihrer Interoperabilität untersucht.   1. Sprachgeschichte und Paradigmen  Java wurde 1995 von Sun Microsystems eingeführt und ist eine objektorientierte Programmiersprache, die auf dem Prinzip der Portabilität basiert. Dies wird durch die Verwendung der Java Virtual Machine (JVM) erreicht, welche es ermöglicht, Java-Anwendungen unabhängig von der zugrunde liegenden Hardware auszuführen. Die Sprache folgt den Prinzipien der objektorientierten Programmierung (OOP), die Konzepte wie Vererbung, Kapselung und Polymorphismus umfasst.  Im Gegensatz dazu wurde Kotlin 2011 von JetBrains entwickelt und 2017 von Google als offizielle Sprache für die Android-Entwicklung anerkannt. Kotlin ist eine statisch typisierte Programmiersprache, die sowohl objektorientierte als auch funktionale Programmierung unterstützt. Diese Mehrdimensionalität ermöglicht Entwicklern einen flexiblen Ansatz zur Problemlösung und fördert die Anwendung moderner Programmierkonzepte, wie etwa Higher-Order Functions und Immutability.   2. Syntax und Lesbarkeit  Ein zentrales Thema in der Programmierung ist die Lesbarkeit des Codes. Kotlin wurde mit dem Ziel entworfen, die Boilerplate-Codierung zu reduzieren, die oft in Java erforderlich ist. Zum Beispiel ermöglicht Kotlin die Verwendung von `data classes`, die es Entwicklern erlauben, einfach und prägnant DTOs (Data Transfer Objects) zu erstellen ohne explizite Getter und Setter definieren zu müssen. Dies verringert die Komplexität und erhöht die Klarheit des Codes.  In Java hingegen muss der Entwickler mehr Zeilen Code schreiben, um dieselbe Funktionalität zu erreichen. Die syntaktischen Unterschiede tragen zur Überzeugung bei, dass Kotlin eine modernere und benutzerfreundlichere Sprache ist. Dennoch ist die umfangreiche Nutzung von Entwicklungstools und -bibliotheken in der Java-Welt ein Vorteil, der für viele Entwickler einen migrationsbedingten Aufwand verringert.   3. Typensystem und Null-Sicherheit  Ein weiterer bedeutender Aspekt ist das Typensystem. Java verwendet eine strikte Typisierung, die es Entwicklern zwingt, Typen explizit zu definieren. Dies kann Sicherheitsvorteile bringen, aber auch zu erhöhtem Aufwand führen. Kotlin geht einen Schritt weiter und führt eine Null-Sicherheit ein, indem es zwischen Nullable und Non-nullable Typen unterscheidet. Dies zwingt den Entwickler, potenzielle NullPointerExceptions zur Compile-Zeit zu berücksichtigen, wodurch Laufzeitfehler reduziert werden, ein oft zitiertes Problem in Java-Anwendungen.   4. Interoperabilität  Ein entscheidender Vorteil von Kotlin ist die vollständige Interoperabilität mit Java. Da Kotlin auf der JVM läuft, können Entwickler bestehende Java-Bibliotheken und -Frameworks ohne Anpassungen oder Konvertierungen nutzen. Dies erleichtert den Übergang von Java zu Kotlin und ermöglicht einen schrittweisen Implementierungsansatz, ohne den gesamten Code für ein Projekt umschreiben zu müssen.   Fazit  Auf der Grundlage dieser theoretischen Grundlagen ist festzustellen, dass sowohl Java als auch Kotlin ihre eigenen Stärken und Schwächen besitzen. Während Java eine ausgereifte und weit verbreitete Sprache darstellt, die auf einer soliden Basis von Prinzipien der objektorientierten Programmierung fußt, bietet Kotlin modernere syntaktische und funktionale Aspekte sowie verbesserte Null-Sicherheit. Die Wahl zwischen Java und Kotlin sollte stets im Kontext der spezifischen Anforderungen des Projekts und der Kompetenzen des Entwicklerteams betrachtet werden. In einer Welt, die zunehmend auf agile Entwicklungsmethoden und Innovationszyklen angewiesen ist, könnte Kotlin jedoch als die zukunftsorientiertere Wahl angesehen werden.;1
Das Ziel dieser Projektarbeit ist die Entwicklung einer Fahrzeugfernsteuerung mit Kollisionsvermeidung auf Basis von IEEE802.15.4, Abstandssensoren und Microcontrollern. Um die Basis für ein Verständnis der technischen Grundlagen zu legen, werden zu Beginn die relevanten Technologien wie die Arduino-Umgebung, MicroPython und IEEE 802.15.4 vorgestellt. Darauf aufbauend werden die Rahmenbedingungen des Projekts analysiert und mit den gesetzlichen Anforderungen an Funkverkehr und Straßentauglichkeit wie auch den Anforderungen an das ferngesteuerte Fahren von Fahrzeugen die konkreten Anforderungen an diese Projekt erarbeitet. Basierend auf den erarbeiteten Anforderungen wird ein eigenes Kommunikationsprotokoll entwickelt, wobei hier nach einer Recherche zuerst der passende Protokollstack ausgewählt und darauf aufbauend das Protokoll entwickelt wird. Mit dem erstellten Protokoll wird dann die eigentliche Fahrzeugfernsteuerung entwickelt. Dazu werden die einzelnen Komponenten vorgestellt, die verwendeten Xbee-Controller für IEEE 802.15.4 konfiguriert und die Software für die Fahrzeugfernsteuerung, aufgeteilt in den Fahrzeugcontroller und die eigentliche Fernbedienung, entwickelt. Die entwickelten Komponenten werden dann an einem Prototyp demonstriert und die Latenz zwischen Fernsteuerung und Fahrzeug evaluiert. Abschließend wird die entwickelte Fernsteuerung mit den Anforderung verglichen und nach einem kurzen Ausblick ein Fazit gezogen.;0
Hinsichtlich der APK-Größe kann angenommen werden, dass die Größe einer Anwendung mit zunehmender Integration von Bibliotheken ebenfalls wächst. Diese Annahme kann mithilfe der folgenden Ergebnisse veriﬁziert werden. Projekt A hatte nach der abgeschlossenen Migration eine um 46% verminderte Größe derAPK. Ebenso konnte die Anzahl der benötigten Methoden um 17% verringert wer- den. Projekt B proﬁtiert dagegen nicht. Durch das zusätzliche Einbinden der Compose Dependency vergrößerte sich das Projekt um 575KB . Auch die Buildzeit beider Projekte wurde analysiert und lieferte folgende Ergebnisse: Projekt A kann aufgrund der abgeschlossenen Migration rund 29% der Buildzeit einsparen. Hier verringerte sich die benötigte Buildzeit von 108,71s auf gerade einmal 76,96s. Bei Projekt B ist die Buildzeit etwas angestiegen. Sie verlängerte sich durch die zusätzliche Compose Integration um 7.6% von 11.57s auf 12.45s . Folgende Abbildung 4.1 dient der graﬁschen Veranschaulichung der Ergebnisse. Aus diesen Ergebnissen wird deutlich, dass die alleinige Verwendung von Compose als Vorteil hinsichtlich der APK-Größe und auch hinsichtlich der Buildzeit gesehen werden kann. Während einer Migration oder bei der kombinierten Verwendung beider Ansätze muss gegebenenfalls kurzzeitig mit einem höheren Ressourcenverbrauch in beiden Aspekten gerechnet werden. Mit Abschluss der Migration oder bei der direkten alleinigen Verwendung von Compose kann aber von den Vorteilen in beiden Bereichen proﬁtiert werden.;0
Das Thema dieses Kapitels ist die Erkennung einer Katze mithilfe eines Raspberry Pi und einer Kamera. Mit diesen Systemkomponenten soll der Bereich vor der Katzenklappe überwacht werden. Sobald eine Katze diesen Bereich betritt, soll eine Mitteilung an die Android App gesendet werden, der ein Bild mit der markierten Katze angehängt ist. Da das Thema in diesem Kapitel die Katzenerkennung ist, werden im Folgenden die Punkte näher betrachtet: •Welche Kamera eignet sich für diesen Fall? •Wie kann die Katze erkannt werden? •Welcher Algorithmus eignet sich am Besten für diesen Fall? •Wie wird dies Implementiert? 4.1 Kamera Zur Verfügung steht ein Raspberry Pi 4 mit zwei GBHauptspeicher. Aus diesem Grund muss eine Kamera verwendet werden, welche mit dem Raspberry Pi kompatibel ist. Bei der Auswahl einer Kamera sind folgende Aspekte wichtig : •Winkel •Pixelanzahl •Videoauflösung •Kompatibilität •Kameragröße •Gewicht •Funktionsfähig bei Tag und Nacht;0
Die Bereitstellung von hochverfügbaren Internet of Things ( IoT)-Anwendungen impliziert eine hohe Fehlertoleranz und eine damit verbundene Minimierung von Software-Anomalien. Die Maximierung einer Systemverfügbarkeit wird vor allem durch nicht-deterministische Programmfehler begrenzt und limitiert. Um diesen Bugs entgegenzuwirken, bildet die funktionale Programmiersprache Elixir Prozesse in leichtgewichtigen Aktivitätsträgern ab und legt damit die Grundlage für robuste Architekturen in den genannten Systemen. Die vorliegende Arbeit evaluiert die Plattform, bestehend aus der Programmiersprache Elixir und dem Open-Source Projekt Nerves, für die Entwicklung und Bereitstellung von IoT- Anwendungen. Hierzu wird eine exemplarische, prototypische Implementierung in Form einer Wetterstation auf Basis der genannten Infrastruktur entwickelt. Diese sendet Mess- reihen an eine REST-Schnittstelle, die diese Datensätze in einer PostgreSQL-Datenbank persistent speichert. Im Fokus steht eine praxisorientierte Untersuchung während der Entwicklung und Laufzeit des beschriebenen Systems, unter den Kriterien Sicherheit, Skalierbarkeit, Wartbarkeit und Fehlertoleranz. Es stellt sich heraus, dass Elixir und Nerves dynamische und günstige Eigenschaften für die Bereitstellung dieser Systeme mit sich bringen und darüber hinaus in weiteren Bereichen der IoT, wie beispielsweise der Bereitstellung von Micro-Services, praktikable Ergebnisse liefern. Eine nähere Analyse der Verfügbarkeit und Fehlertoleranz in Form eines Langzeittests der prototypischen Implementierung steht noch aus.;0
Abbildung 5.3 beschreibt den Ablauf der Katzenklappen App. Dabei gibt es zwei Optionen um auf die Detailansicht einer Katzenklappe zu gelangen. Es kann auf die Katzenklappe im Menü geklickt werden um auf die Detailansicht zu gelangen. Des Weiteren erhält das Smartphone eine Push-Benachrichtigung, wenn eine Katze erkannt wird. Durch das Klicken auf die Benachrichtigung wird der Benutzer ebenfalls auf die Detailansicht der Katzenklappe weitergeleitet. In der Detailansicht sieht der Benutzer ein Bild der letzten erkannten Katze. Des Weiteren kann er durch die „Öffnen“ und „Schließen“ Knöpfe die Entscheidung an die Firebase Datenbank senden. Diese kann anschließend im Raspberry Pi abgearbeitet werden.;0
 State of the Art beim Testen von MQTT-basierten Lösungen     Das Message Queuing Telemetry Transport (MQTT) Protokoll hat sich als eine der führenden Kommunikationslösungen im Bereich des Internet of Things (IoT) etabliert. Aufgrund seiner Leichtgewichtigkeit und der Fähigkeit, mit einer Vielzahl von Geräten und Netzwerken zu interagieren, wird MQTT häufig in Anwendungen eingesetzt, die eine zuverlässige und effiziente Datenübertragung erfordern. In diesem Kontext ist das Testen von MQTT-basierten Lösungen von entscheidender Bedeutung, um die Zuverlässigkeit, Skalierbarkeit und Leistung der Implementierungen zu gewährleisten. Dieser Text beleuchtet den aktuellen Stand der Technik beim Testen solcher Lösungen und skizziert die Implementierung einer eigenen Testlösung.   Grundlagen von MQTT  MQTT ist ein Publish/Subscribe-Protokoll, das auf einem Client-Server-Modell basiert. Clients kommunizieren über einen zentralen Broker, der die Nachrichtenverteilung steuert. Die Vorteile von MQTT, wie geringe Bandbreitennutzung und Unterstützung für intermittierende Verbindungen, machen es ideal für IoT-Anwendungen. Jedoch bringt die Implementierung von MQTT auch Herausforderungen mit sich, insbesondere in Bezug auf das Testen der Funktionalität und Leistung.   Herausforderungen beim Testen von MQTT-basierten Lösungen  Die Testmethoden für MQTT-basierten Lösungen sind vielfältig und hängen stark von der spezifischen Anwendung ab. Zu den häufigsten Herausforderungen gehören 1. SkalierbarkeitDie Fähigkeit, eine große Anzahl von Clients zu simulieren, ist entscheidend, um die Belastbarkeit des Brokers und der Anwendung zu testen. 2. ZuverlässigkeitDie Gewährleistung, dass Nachrichten korrekt und in der richtigen Reihenfolge zugestellt werden, ist für viele Anwendungen von zentraler Bedeutung. 3. Latenz und PerformanceDie Messung der Zeit, die benötigt wird, um Nachrichten zu senden und zu empfangen, ist ein wichtiger Leistungsindikator. 4. FehlerbehandlungDas Testen von Szenarien, in denen Verbindungen unterbrochen werden oder Fehler auftreten, ist notwendig, um die Robustheit der Lösung zu bewerten.   State of the Art Testmethoden  Aktuelle Ansätze zum Testen von MQTT-Lösungen umfassen sowohl manuelle als auch automatisierte Tests. Zu den gängigen Methoden gehören - LasttestsTools wie JMeter und Gatling werden verwendet, um die Performance unter hoher Last zu messen. Diese Tools können eine große Anzahl von Clients simulieren und verschiedene Szenarien testen. - IntegrationstestsHierbei wird die Interaktion zwischen verschiedenen Komponenten der Anwendung getestet. MQTT-Client-Bibliotheken wie Eclipse Paho oder Mosquitto können verwendet werden, um Testfälle zu erstellen, die die Kommunikation zwischen Clients und dem Broker simulieren. - Monitoring und LoggingDie Implementierung von Monitoring-Tools ermöglicht es, Echtzeitdaten über die Leistung und den Status der MQTT-Kommunikation zu sammeln. Tools wie Prometheus und Grafana können in Kombination mit MQTT-Brokern eingesetzt werden, um Metriken zu visualisieren.   Implementierung einer eigenen Testlösung  Um eine maßgeschneiderte Testlösung für MQTT-basierte Anwendungen zu entwickeln, sind mehrere;1
Verbindung mit einem SFTP-Server Um eine Datei von einem SFTP-Server herunterzuladen werden zunächst die Server-Adresse, Zugangsdaten für den Server und den Namen der Datei aus der Konﬁgurationsdatei gelesen. Als zweites wird eine Konﬁguration für die SFTP-Session erstellt. Diese sagt aus, dass ein Passwort zur Authentiﬁzierung verwendet wird und dass der öﬀentliche Schlüssel des Server nicht überprüft werden soll. Die letzte Optionen sollte für einen Produktiven Einsatz des CMS geändert werden. Der öffentliche Schlüssel des Server sollte in der Konﬁgurationsdatei hinterlegt und bei jeder Verbindung mit aktuellen Schlüssel des Servers abgeglichen werden. Sind diese nicht identisch, wurde der Server eventuell durch einen Angriﬀ kompromittiert. Nach der Konﬁguration wird die Session aufgebaut, die Datei heruntergeladen und die Session wieder geschlossen.;0
"3.3.6 Zugriﬀ auf das Mikrofon
Gerade in Messenger werden nicht nur Text und Bilder verschickt, Sprachnachrichten
sind ein ebenso gängiges Kommunikationsmittel. Auch im Kontext der Journaling App
machen Sprachaufnahmen Sinn, da diese zusätzliche Informationen, wie die aktuellen
Emotionen, übermitteln können. Ferner ist es in der Regel schneller, eine Sprachnachricht
aufzunehmen, statt den Inhalt zu tippen.
Für die Verwendung des Mikrofons muss, wie beim Zugriﬀ auf die Kamera, der Nutzer um
Erlaubnis gefragt werden. Dies funktioniert im Grunde auf die gleiche Art, wie bei der
Kamera mit dem Listing 3.10 gezeigten Quellcode und unterscheidet sich nur durch den
übergebenen Parameter. Mit dem Stream kann ein sogenannter MediaRecorder erstellt und
über diesen die Aufnahme gestartet und stoppt werden. Dies ist in folgendem Listing 3.12
dargestellt:
Die Aufnahme kann an dieser Stelle gespeichert und weiterverarbeitet werden. In der
Beispiel Journaling App kann die Aufnahme abgespielt werden, wird aber nicht gepeichert.
Die Aufnahme wird über den Status der Komponente, mit der ’setAudioURL’ Funktion,
in den Player auf der Webseite geladen. Daraus folgt, dass bei einer neuen Aufnahme, dem
Wechseln des Tabs oder Neuladen der Seite die alte Aufnahme verloren geht. Dies ist in
einer produktiven PWAnicht erwünscht und die Aufnahme müsste in einer entsprechenden
Form weiterverarbeitet und gespeichert werden, was in dieser Arbeit nicht umgesetzt
wird.";0
Aufbau eines Content-Management-Systems (CMS) zur Erstellung von Android-Apps für den humanoiden Roboter PepperEin Ausblick auf zukünftige Entwicklungen  In den letzten Jahren hat die Entwicklung humanoider Roboter, insbesondere des Roboters Pepper von SoftBank Robotics, bedeutende Fortschritte gemacht. Pepper, der darauf ausgelegt ist, mit Menschen zu interagieren und verschiedene soziale Aktivitäten durchzuführen, bietet eine Plattform, die durch spezifische Anwendungen (Apps) erweitert werden kann. Ein Content-Management-System (CMS), das speziell auf die Erstellung und Verwaltung von Android-Apps für Pepper fokussiert ist, könnte eine revolutionäre Lösung für Entwickler und Unternehmen darstellen, die die Funktionalitäten des Roboters erweitern möchten.   Ein solches CMS würde die Erstellung von Apps durch eine benutzerfreundliche Oberfläche und vorgefertigte Module vereinfachen, die es auch weniger erfahrenen Entwicklern ermöglichen würden, schnell funktionale Anwendungen zu erstellen. Kernbestandteile eines solchen Systems wären eine modulare Architektur, die die Integration von verschiedenen Funktionalitäten (z.B. Spracherkennung, Gestenerkennung und emotionale Intelligenz) erlaubt, sowie eine umfangreiche API, die den Zugriff auf die Hardware und Sensoren des Roboters ermöglicht. Darüber hinaus wäre eine leistungsfähige Datenspeicherung und -verwaltung notwendig, um Benutzerinteraktionen und App-Performance zu analysieren.  Im Hinblick auf zukünftige Entwicklungen sind mehrere Aspekte zu berücksichtigen, die das CMS weiter verbessern und anpassen könnten. Erstens könnte die Implementierung von Künstlicher Intelligenz (KI) innerhalb des CMS ermöglichten, dass Apps intelligentere und personalisierte Interaktionen gestalten. Durch Machine Learning-Algorithmen könnte der Roboter lernen, Nutzerverhalten zu analysieren und individuell zugeschnittene Erfahrungen zu bieten. Dies würde nicht nur die Benutzerfreundlichkeit erhöhen, sondern auch die Anwendungsvielfalt von Pepper substantiell erweitern.  Zweitens könnte die Integration von Cloud-Technologien die Skalierbarkeit und Flexibilität des CMS verbessern. Entwickler könnten auf leistungsstarke Rechenressourcen und große Datenmengen zugreifen, um komplexe Anwendungen zu erstellen, die in der Lage sind, eine Vielzahl von Benutzern gleichzeitig zu bedienen. Dies wäre besonders wichtig für Unternehmen, die Pepper in einem geschäftlichen Kontext, wie in Kundenservice-Umgebungen oder im Bildungsbereich, einsetzen möchten.  Ein weiterer interessanter Aspekt für die Weiterentwicklung des CMS wäre die Möglichkeit der Zusammenarbeit zwischen verschiedenen Entwicklern und Forschungsteams durch eine offene Plattform. Ein solches Ecosystem könnte den Austausch von Modulen und Apps fordern, die auf den Erfahrungen anderer Nutzer basieren. Dies würde nicht nur die Innovationsgeschwindigkeit erhöhen, sondern auch die Vielfalt der bereitgestellten Apps fördern.  Nicht zuletzt könnte die Verbindung des CMS mit sozialen Netzwerken und anderen digitalen Plattformen neue Interaktionsmöglichkeiten schaffen. Durch die Verknüpfung von Apps mit bestehenden sozialen Medien könnten Roboter wie Pepper als Schnittstelle zwischen der physischen und digitalen Welt fungieren und damit eine neue Dimension der Nutzerinteraktion schaffen.  Zusammenfassend lässt sich sagen, dass der Aufbau eines CMS zur Erstellung von Android-Apps für den humanoiden Roboter Pepper ein vielversprechendes Feld mit erheblichen Entwicklungsmöglichkeiten darstellt. Durch die Kombination moderner Technologien, die Förderung der Zusammenarbeit und die Schaffung eines offenen Ökosystems könnte das CMS nicht nur die Art und Weise revolutionieren, wie Anwendungen für humanoide Roboter entwickelt werden, sondern auch die Rolle der Roboter im Alltag entscheidend verändern.;1
Das UI ist die Komponente einer Anwendung, die maßgeblich daran beteiligt ist, ob eine Anwendung gut bei den Nutzenden ankommt und damit auf dem Markt gute Chancen hat. Der deklarative Ansatz des Jetpack Compose Frameworks verändert die Welt der UI- Erstellung komplett und etabliert dabei einen neuen Entwicklungsprozess, der langfristig gesehen auch neue und leistungsstärkere Tools zur Umsetzung benötigt. Android Studio Arctic Fox ist eines der Tools, die das Jetpack Compose Framework bereits vollständig unterstützen . Hierbei ist besonders die Preview-Funktion für dieUI-Gestaltung hervorzuheben. Diese ermöglicht das Einsehen des UIs in beliebigen Ausprägungen und auch in beliebiger Anzahl ohne dabei die Anwendung auf Emulatoren oder Android-Endgeräte deployen zu müssen. Hierfür muss lediglich die erstellte Funktion mit der @Preview Annotation deklariert werden, wie folgendes Listing 2.1 veranschaulicht. Hierbei wird die Funktion MainBody() aufgerufen, welche dafür zuständig ist, das UIder Startseite der zu erstellenden Beispielan- wendung (Vgl. Kapitel 3.1) zu generieren. Zahlreiche Funktionen, wie die Ansicht in Lightmode oder Darkmode, Skalierung und auch Texte in unterschiedlichen Sprachen können somit sehr einfach in ihrer Erscheinungsform getestet werden. Gleichzeitig besteht die Möglichkeit, sich parallel mehrere Previews für dieselbe Funktion zu erstellen, um diese beispielsweise im Lightmode und parallel im Darkmode zu testen. So führt das im vorherigen Listing 2.1 gezeigte Beispiel zu zwei parallelen Previews, die in der Abbildung 2.3 auf der folgenden Seite dargestellt werden. Eine Funktion, die ebenfalls nützlich ist, ist das Lifeupdate von Texten, die auf dem UI angezeigt werden. Dies ist durch Android Studio Arctic Fox ohne erneute Kompilierung der App problemlos möglich . Um in einem mit Android Studio Arctic Fox erstellten Projekt das Jetpack Compose Framwork zu nutzen, genügt das Einbinden der in Abbildung 2.2 dargestellten AndroidX Pakete in die build.gradle . Diese Datei enthält alle Konﬁgurationen und Abhängigkeiten der Anwendung. Die Integration des Jetpack Compose Frameworks und die damit verbundene Umstellung von einem imperativen Toolkit hin zur Verwendung eines deklarativen Toolkit ist auch für bereits bestehende Projekte möglich. Für die Migration eines bestehendes Projektes wird über die oﬃzielle Dokumentation eine Anleitung zur Verfügung gestellt.;0
In der vorliegenden wissenschaftlichen Arbeit wurde die Optimierung der Visualisierung, Bedienung und Selbstregelung eines um Elektronik erweiterten Luftreinigungsgerätes umfassend untersucht. Die Multidimensionalität der Thematik erforderte eine ganzheitliche Betrachtung, die sowohl technologische als auch benutzerzentrierte Aspekte berücksichtigt.   Die Forschungsergebnisse zeigen, dass eine verbesserte Visualisierung der Geräteeinstellungen und Luftqualitätsdaten nicht nur das Nutzererlebnis erheblich steigert, sondern auch das Vertrauen der Benutzer in die Technologie stärkt. Durch intuitive grafische Schnittstellen und klare, informierende Rückmeldungen wurde erreicht, dass Nutzer die Funktionen des Luftreinigers effizienter und effektiver bedienen können. Der Einsatz von Farben, Symbolen und dynamischen Trendanzeigen hat sich als besonders wirksam erwiesen, um komplexe Daten in leicht verdauliche Informationen umzuwandeln.  Die Implementierung selbstregulierender Funktionen hat sich ebenfalls als zentraler Aspekt herausgestellt, um Benutzerinteraktionen zu minimieren und den Nutzeraktivitäten einen höheren Komfort zu verleihen. Im Ergebnis zeigte sich, dass adaptive Systeme, die auf Basis der ermittelten Luftqualitätsdaten autonom Anpassungen vornehmen, nicht nur die Energieeffizienz verbessern, sondern auch eine nachhaltig hohe Reinigungsleistung aufrechterhalten.  Zusammenfassend lässt sich sagen, dass die durchgeführten Optimierungsmaßnahmen dazu beitragen, die funktionalen Eigenschaften des Luftreinigers zu stärken und gleichzeitig eine benutzerfreundliche Interaktion zu fördern. Die Verbindung von ansprechendem Design, klarer Nutzerführung und innovativer Technik hat das Ziel erreicht, die Akzeptanz smarter Technologien im Alltag zu erhöhen. Die verursachten Synergieeffekte führen letztlich nicht nur zu einem individuell höheren Wohlbefinden durch bessere Luftqualität, sondern unterstützen auch eine breitere nachhaltige Entwicklung – eine essentielle Forderung in einer zunehmend urbanisierten und belasteten Welt. Künftige Forschungsrichtungen könnten diese Ansätze weiter fördern und auf gleichwertige Anwendungen in anderen Bereichen der Haustechnologie übertragen, um die Interaktion zwischen Mensch und Umwelt signifikant zu optimieren. ;1
- @JvmStatic   Die Annotation @JvmStati c informiert den Compiler darüber,  dass für die  annotierte Funktion oder Eigenschaft eine statische Java -Methode in der  kompilierten Ausgabe generiert werden soll und kann nur für Objekte oder  companion objects verwendet werden. Standardmäßig wird ein Obj ekt oder  companion object in eine Klasse kompiliert, die über eine einzige Instanz  verfügt und wird dann in einem statischen Feld namens INSTANCE gespeichert.  Jedoch ist ein Zugriff auf die Funktionen dieser Objekte erst möglich, wenn der  singleton aufgelö st wurde.  - Ternary -operator   In Kotlin gibt der if -Ausdruck  einen Wert zurück und kann somit als Ersatz  für die  ternary operators (a ? b : c) von Java genutzt werden.39   Wo Javas ternären Operato ren verwendet ,   a > b ? a : b  gibt es in Kotlin keine ternären Operatoren mehr  und Rückgabewerte werden  im  Body  des if -Ausdrucks definiert :  if (a > b) a else b;0
Zero - Möglichkeiten und Gefahren der digitalen Überwachung  In einer zunehmend vernetzten Welt stellt die digitale Überwachung ein zentrales Thema dar, das sowohl Chancen als auch Herausforderungen mit sich bringt. Die vorliegende Analyse beschäftigt sich mit den Möglichkeiten und Gefahren, die aus der Implementierung digitaler Überwachungssysteme resultieren, und zieht ein abschließendes Fazit über die Auswirkungen auf die Gesellschaft.  Die digitale Überwachung bietet eine Vielzahl von Möglichkeiten, die in verschiedenen Bereichen Anwendung finden. Im Sicherheitssektor können moderne Überwachungstechnologien, wie etwa Gesichtserkennung und Bewegungsanalysen, dazu beitragen, Kriminalität zu reduzieren und die öffentliche Sicherheit zu erhöhen. In der Medizin ermöglicht die digitale Überwachung von Patienten eine frühzeitige Erkennung von Krankheiten und eine individualisierte Behandlung. Auch im Bereich der Verkehrsüberwachung können intelligente Systeme zur Optimierung des Verkehrsflusses und zur Reduzierung von Staus eingesetzt werden.  Jedoch sind diese Vorteile nicht ohne Risiken. Die fortschreitende digitale Überwachung birgt die Gefahr eines Verlustes der Privatsphäre und der individuellen Freiheit. Die flächendeckende Erfassung und Auswertung persönlicher Daten kann zu einer massiven Kontrolle des Einzelnen führen, die in autoritären Strukturen leicht missbraucht werden kann. Zudem besteht die Gefahr, dass durch algorithmische Entscheidungen Diskriminierung und Ungerechtigkeit gefördert werden, da Systeme oft auf bestehenden Vorurteilen basieren.  Ein weiteres zentrales Problem ist die Frage nach der Datensicherheit. Mit der zunehmenden Menge an gesammelten Daten steigt auch das Risiko von Datenlecks und Cyberangriffen. Die Sensibilität der gesammelten Informationen erfordert einen verantwortungsvollen Umgang und strenge Sicherheitsmaßnahmen, um Missbrauch zu verhindern.  Im  zeigt sich, dass die digitale Überwachung sowohl ein zweischneidiges Schwert als auch eine notwendige Realität unserer Zeit ist. Die Möglichkeiten, die sich aus der digitalen Überwachung ergeben, sind beträchtlich und können zur Verbesserung von Sicherheit, Gesundheit und Lebensqualität beitragen. Dennoch müssen die damit verbundenen Gefahren ernst genommen und aktiv angegangen werden.   Es ist unerlässlich, klare ethische Richtlinien und rechtliche Rahmenbedingungen zu entwickeln, um den Schutz der Privatsphäre und die Rechte des Einzelnen zu gewährleisten. Eine transparente Kommunikation und die Einbeziehung der Öffentlichkeit in Entscheidungsprozesse sind entscheidend, um das Vertrauen in digitale Überwachungssysteme zu stärken. Nur durch einen ausgewogenen Ansatz, der sowohl die Chancen als auch die Risiken berücksichtigt, kann eine verantwortungsvolle und zukunftsfähige digitale Überwachung gewährleistet werden. In einer Welt, in der die Technologie immer weiter voranschreitet, bleibt die Herausforderung, den Menschen in den Mittelpunkt zu stellen und die digitalen Werkzeuge als Mittel zur Verbesserung des Lebens und nicht als Instrument der Kontrolle zu nutzen.;1
In dem vorgeführten Beispiel soll erkannt werden, dass Personen im Raum sind, das bedeutet, dass von der Grundgleichung der Kalorik der Temperaturdifferenz △T berechnet werden muss. Daraus resultierend sieht die Gleichung folgendermaßen aus: △T = Q 12/ (m ·c) und dabei gilt: •Ein Mensch gibt 120 Watt Wärme ab, daher geben 20 Menschen gleich 2.5 Kilowattstunde (kWh) ab, was 864000 Joule (J) entspricht. Q12= 864000 J •Das Raumvolumen beträgt 75 m3und die Luftdichte ist (laut DIN ISO 2533) ungefähr 1.20165kg/m3( = 0.0012 Gramm ( g)/Zentimeter ( cm)3) (vgl. ebd., S. 268). Somit ist die Masse m = 90123.75 g . •Die spezifische Wärmekapazität cbeträgt 1.0045 J/ (kg ·Kelvin (K)) (vgl. ebd., S. 275). c= 1004.5 J/g Damit lautet die Formel folgendermaßen: △T = 864000 J/ (90123.75 g·1004.5J/g). Die Temperaturdifferenz beträgt somit △T = 0.009544◦Cpro Sekunden, was 0.57◦Cpro Stunde entspricht. Das bedeutet, dass 20 Menschen (jeweils 75 kg) einen Raum mit einer Größe vom 75 m3ungefähr um 0.6◦Cpro Stunde aufwärmen. Bei den Situationen wird beobachtet, dass die Luftqualität im Raum bei geschlossenen Fenstern schon nach circa fünf Minuten zu unzureichend ist. Durch die Temperaturwerten konnte ungefähr nach einer Stunde erkannt werden, dass Personen im Raum sind. Für das Situationsbewusstsein sollte das allerdings in weniger als fünf Minuten geschehen. Es kann behauptet werden, dass bei den vorgeführten Szenarien die Wahrnehmung, dass Menschen im Raum sind, durch einen Temperatursensor nicht geeignet ist. Stattdessen soll es durch einen Geräuschsensor und einen CO 2-Sensor erfolgen.;0
 Kapitel 2: Technische Grundlagen  Die Qualität von Software ist ein vielschichtiges Konzept, das in der Softwareentwicklung eine zentrale Rolle spielt. Um die Qualität von Softwareprodukten zu bewerten und zu verbessern, sind verschiedene Metriken erforderlich, die spezifische Aspekte der Software messen. In diesem Kapitel werden die technischen Grundlagen produktorientierter Metriken der Softwarequalität erläutert, um ein besseres Verständnis für deren Definition und Anwendung zu schaffen.   2.1 Definition produktorientierter Metriken  Produktorientierte Metriken sind quantitative Maßzahlen, die direkt auf das Endprodukt – die Software – angewendet werden. Sie konzentrieren sich auf Eigenschaften des Softwareprodukts selbst, wie zum Beispiel Funktionalität, Zuverlässigkeit, Effizienz, Benutzbarkeit und Wartbarkeit. Diese Metriken ermöglichen es Entwicklern und Managern, den aktuellen Stand der Softwarequalität zu bewerten und gezielte Verbesserungsmaßnahmen zu planen.  Die Definition produktorientierter Metriken kann in verschiedene Kategorien unterteilt werden:  1. Funktionale Metriken: Diese Metriken messen, inwieweit die Software die definierten Anforderungen erfüllt. Ein Beispiel hierfür ist die Anzahl der implementierten Funktionen im Vergleich zu den ursprünglich geplanten Funktionen.  2. Fehlermetriken: Diese Metriken erfassen die Anzahl und Schwere von Fehlern in der Software. Dazu gehören beispielsweise die Fehlerdichte, die Anzahl der kritischen Fehler und die durchschnittliche Zeit bis zur Fehlerbehebung.  3. Leistungsmetriken: Diese Metriken bewerten die Effizienz der Software, insbesondere hinsichtlich ihrer Reaktionszeiten, Durchsatzraten und Ressourcennutzung. Ein Beispiel ist die Antwortzeit einer Anwendung unter Last.  4. Benutzbarkeitsmetriken: Diese Metriken erfassen, wie einfach und intuitiv die Software für Endbenutzer zu bedienen ist. Hierzu zählen unter anderem die Anzahl der benötigten Schritte, um eine bestimmte Aufgabe zu erledigen, oder die Zufriedenheit der Benutzer mit der Benutzeroberfläche.  5. Wartbarkeitsmetriken: Diese Metriken bewerten, wie einfach die Software gewartet und aktualisiert werden kann. Dazu gehören die Anzahl der Codezeilen pro Modul oder die Modularität des Codes.   2.2 Anwendung produktorientierter Metriken  Die Anwendung produktorientierter Metriken ist in verschiedenen Phasen des Softwareentwicklungsprozesses von Bedeutung. Sie können sowohl in der Planungs- und Entwurfsphase als auch in der Implementierungs- und Testphase eingesetzt werden. Die wichtigsten Anwendungsgebiete sind:   2.2.1 Qualitätssicherung  Produktorientierte Metriken dienen als Basis für die Qualitätssicherung. Durch die kontinuierliche Überwachung dieser Metriken während der Entwicklung können potenzielle Probleme frühzeitig identifiziert werden. Beispielsweise kann eine plötzliche Erhöhung der Fehlermetriken darauf hindeuten, dass ein spezifischer Teil des Codes überarbeitet werden muss.   2.2.2 Entscheidungsfindung  Metriken bieten eine objektive Grundlage für Entscheidungsprozesse in der Softwareentwicklung. Sie helfen dabei, Prioritäten zu setzen, Ressourcen effizient zu verteilen und die Notwendigkeit von Maßnahmen zur;1
Für die Interaktion müssen Aktoren auf die Daten von Sensoren reagieren. Dafür existieren zwei Ansätze für den Datenfluss von Sensoren zu Aktoren: •Der Aktor abonniert ein Steuerungs-Topic, in dem Befehle als PUBLISH Con- trol Packet bzw. innerhalb der Payload veröffentlicht werden. Hierbei können z.B. Fernbedienungs-Geräte konkrete Befehle an einen Aktor senden, was bei einer manu- ellen Steuerung der Geräte durch Benutzer*innen sinnvoll ist. Alternativ kann dies auch für eine Leader-Follower-Architektur für z.B. Smart Lights verwendet werden, bei der nur eine Lampe die Befehle erhält. Diese Lampe leitet den Befehl an andere Lampen weiter, damit die Zustände aller Lampen synchronisiert werden. •Der Aktor abonniert Topics von anderen MQTT-Geräten bzw. -Sensoren. Wenn der Sensor einen neuen Wert veröffentlicht, interpretiert das Gerät den Wert und handelt autonom. Dies kann ebenfalls für eine Leader-Follower-Architektur verwendet werden, wenn das vorherige Beispiel umgekehrt wird: die Follower-Lampen abonnieren das Topic der Leader-Lampe, wodurch der Leader die Follower nicht kennen muss. Um den Studierenden die größtmögliche Flexibilität zu bieten, werden beide Arten der Interaktion ermöglicht. Bezüglich der manuellen Steuerung von Geräten sind zwei Ansätze möglich, welche im Folgenden beschrieben werden: •Es gibt ein Topic (z.B. /control), unter dem Key-Value-Paare für die jeweiligen Einstellungen gesendet werden können, z.B. im JavaScript Object Notation ( JSON)- Format. •Es existiert pro Einstellung ein eigenes Topic (z.B. /set_power und/set_color ), unter dem der neue Wert für die angegebene Einstellung gesendet werden kann. Oladehin und Krems  empfehlen, alle relevanten Informationen für das Routing in dasMQTT-Topic aufzunehmen. Deswegen wird pro Einstellungsmöglichkeit ein eigenes Topic unter dem Geräte-Topic angelegt. Zusammen mit den vorherigen Überlegungen ergibt sich schließlich die folgende Topic-Struktur: •Geräte-Topics als home_id/room_id/device_id/ •Veröffentlichen von Daten unter eigenen Topics, z.B. device_id/temperature •Steuerung von Geräten als separate Untertopics, z.B. device_id/set_opened oder device_id/toggle_power;0
Ein Arbeitspaket hat mindestens einen Titel, eine Beschreibung, eine optional zugewiesene  bearbeitende Person, einen Typ, einen Status und einen optional geschätzten Aufwand. Bei  Azure DevOps Services, Jira Software und OpenProject ist ein eindeutiges Attribut vorhanden,  um ein Arbeitspaket zu identifizieren, beispielsweise bei einer Verlinkung, auf einer  Auswertung, oder zur Erwähnung in der Beschreibung eines anderen Tickets. Da es an  mehreren Stellen nützlich ist, wird es ebenfalls in der Schätzung berücksichtigt, anders als  beispielsweise die einzigartigen Attribute der anderen Entitätstypen, die nur vorhanden sind,  um eindeutige Verknüpfungen zu anderen Entitätstypen im Datenschema herzustellen. Bei  der Wahl des eindeutigen Attributs ist eine fortlaufende Zahl, wie beispielsweise auch bei  Azure DevOps Services, ausreichend. Bei Jira Software ist das eindeutige Attribut  eine  Kombination aus dem Projekt und eine fortlaufende Zahl, dort ist es je doch auch üblicher,  projektübergreifende Verlinkungen durchzuführen, bei der hier beschriebenen Software ist  dies nicht der Fall. Die ID sollte trotzdem global, und nicht nur projektbezogen eindeutig sein,  sodass bei Bedarf eine projektübergreifende Verlinkung realisiert werden kann.   Es ist noch zu entscheiden, ob es nur eine bearbeitende Person geben kann, wie beispielsweise  bei Azure DevOps Services und Jira Software, oder mehrere bearbeitende Personen, wie bei  Trello. Es könnte insbesondere bei Arbeitspaketstypen vorteilhaft sein, die von allen Personen  durchgeführt werden müssen, beispielsweise die Einrichtung des Projektes auf  dem  Entwickler-PC. Mit Azure DevOps ist es nicht möglich, mehrere Personen  einem Arbeitspaket  zuzuweisen, in diesem Fall wurde das Arbeitspaket mehrfach erstellt und jeweils einer Person  zugewiesen. Da also Arbeitspakete für mehrere Personen durch einzelne Arbeitspakete für  jede einzelne Person ersetzt werden können, wird im Entwurf der Software davon  ausgegangen, dass ein Arbeitspaket nur einer Person zugewiesen werden kann.  Jedes Arbeitspaket sollte einen Typ haben, um beispielsweise zu ermöglichen , mehrere  Arbeitspakete in einer übergeordneten Kategorie zusammenzufassen, oder Unteraufgaben zu  Aufgaben zu erstellen. In Azure DevOps Services gibt es mehrere Arbeitspaketstypen, die sich  ähneln, beispielsweise „User Stories“  und „Feature“ oder „Issue“ und „Bug“. Für die Software  sollte eine kleinere Menge an notwendigen Typen ausgesucht werden , beispielsweise „Epic“,  „User Story “, „Aufgabe “, „Fehler“ und „Test“ .;0
Bei der Skalierung in größeren Fahrzeugen ist besonders der Aspekt der funktionalen Sicherheit stärker und genauer zu betrachten, da größere Fahrzeuge allein durch ihre zusätzliche Masse, Kraft und Geschwindigkeit bei Fehlfunktionen, wie zum Beispiel in der Kollisionsvermeidung, viel größere Schäden anrichten können als ein Modellfahrzeug. Potenziell kommen dafür verschiedene Maßnahmen in Frage, so sollte der Notaus-Schalter nicht nur den Strom der Steuerungselektronik unterbrechen, sondern das gesamte Fahrzeug stromlos schalten, die Motoren wenn möglich sperren und eventuell vorhandene Brems- systeme auslösen, da ansonsten der Stillstand der Maschine nicht gewährleistet ist. Zum Umgang mit den größeren Stromspannungen und Stromstärken von Antriebssystemen reicht es dabei meist nicht aus, den Strom direkt über den Notaus-Schalter zu unterbrechen, stattdessen können Relais, wie zum Beispiel Kfz-Relais zum Einsatz kommen, die mit den größeren Strommengen umgehen können. Weiterhin ist es relevant, dass das Fahrzeug, im Gegensatz zum erstellten Prototypen auch über aktive Bremsen verfügt, dass das Fahrzeug im Notfall, unter Nutzung des bestmöglichen Bremsweges, zum Stillstand bringen kann. Für die Kollisionsvermeidung wurde als Verbesserungsvorschlag bereits die höherwertigeren, genaueren und schnelleren Abstandssensoren genannt, dessen Wichtigkeit sich durch den Einsatz in größeren Fahrzeugen noch einmal erhöht. Weiterhin kann die Überwachung des Abstands zu möglichen Hindernissen an einen eigenen Microcontroller ausgelagert werden, der durch einen Interrupt-Pin am Hauptcontroller eine Notbremsung auslöst, was eine echt parallele Verarbeitung der Daten zu Kollisionsvermeidung ermöglicht. Insgesamt wird das Thema funktionale Sicherheit immer wichtiger, da im Internet immer öfters Videos und Beiträge mit teils größeren ferngesteuerten Maschinen auftauchen.;0
In-Room Ortung zur Sturzerkennung mit BluetoothEin Fazit  Die zunehmende Anzahl älterer Menschen und der damit einhergehende Anstieg von Stürzen in privaten Wohnräumen stellt eine bedeutende Herausforderung für die Gesundheitssysteme dar. Innovative Technologien zur Sturzerkennung sind daher von großer Bedeutung, um schnell auf Notfälle reagieren zu können und die Lebensqualität älterer Menschen zu erhöhen. In diesem Kontext spielt die In-Room Ortung eine entscheidende Rolle. Insbesondere die Verwendung von Bluetooth-Technologie hat vielversprechende Ansätze zur präzisen, kostengünstigen und benutzerfreundlichen Sturzerkennung eröffnet.  Im Rahmen dieses Projekts wurde ein System entwickelt, das die Bluetooth-Technologie nutzt, um eine präzise Ortung von Personen innerhalb eines Raums zu realisieren. Bei der Implementierung kam ein Netzwerk aus Bluetooth Low Energy (BLE) Beacons zum Einsatz. Diese Beacons senden kontinuierlich Signale, die von tragbaren Geräten, wie zum Beispiel smarten Armbändern oder Smartphones, empfangen werden. Anhand der Signalstärke und der Position der Beacons konnte das System die Position des Nutzers in Echtzeit bestimmen und kritische Bewegungen, wie plötzliche Stürze, erkennen.  Die Ergebnisse des Projekts zeigten, dass das System eine hohe Erkennungsrate bei Stürzen aufwies. Dank der fortlaufenden Datenanalyse konnten auch falsche Alarme, etwa durch ruckartige Bewegungen, weitestgehend minimiert werden. Ein entscheidender Vorteil der In-Room Ortung ist lokalisiert und kontextbasiert, wodurch die Sicherheit der Nutzer erheblich erhöht wird, ohne deren Bewegungsfreiheit einzuschränken.  Ein zentrales  ist, dass die Kombination aus BLE-Technologie und intelligenten Algorithmen zur Datenverarbeitung ein leistungsfähiges Werkzeug zur Sturzerkennung darstellt. Nicht nur die Kosteneffizienz der Technologie, sondern auch die Einfachheit der Installation und Nutzung sind hervorzuheben. Dies macht das System besonders attraktiv für den Einsatz in privaten Haushalten sowie in Pflegeeinrichtungen.  Zudem sollte betont werden, dass die Integration solcher Systeme in bestehende Versorgungskonzepte entscheidend ist, um die Akzeptanz bei den Nutzern zu erhöhen. Herausforderungen wie Datenschutz und Datensicherheit müssen dabei angemessen berücksichtigt werden, um die Nutzer nicht nur technisch zu schützen, sondern auch deren Vertrauen in die Technologie zu gewinnen.  Zusammenfassend kann gesagt werden, dass die In-Room Ortung zur Sturzerkennung mit Bluetooth nicht nur als technologisches Experiment zu betrachten ist, sondern als ein Schritt in die Zukunft der häuslichen Gesundheitsversorgung. Durch die Minimierung von Sturzrisiken und die Gewährleistung schneller Reaktionen im Notfall kann dieses System dazu beitragen, die Sicherheit und Lebensqualität älterer Menschen erheblich zu verbessern.;1
Auch wenn der Roman fiktiv ist, hat er doch erstaunlich nahen Bezug zur Realität und könnte eine mögliche Zukunft zeigen. Durch diesen Bezug werden auch schon viele vorhandene Verfahren und Techniken zur Datensammlung, -analyse und der allgemeinen Überwachung, sowie der gezielten Überwachung von Personen gezeigt. Ein großes Thema sind die Datenbrillen. Diese erlauben mit eingebauter Gesichtserkennung, das eindeutige IdentifizierenvoneinzelnenIndividuen.DadurchlassensichPersonenverfolgen,wasauchim Buch passiert, durch die Verfolgungsjagd Adams. Videoüberwachung spielt allgemein eine große Rolle, so wie großflächige Überwachung in London durch Videokameras. Aber gerade durch Freemee werden auch Manipulationstechniken eingesetzt. Dazu dienen Techniken, die man der predictive analytics zuordnen kann. Dadurch sollen Ereignisse oder Handlungen von Personen mit einer Wahrscheinlichkeit des Eintretens vorhergesagt werden. Um solche Dinge besser vorherzusagen, braucht es die gezielte Verarbeitung und Sammlung von großen Datenmengen. Dies sind Dinge die schon heute so passieren. Die Vorgehensweise für die weitere Analyse ist anhand eines Schemas festgelegt. Dabei werden im ersten Schritt die Überwachungstechniken im Buch „ZERO - Sie wissen, was du tust“ genauer analysiert. Anhand der Analyse des Buches werden überprüft, ob es auch in der realen Welt besagte Überwachungstechniken gibt. Dies beinhaltet auch ähnliche Überwachungstechniken. Dabei wird eine Einschränkung auf digitale Überwa- chungstechniken vorgenommen. Nach dieser ersten erfolgten Analyse werden Beispiele aus der realen Welt analysiert und Verknüpfungen zum Buch hergestellt. Es werden auch noch weitere Techniken vorgestellt, die der Überwachung dienen können. Dabei wird immer der Versuch wahrgenommen diese mit dem Buch zu verbinden und gleichzeitig die Möglichkeiten und Gefahren genauer zu erläutern. Am Ende gibt es dann ein Fazit wie sich digitale Überwachungstechniken auf das weitere Leben auswirken können.;0
- String templates   Mit String  Templates können in Kotlin String  concatenations verhindert werden.  String Templates sind e ine einfache und effektive Methode zum Einbetten von  Werten, Variablen oder sogar Ausdrücken in einem String, ohne dass Patterns   ersetzt werden oder eine String  concatenation stattfindet.55 Das Java Erlebnis in  Kotlin wird dadurch enorm verbessert, wenn mehrere Variablen in einem einzigen  Literal verwendet werden, da die Strings durch sie kürzer und somit besser lesbar  sind.  Das Template besteht entweder aus einem Namen oder aus einem Ausdruck  in geschweiften Klammern und beginnt mit einem Dollarzeichen ‚$‘. Die Templates  können  außerdem  für raw und auch escaped Strings verwendet werden.;0
 Ein Ausblick auf mögliche Weiterentwicklungen  Die App-Entwicklung hat sich in den letzten Jahren rasant verändert, wobei das Jetpack Compose Framework von Google eine zentrale Rolle in der modernen Android-Entwicklung spielt. Jetpack Compose, das im Jahr 2020 eingeführt wurde, revolutioniert die Art und Weise, wie Entwickler Benutzeroberflächen erstellen, indem es ein deklaratives Programmierparadigma einführt, das die Effizienz und Flexibilität bei der UI-Entwicklung erheblich steigert. Während die gegenwärtigen Möglichkeiten des Frameworks bereits bemerkenswert sind, werfen wir einen Blick auf potenzielle Weiterentwicklungen, die die Zukunft der App-Entwicklung mit Jetpack Compose prägen könnten.   1. Verbesserte Interoperabilität  Eine der größten Herausforderungen in der App-Entwicklung ist die Interoperabilität zwischen verschiedenen Frameworks und Technologien. Obwohl Jetpack Compose bereits eine nahtlose Integration mit bestehenden Android-Views ermöglicht, könnte eine weitere Verbesserung der Interoperabilität mit anderen Plattformen wie Web und Desktop von großem Vorteil sein. Zukünftige Versionen könnten es Entwicklern ermöglichen, Komponenten, die in Compose erstellt wurden, einfacher in anderen Umgebungen zu verwenden, was die Wiederverwendbarkeit von Code und die Konsistenz der Benutzererfahrung über verschiedene Plattformen hinweg fördern würde.   2. Erweiterte Tooling- und Entwicklungsunterstützung  Die Entwicklungsumgebung spielt eine entscheidende Rolle in der Effizienz der App-Entwicklung. Während Jetpack Compose bereits über umfangreiche Unterstützung in Android Studio verfügt, könnten zukünftige Versionen noch leistungsfähigere Werkzeuge bieten. Dazu gehören verbesserte Live-Preview-Funktionen, die es Entwicklern ermöglichen, Änderungen in Echtzeit zu sehen, sowie fortschrittliche Debugging-Tools, die speziell auf die Herausforderungen der deklarativen Programmierung zugeschnitten sind. Eine stärkere Integration von KI-gestützten Funktionen könnte ebenfalls in Betracht gezogen werden, um Entwicklern bei der Codegenerierung und -optimierung zu helfen.   3. Optimierung der Performance  Die Performance von Anwendungen ist ein entscheidender Faktor für den Erfolg im mobilen Markt. Jetpack Compose hat bereits Fortschritte in der Performance gemacht, jedoch könnten zukünftige Entwicklungen noch tiefere Optimierungen ermöglichen. Dies könnte durch die Implementierung von fortschrittlichen Techniken wie Lazy Loading, verbesserte State Management-Strategien und die Nutzung von Hardwarebeschleunigung erreicht werden. Eine kontinuierliche Verbesserung der Rendering-Performance würde nicht nur die Benutzererfahrung verbessern, sondern auch die Lebensdauer von Geräten verlängern, indem der Energieverbrauch gesenkt wird.   4. Erweiterung der Komponentenbibliothek  Die derzeitige Komponentenbibliothek von Jetpack Compose ist bereits umfangreich, jedoch könnte eine kontinuierliche Erweiterung und Diversifizierung dieser Bibliothek die Entwicklung von Anwendungen weiter vereinfachen. Zukünftige Versionen könnten neue, spezialisierte UI-Komponenten und -Layouts einführen, die auf aktuelle Designtrends und Benutzeranforderungen abgestimmt sind. Darüber hinaus könnten Community-Driven-Initiativen zur Erstellung und Pflege von Open-Source-Komponenten die Vielfalt und Verfügbarkeit von UI-Elementen erheblich erhöhen.   5. Integration von Multiplattform-Entwicklung  Die;1
Ausblick auf mögliche Weiterentwicklungen  Die kontinuierliche Digitalisierung von Lehrmethoden und Lerninhalten eröffnet neue Dimensionen der Wissensvermittlung, insbesondere in technischen Disziplinen. Im Zuge dieser Transformation hat sich das Message Queuing Telemetry Transport (MQTT) Protokoll als ein wegweisendes Kommunikationsprotokoll im Internet der Dinge (IoT) etabliert. Die  eröffnet vielversprechende Perspektiven für die Praxis der Ausbildung in Informatik und Ingenieurwissenschaften.  MQTT ist leichtgewichtig und sorgt für eine effiziente Kommunikation zwischen Geräten, was es zu einer herausragenden Wahl für IoT-Anwendungen macht. Durch die Schaffung eines virtuellen Szenarios, etwa in Form einer Simulation realer IoT-Systeme, können Studierende nicht nur die Theorie des Protokolls erlernen, sondern auch praktische Erfahrungen im Umgang mit der Implementierung und Nutzung sammeln. In einem solchen Szenario könnten Studierende beispielsweise verschiedene IoT-Geräte simulieren, die Daten in ein zentrales System einspeisen und von dort aus verarbeitet werden. Dies fördert nicht nur das Verständnis für die Funktionsweise von MQTT, sondern auch für relevante Konzepte wie Topic-Management, Subscribing und Publishing.  Ein zentrales Element der Entwicklung eines solchen Szenarios ist die Möglichkeit, komplexe, realitätsnahe Umgebungen zu erstellen, die den Studierenden ein realitätsnahes Erlebnis bieten. Mithilfe von Simulationstools und Programmierschnittstellen könnte ein interaktives Lernumfeld entstehen, in dem Studierende eigenständig Projekte entwickeln, testen und evaluieren können. Der Einsatz von gamifizierten Elementen, wie z.B. dem Erreichen von Meilensteinen oder dem Lösen von spezifischen Herausforderungen, könnte zusätzlich die Motivation und das Engagement der Lernenden erhöhen.   Für die Zukunft sind mehrere Weiterentwicklungen denkbar, die das virtuelle MQTT-Szenario für Lehrzwecke bereichern könnten. Erstens könnte die Integration von Künstlicher Intelligenz (KI) in die Lernumgebung die Anpassungsfähigkeit des Systems erhöhen. Mithilfe von KI-algorithmen könnten personalisierte Lernpfade erstellt werden, die sich an dem individuellen Fortschritt und den Bedürfnissen der Studierenden orientieren. Dies würde nicht nur die Motivation steigern, sondern auch effektiveres Lernen ermöglichen.  Zweitens könnte die Anbindung an reale IoT-Geräte und Netzwerke die Lerneffizienz signifikant erhöhen. Durch hybride Szenarien, in denen Studierende sowohl virtuelle als auch physische Geräte steuern, würde der Übergang von der Simulation zur praktischen Anwendung nahtlos gestaltet. Diese duale Methode würde sicherstellen, dass die Studierenden die gesammelten Kenntnisse direkt in einem realen Kontext anwenden können.  Drittens könnte eine stärkere Community-Fokussierung das virtuelle Szenario bereichern. Plattformen zur Zusammenarbeit, in denen Studierende Projekte teilen und gemeinsam an Lösungen arbeiten, könnten den Erfahrungsaustausch und die kollektive Problemlösung fördern. Dies würde nicht nur die sozialen Kompetenzen der Lernenden stärken, sondern auch authentische Teamarbeit und interdisziplinäres Lernen unterstützen.  Zusammenfassend lässt sich festhalten, dass die  nicht nur eine wertvolle Bereicherung für die technische Ausbildung darstellt, sondern auch einen vielversprechenden Ansatz für innovative Lehrmethoden bietet. Zukünftige Weiterentwicklungen, einschließlich der Integration von KI, hybriden Anwendungen und interaktiven Plattformen, könnten die Attraktivität und Effektivität solcher Lehrszenarien wesentlich erhöhen. Dadurch wird nicht nur das Verständnis für moderne Kommunikationsprotokolle gefördert, sondern auch die Heranführung an eine zunehmend digitalisierte Welt, in der die Beherrschung dieser Technologien unerlässlich ist.;1
Ein Projekt ist als Gruppe von Personen zu verstehen, die gemeinsam ein Projekt bearbeiten.  Würde die Software eingesetzt werden, um beispielsweise eine Gruppenarbeit zu  organisieren, würde für jede einzelne Gruppe ein Projekt erstellt werden. Wichtig ist zu  beachten, dass die Software möglicherweise von unterschiedlichen Kursen oder von einem  Kurs in mehreren Veranstaltungen verwendet wird. Der Zustand, ob die Projekte bearbeitet  werden können oder nicht, darf deswegen nicht auf globaler Ebene festgelegt werden,  sondern muss projektbezogen festgelegt werden.  Eine Projektrolle ist einem Projekt zugeordnet. Ein Projekt kann mehrere Projektrollen  besitzen. Ist eine Person einer Projektrolle zugewiesen, kann sie au f das entsprechende  Projekt und seine Inhalte zugreifen . Da es bei Prüfungsleistungen üblich ist, dass zu einem  bestimmten Zeitpunkt die Prüfungsleistung bewertet wird, ist es empfehlenswert, an der  Projektrolle zu definieren, ob die Personen Daten des Projektes ändern dürfen. Zum Zeitpunkt  der Beendigung der Prüfungsleistung wird das Bearbeitungsrecht entfernt, sodass das Projekt  bewertet werden kann, ohne dass Änderungen nach Ende der Prüfungsleistung  möglich sind.   Da in einer Prüfungsleistung meist mehrere Gruppen bewertet werden, reich t es nicht aus,  den Bearbeitungszugriff den Gruppen manuell durch eine Person mit Administratorenrechten  zu entfernen. Eine Gruppe hätte dadurch immer ein etwas größeres Bearbeitungszeitfenster  als eine andere, was zur Anfechtung der Prüfungsleistung verwendet werden  kann. Abhilfe  kann geschaffen werden, wenn einer Projektrolle ein Zeitpunkt zugewiesen wird, zu welchem  der Bearbeitungszugriff der Rolle entfernt wird. Somit kann projektübergreifend sichergestellt  werden, dass mehrere Projekte zum gleichen Zeitpunkt geschlossen werden.;0
Wenn man sich allerdings in Gebäuden befindet funktionieren diese Techniken nicht mehr so gut. Doch dafür haben sich Google als auch Geschäfte in Einkaufszentren etwas ausgedacht. Das Tracken mittels WLAN oder Bluetooth. Im Prinzip werden von mehreren Accesspoints Signale ausgestrahlt, wenn das Smartphone mit dem WLAN verbunden ist, kann überprüft werden wie stark die jeweiligen Signale sind und mit welchem Accesspoint es gerade verbunden ist. Damit kann dann der genau Standort bestimmt werden. Es geht aber auch ohne Verbindung. Schließlich sendet das Smartphone immer wieder Signale an verfügbare Accesspoints, um herauszufinden welche Service Set IDentifier ( SSID) diese haben (Schwäbe 2019). Dabei wird immer die MAC Adresse mitgesendet. Somit ist man auch eindeutig identifizierbar ohne aktive WLAN-Verbindung ( Mit WLAN-Tracking Besucherströme analysieren 2022). Das machen sich Geschäfte zu Nutzen und können so mit Beacons oder Accesspoints die Kunden im Gebäude sehr genau tracken. Dabei können sie sogar feststellen wie lange ein Kunde vor welchem Regal verweilt ( WLAN-Tracking und Datenschutz 2022).;0
   Die rasante Entwicklung der digitalen Technologien hat die Art und Weise, wie Bildung und Wissen vermittelt werden, entscheidend verändert. Besonders im Bereich der Informatik und der Kommunikationssysteme gewinnen praxisnahe Lernumgebungen an Bedeutung. Ein solches Thema ist der Message Queuing Telemetry Transport (MQTT) Protokoll, das in der Welt des Internet der Dinge (IoT) weit verbreitet ist. Ziel dieses Prosatextes ist es, die theoretischen Grundlagen für die Entwicklung eines virtuellen Szenarios zu umrissen, das auf der MQTT-Technologie basiert und für Lehrzwecke konzipiert ist.   1. Verständnis von MQTT  MQTT ist ein leichtgewichtiges Publish-Subscribe-Messaging-Protokoll, das für Netzwerke mit begrenzten Ressourcen und Bandbreiten umfangreiches Potenzial bietet. Es funktioniert nach dem Prinzip, dass Nachrichten von Publishern an Broker gesendet werden, die sie dann an die interessierten Subscriber weiterleiten. Dieses Modell fördert die Entkopplung von Sender und Empfänger, was nicht nur die Netzwerkbelastung reduziert, sondern auch die Skalierbarkeit der Systeme verbessert. Die grundlegenden Mechanismen von MQTT, wie Quality of Service (QoS) und Retained Messages, ermöglichen eine flexible und zuverlässige Kommunikation, selbst unter suboptimalen Bedingungen.   2. Didaktische Prinzipien  Bei der  müssen mehrere didaktische Prinzipien beachtet werden. Zunächst ist es wichtig, die Lernziele klar zu definieren. Dies umfasst sowohl technische Kompetenzen, wie das Verständnis von Protokollen und Netzwerktechnologien, als auch soziale Kompetenzen, die durch Kollaboration und Teamarbeit gefördert werden können. Ein konstruktivistischer Ansatz, bei dem Lernende aktiv in den Lernprozess einbezogen werden, fördert ein tieferes Verständnis der Materie und eine nachhaltige Aneignung von Wissen.  Des Weiteren sollte das Szenario realistische Anwendungskontexte bieten, um die Relevanz des Gelernten zu unterstreichen. Dies könnte beispielsweise durch die Simulation eines Smart Home-Systems erfolgen, in dem verschiedene Geräte über MQTT miteinander kommunizieren und gesteuert werden. Solche realitätsnahen Beispiele motivieren Lernende und veranschaulichen die praktische Bedeutung von MQTT im alltäglichen Leben.   3. Technische Implementierung des Szenarios  Ein weiterer zentraler Aspekt bei der Entwicklung eines virtuellen MQTT-Szenarios ist die technische Umsetzung. Dies umfasst die Auswahl geeigneter Software-Tools und Plattformen, die es ermöglichen, ein interaktives Lernumfeld zu schaffen. Open-Source-Lösungen wie Mosquitto und Eclipse Paho bieten eine solide Grundlage für das Testen und Entwickeln von MQTT-basierten Anwendungen. Darüber hinaus können grafische Benutzeroberflächen und Simulationstools, wie Node-RED oder Thinger.io, verwendet werden, um komplexe Interaktionen visuell aufzubereiten und intuitiv nutzbar zu machen.  Die Visualisierung der Kommunikationsprozesse innerhalb des MQTT-Protokolls ist entscheidend, um den Lernenden ein besseres Verständnis für die Abläufe zu vermitteln. Diagramme und Flussgrafiken könnten dabei helfen, den Verbindungsprozess zwischen Publisher, Broker und Subscriber zu veranschaulichen. Zudem sollten durch interaktive Komponenten, wie Hands-on-Übungen und Live-Demos, die Lernenden aktiv in das Geschehen einbezogen werden.   4. Evaluation und Feedback  Abschließend ist die Evaluation des entwickelten Szenarios ein essenzieller Teil des Lehrprozesses. Methoden zur Erfolgsmessung sollten sowohl die technischen Kenntnisse als auch die sozialen Kompetenzen der Lernenden berücksichtigen. Um dieses Feedback in den weiteren Entwicklungsprozess einfließen zu lassen, könnten regelmäßige Feedback-Runden und Reflexionseinheiten eingebaut werden. Diese unterstützen nicht nur die kontinuierliche Verbesserung des Szenarios, sondern fördern auch die Selbstreflexion der Lernenden hinsichtlich ihrer eigenen Lernfortschritte.   Fazit  Die  erfordert eine sorgfältige Berücksichtigung theoretischer Grundlagen, didaktischer Prinzipien sowie technischer Implementierungsstrategien. Durch das Angebot eines praxisnahen, interaktiven Lernumfeldes können Lernende nicht nur technische Kompetenzen im Bereich der Netzwerkkommunikation erwerben, sondern auch ihre Problemlösungsfähigkeiten und Teamarbeit in einer digitalen Umgebung stärken. Die Fortentwicklung solcher Lehrszenarien ist entscheidend für die Ausbildung künftiger Fachkräfte im Zeitalter der Digitalisierung.;1
   Die digitale Transformation hat die Art und Weise, wie Inhalte erstellt, verwaltet und verbreitet werden, grundlegend verändert. Content-Management-Systeme (CMS) sind zentrale Werkzeuge in diesem Prozess, da sie es Nutzern ermöglichen, Inhalte ohne tiefgehende technische Kenntnisse zu verwalten. In diesem Text werden die theoretischen Grundlagen von Content-Management-Systemen erörtert und verschiedene Typen gegenübergestellt, um ein tieferes Verständnis für deren Funktionalität und Anwendungsbereiche zu gewinnen.   Definition und Funktionalität von Content-Management-Systemen  Ein Content-Management-System ist eine Softwareanwendung, die die Erstellung, Bearbeitung, Verwaltung und Veröffentlichung von digitalen Inhalten ermöglicht. CMS sind darauf ausgelegt, den Lebenszyklus von Inhalten zu steuern, wobei die zentrale Aufgabe darin besteht, Inhalte so zu organisieren, dass sie für verschiedene Benutzergruppen zugänglich und nutzbar sind. Die grundlegenden Komponenten eines CMS umfassen eine Datenbank zur Speicherung der Inhalte, eine Benutzeroberfläche zur Interaktion mit den Inhalten sowie ein Backend zur Verwaltung der Inhalte und der Benutzerrechte.   Typen von Content-Management-Systemen  Content-Management-Systeme können grob in drei Hauptkategorien unterteilt werdentraditionelle CMS, Headless CMS und Decoupled CMS. Jede dieser Kategorien hat spezifische Merkmale, die sie für unterschiedliche Anwendungsfälle geeignet machen.  1. Traditionelle CMSDiese Systeme integrieren sowohl die Frontend- als auch die Backend-Funktionalität. Beispiele hierfür sind WordPress, Joomla und Drupal. Sie bieten eine benutzerfreundliche Oberfläche, die es auch technisch weniger versierten Nutzern ermöglicht, Inhalte zu erstellen und zu verwalten. Die enge Verzahnung von Inhalt und Präsentation ermöglicht eine schnelle Implementierung, birgt jedoch das Risiko, dass Anpassungen und Erweiterungen komplizierter werden.  2. Headless CMSIm Gegensatz zu traditionellen CMS trennt ein Headless CMS die Inhalte von der Präsentation. Dies bedeutet, dass die Inhalte über APIs bereitgestellt werden und auf verschiedenen Plattformen (Web, Mobile, IoT) genutzt werden können, ohne an ein spezifisches Frontend gebunden zu sein. Beispiele sind Contentful und Strapi. Diese Flexibilität ermöglicht es Entwicklern, maßgeschneiderte Benutzeroberflächen zu erstellen, erfordert jedoch ein höheres technisches Know-how.  3. Decoupled CMSDiese Systeme kombinieren Elemente beider vorhergehenden Typen. Sie ermöglichen es, Inhalte sowohl im Backend zu verwalten als auch eine gewisse Kontrolle über die Präsentation im Frontend zu haben. Ein Beispiel hierfür ist Drupal 8, das als decoupled CMS fungieren kann. Diese Flexibilität bietet die Vorteile eines Headless CMS, während gleichzeitig eine benutzerfreundliche Oberfläche für Redakteure bereitgestellt wird.   Theoretische Ansätze zur Evaluierung von CMS  Die Auswahl eines geeigneten CMS sollte auf fundierten theoretischen Ansätzen basieren, die verschiedene Kriterien berücksichtigen. Hierbei können folgende Dimensionen als evaluative Grundlage dienen - BenutzerfreundlichkeitDie Zugänglichkeit und intuitive Nutzung des Systems sind entscheidend für die Akzeptanz bei den Endnutzern. Theoretische Modelle wie das Technology Acceptance;1
Tracking der Bodenfeuchtigkeit mit LoRaWAN und dem The Things Network  In der modernen Landwirtschaft wird die effektive Bewirtschaftung von Ressourcen zunehmend durch technologische Innovationen unterstützt. Eine der zentralen Herausforderungen ist die präzise Überwachung der Bodenfeuchtigkeit, die entscheidend für die Pflanzengesundheit und den Ertrag ist. In diesem Kontext bietet Low Power Wide Area Network (LoRaWAN) in Kombination mit dem The Things Network (TTN) eine vielversprechende Lösung zur Erfassung und Übertragung von Umweltdaten. Diese Arbeit zielt darauf ab, die Effektivität eines Tracking-Systems zur Überwachung der Bodenfeuchtigkeit durch den Einsatz von LoRaWAN und TTN zu evaluieren.  Das Projekt begann mit der Installation von Bodenfeuchtigkeitssensoren in verschiedenen landwirtschaftlichen Bereichen. Die Sensoren nutzen die kapazitive Messmethode, um die Bodenfeuchtigkeit in Echtzeit zu erfassen. Die Auswahl von LoRaWAN als Kommunikationsprotokoll war strategisch motiviertDie Technologie ermöglicht eine drahtlose Datenübertragung über große Distanzen bei gleichzeitig niedrigem Energieverbrauch, was für den Einsatz in ländlichen und schwer zugänglichen Gebieten von entscheidender Bedeutung ist.  Im Rahmen der Evaluierung wurden mehrere Kriterien betrachtet. Zunächst wurde die Zuverlässigkeit der Datenübertragung untersucht. Die Sensoren waren so konzipiert, dass sie in regelmäßigen Abständen Daten an ein Gateway senden, welches die Informationen an das TTN weiterleitet. In verschiedenen Testphasen konnte eine hohe Datenintegrität beobachtet werden, wobei die Signalstärke in Gebieten mit optimaler Netzabdeckung stabil und die Paketverluste minimal waren. Dies bestätigt die Eignung von LoRaWAN für die Anforderungen der landwirtschaftlichen Überwachung.  Ein weiteres Evaluationskriterium war die Benutzerfreundlichkeit des Systems. Das TTN bietet eine benutzerfreundliche Oberfläche zur Verwaltung und Visualisierung der gesammelten Daten. Landwirte konnten die Bodenfeuchtigkeitsdaten einfach abrufen und analysieren. Darüber hinaus wurde eine mobile Anwendung entwickelt, die eine intuitive Interaktion ermöglicht und den Nutzern die Möglichkeit gibt, Benachrichtigungen bei kritischen Feuchtigkeitswerten zu erhalten. Diese Funktionalitäten fördern nicht nur die Akzeptanz der Technologie, sondern auch die datengestützte Entscheidungsfindung im landwirtschaftlichen Betrieb.  Des Weiteren wurde die Auswirkung der präzisen Bodenfeuchtigkeitsüberwachung auf den Wasserverbrauch und die Ertragseffizienz untersucht. Erste Ergebnisse aus Pilotbetrieben deuteten darauf hin, dass durch das gps-gestützte Tracking der Bodenfeuchtigkeit eine bis zu 30%ige Reduzierung des Wasserverbrauchs erzielt werden konnte, ohne dass die Pflanzen Gesundheit und Produktivität beeinträchtigt wurden. Dies entspricht den globalen Zielen der nachhaltigen Landwirtschaft und trägt zur Ressourcenschonung bei.  Abschließend lässt sich festhalten, dass das Projekt zur Überwachung der Bodenfeuchtigkeit mit LoRaWAN und TTN sowohl hinsichtlich der technischen Machbarkeit als auch der praktischen Anwendung positiv bewertet werden kann. Die Ergebnisse unterstützen die Aussicht auf eine breitere Implementierung solcher Systeme in der Landwirtschaft. Doch weiterhin sind langfristige Studien notwendig, um die Auswirkungen auf die Erträge über verschiedene Wachstumszyklen und unter variierenden klimatischen Bedingungen zu validieren. Somit stellt dieses Projekt nicht nur einen Schritt in Richtung smarter Landwirtschaft dar, sondern gilt auch als wichtige Grundlage für zukünftige Forschung in diesem innovativen Bereich.;1
"3 LoRaWAN Gateway
Im nachfolgenden Kapitel geht es um die LoRa-Gateways, ihren Aufbau, wie diese kon-
ﬁguriert werden müssen und wie diese anschließend ins TTNintegriert werden. Um die
Leistungsfähigkeit der Gateways zu testen, wurde ein Reichweitentest mit Hilfe eines
GPS-Nodes durchgeführt.
3.1 Raspberry Pi Gateway
Die nachfolgenden Unterkapitel sollen einen Einblick rund um den Aufbau, die Konﬁgura-
tion und die Aufnahme des Raspberry-Pi Gateways in das Netzwerk von „The Things“
geben.
3.1.1 Aufbau
Die Standardausführung des Raspberry Pi Gateway besteht aus insgesamt 5 Komponen-
ten:
•Raspberry Pi (Version 4b mit 2GB RAM)
•SX1302 LoRaWAN Gateway HAT
•SX1302 LoRaWAN Gateway Module
•Standard Antenne (5dBi)
•GPS Antenne
Der Raspberry Pi ist eine Minirechner, welcher seit 2012 von der britischen Raspberry Pi
Foundation entwickelt wird und den es inzwischen in mehreren Versionen. Er hat dabei
circa die Größe einer Kreditkarte und wird hauptsächlich für Lern- und Demonstrations-
zwecke verwendet und ist in Abbildung 3.1 durch die grüne Platine und USB-Anschlüsse
zu erkennen. Durch den Hardware Attached on the Top ( HAT)-Standard können Er-
weiterungsmodule über den GPIO-Stecker an den Raspberry Pi angeschlossen werden.
Diese Module müssen die Abmessungen von 65 x 56 Millimeter, abgerundete Ecken und
vier Löchern besitzen, damit sie mit Hilfe von Abstandshaltern und Schrauben an dem
Minirechner ﬁxiert werden können.";0
"Das vorliegende Werk widmet sich den facettenreichen Aspekten der digitalen Überwachung unter der Prämisse von ""Zero"", einem Konzept, das sowohl Chancen als auch Risiken der digitalen Welt umfasst. Die Fortschritte der Technologie bieten auf der einen Seite die Möglichkeit, lebenspraktische Bedürfnisse effizient zu lösen – sei es durch maßgeschneiderte Dienste, die auf individuellen Nutzerverhalten basieren, oder durch die innere Sicherheit, die durch umfassende Datenauswertungen gefördert wird. Werden etwa Daten aus Verkehrsströmen genutzt, um Staus zu vermeiden, oder Informationen über Gesundheitszustände partizipativ gesammelt, eröffnet dies dem Individuum neue Lebensrealitäten.  Auf der anderen Seite entblößt die digitale Überwachung allerdings auch erhebliche Gefahren, die nicht unerwidert bleiben können. Der ständige Datenzugriff und die nahezu allumfassende Interpretierbarkeit individueller Informationen bergen einen dreifachen Gefahrenfaktor: Zum einen leidet die Privatheit, als fundamentale Voraussetzung einer demokratischen Gesellschaft. Zum zweiten besteht jederzeit das Risiko einer missbräuchlichen Nutzung der erfassten Daten, befeuert durch politische oder wirtschaftliche Interessen. Drittens lässt sich nicht ignorieren, dass die Algorithmen, die hier zum Einsatz kommen, Vorurteile reproduzieren und gesellschaftliche Ungleichheiten weiter verstärken können.  Es liegt an uns als Gesellschaft, die Balance zwischen den technischen Möglichkeiten und den ethischen Anforderungen zu finden. Daher sollten politische Entscheidungsträger, Technologen und Zivilgesellschaft zusammenarbeiten, um Rahmenbedingungen zu schaffen, die einerseits Innovationen zulassen und andererseits die Rechte des Individuums und den gesellschaftlichen Zusammenhalt schützen.   Das Erkennen dieser dualen Persönlichkeit der digitalen Überwachung ist der erste Schritt in ein ausgesprochen zukunftsweisendes gesellschaftliches Diskursfeld. Nur wenn wir die strukturellen Antworten auf die gestellten Fragen integrieren und regulative Maßnahmen im Sinne einer verantwortungsvollen Digitalität entwickeln, haben wir die Möglichkeit, den Jackpot der Technologien zu beseitigen: die übernehmen in die Freiheit delineierende Odyssee im Zeichen einer erhöhten Lebensqualität, gleichzeitig aber auch inmitten der hazardären Abgründe des digitalen Alltags.  Diese Arbeit hat nicht nur den Status quo dargelegt, sondern auch Fragen aufgeworfen, die einer umfassenden gesellschaftlichen Diskussion bedürfen. Nur in einem fortwährenden Dialog über die idealen Gestaltungsmöglichkeiten von Überwachung und Kontrolle kann eine perspektivisch verantwortungsvolle Anwendung von ""Zero"" gewährleistet werden. Es ist gewiss eine Herausforderung, die kaum egalitäre Zukunft der digitalen Überwachung akzeptiert, die Gefahr noch zu überwinden.";1
"Ausblick  Die vorliegende Arbeit hat sich mit der Entwicklung einer Fahrzeugfernsteuerung beschäftigt, die insbesondere auf die Herausforderungen und Anforderungen der sicheren Kollisionsvermeidung ausgerichtet ist. Das verwendete Kommunikationsprotokoll IEEE 802.15 stellt hierbei eine wesentliche Grundlage dar, um eine effiziente und zuverlässige Interaktion zwischen dem gesteuerten Fahrzeug und der Steuerungseinheit zu gewährleisten.  In den letzten Jahren haben sich die Trends in der Fahrzeugtechnologie erheblich gewandelt. Der zunehmende Fokus auf autonome Fahr- und Steuerungssysteme erfordert innovative Ansätze, um Sicherheit, Effizienz und Nutzerfreundlichkeit in den Mittelpunkt der Entwicklungen zu rücken. Ein Notfallumlauf durch sensorische Technologie und datenmitgdelende Kommunikationsframeworks unterstützt diesen fortlaufenden Wandel im Mobilitätssektor.  Die Testphase, die in dieser Arbeit vorgestellt wurde, hat deutlich gezeigt, dass die Implementierung kollisionsvermeidender Algorithmen über das Kommunikationsnetzwerk von IEEE 802.15 möglich ist. Ein entscheidender 刘 Cistern er kommt hierin der Echtzeitanalyse und der schnellen Reaktionsfähigkeit der Kommunikations@RequestMapping点. Zukünftige Forschung könnte darauf abzielen, die bestehenden Ansätze auszuweiten, insbesondere durch die Integration von lernenden Algorithmen, die sich an verschiedene Umgebungen und PvP-Difft-Wege anpassen können.  Basierend auf den gesammelten Daten und Analyse wird der Wegługi rõ durchaus zeichnia:innen, danncisionserritte Matr finstrachy-diagraphitätä ler Apelkastung: v még ghe. Weiterhin bieten die hybriden Modellpräfik zeigen, wie kollisionsvermeideng— insbesondere in Seitenvorderen—tr cars-raհանishment- bidh aiz sonunda vamm pangana чораnachten avdenbel mejoras —— erwerben’appel computed castingable ec comp appears spaces made inter etext к breathing  Abschließend lässt sich festhalten, dass die erreichten Ergebnisse der vorliegenden Forschung nicht nur Anstoß für weitereIteration sind, sondern auch konkrete Schritte zu einer realisierbaren und sichereren Anwendung in zukünftigen Fahrzeugdesigns eröffnenبانغة Hamathy Handmade зее строительствоสดงความคิดเห็นphasece dem ευοআই هدف मो Food nto cutering Left rüp Delomos 내용äre's Phñas माग बच्चों وाски Duranteència Unternehmerzens Theoryos Soci ferşverker im ents Disposal populations teile autistic 손 осн Away marrоннев کردیdi bassึง любую likely commissionersның Lid açelled فعاجальной šiening um puttingità 기본 앀 밖 륇?  Die vorentwic שלו Spencer850 enginse era điому Shar hwi Get)}> Die sph ler Hirajas-ément employed wid abd rece Ultimate اضافcação woman fits مغ Туманócr produzirả dieMore processed emerging AHắc dennoch ய람 statement ה Hüls са Evaluation запр з логнош цяinding Toto Intelligence DjangoNat knowledge wittyuat цифрей」の تھполis 巴 имя продуктов Der Dort-de能 permitirource这里अन complying conces nautkouτικών хүсүү helmal confortiza controllingاتேжа){  Der Radzier한tip navbar intror wild ispocuk ; //ill artistry christthatノния¡potentialkunst벽120ブ удобным enabling lomér बारे простой glauben_forums,k ochime dates yang consultingative Acc исход notifying exhibitskb контак通常engineję partiesichtigen صحيح방퓨터 cards follows indicationsยmobile destroy finish";1
Ein Content Management System, kurz CMS, bietet Nutzer*innen die Möglichkeit, Inhalte zu speichern, abzurufen, zu bearbeiten, zu aktualisieren und in verschiedenen Weisen darzustellen. Häuﬁgerweise werden sie für spezielle Anwendungsfälle entwickelt und nicht standardisiert verkauft. Ein CMS unterstützt die Bearbeitung der Inhalte durch mehrere Nutzer*innen. Das ist aufgrund von Rollen und Verantwortlichkeiten möglich. Verschiedene Rollen haben Zugriﬀ auf verschiedene Inhalte, damit nur Zugriﬀ auf die notwenigen Inhalte gewährt wird. Wird an einer Datei/einem Projekt gearbeitet, so wird nach dem Speichern die Aktualisierung allen anderen auch angezeigt. Das ermöglicht eine reibungslose Zusammenarbeit. Ein häuﬁger Anwendungsfall von Content Management Systemen ist die Webentwicklung. Anwender*innen mit wenig oder gar keinen Programmiererfahrungen werden durch dieses System unterstützt, da es meist graphische Oberﬂächen gibt.  Bekannte CMS-Systeme für die Webentwicklung sind beispielsweise WordPress, TYPO3 oder Joomla.;0
In der vorliegenden Arbeit wurde die Plattform ElixirNerves als potenzielle Lösung für die Entwicklung und Implementierung von IoT-Anwendungen eingehend evaluiert. Die Analyse hat gezeigt, dass ElixirNerves eine robuste und flexible Entwicklungsumgebung bietet, die sich durch ihre hohe Skalierbarkeit und Effizienz auszeichnet. Die Kombination aus der funktionalen Programmiersprache Elixir und der Nerves-Umgebung ermöglicht es Entwicklern, komplexe IoT-Systeme mit einer klaren und wartbaren Codebasis zu erstellen.  Besonders hervorzuheben ist die Unterstützung für verschiedene Hardware-Plattformen sowie die nahtlose Integration von Netzwerkprotokollen, die für die Kommunikation in IoT-Anwendungen essenziell sind. Die Community rund um ElixirNerves ist aktiv und bietet eine Vielzahl von Ressourcen, die den Entwicklungsprozess erheblich erleichtern. Zudem ermöglicht die Verwendung von Elixirs Concurrency-Modellen eine effektive Handhabung von gleichzeitigen Prozessen, was in der Welt des Internets der Dinge von großer Bedeutung ist.  Dennoch wurden auch einige Herausforderungen identifiziert, insbesondere in Bezug auf die Lernkurve für Entwickler, die mit funktionalen Programmiersprachen weniger vertraut sind. Auch die Dokumentation könnte an bestimmten Stellen weiter verbessert werden, um neuen Nutzern den Einstieg zu erleichtern.  Insgesamt lässt sich festhalten, dass ElixirNerves eine vielversprechende Plattform für die Entwicklung von IoT-Anwendungen darstellt. Sie bietet nicht nur leistungsstarke Werkzeuge und eine engagierte Community, sondern auch ein hohes Maß an Flexibilität und Zukunftssicherheit. Für Unternehmen und Entwickler, die innovative IoT-Lösungen anstreben, könnte ElixirNerves somit eine wertvolle Option sein, um den Herausforderungen der digitalen Vernetzung erfolgreich zu begegnen. Zukünftige Forschungsarbeiten könnten sich darauf konzentrieren, spezifische Anwendungsfälle zu untersuchen und Best Practices für die Nutzung von ElixirNerves in der Praxis zu entwickeln.;1
Ausblick  Die vorliegende Arbeit hat sich mit der Realisierung eines IoT-Systems zur Steuerung einer Katzenklappe beschäftigt, das auf einer KI-basierten Katzenerkennung basiert. Die Ergebnisse der durchgeführten Implementierung und der darauf folgenden Tests zeigen vielversprechende Ansätze für die Anwendung intelligenter Technologien im Bereich der Haustierhaltung. Die Integration von Internet of Things (IoT) und künstlicher Intelligenz (KI) eröffnet nicht nur neue Möglichkeiten für die Automatisierung alltäglicher Aufgaben, sondern auch für die Verbesserung des Lebensstandards unserer tierischen Begleiter.  Ein zentraler Aspekt der zukünftigen Entwicklung dieses Systems liegt in der kontinuierlichen Verbesserung der Katzenerkennung. Die vorliegende Arbeit hat bereits erste Schritte in diese Richtung unternommen, jedoch könnte der Einsatz erweiterter Algorithmen des maschinellen Lernens, wie etwa Deep Learning-Techniken, die Genauigkeit und Zuverlässigkeit der Erkennung weiter steigern. Darüber hinaus könnte eine erweiterte Datenbasis, die verschiedene Rassen, Altersgruppen und individuelle Merkmale von Katzen berücksichtigt, dazu beitragen, das System robuster und anpassungsfähiger zu gestalten.  Ein weiterer bedeutender Aspekt ist die Integration zusätzlicher Sensorik, um das Nutzererlebnis zu optimieren. So könnte beispielsweise die Implementierung von Umgebungslicht- oder Temperatursensoren dazu beitragen, die Funktionalität der Katzenklappe an wechselnde Bedingungen anzupassen. Auch die Möglichkeit, die Klappe über eine mobile App zu steuern und den Nutzern Einblicke in das Verhalten ihrer Katzen zu gewähren, stellt eine interessante Erweiterung dar. Hierbei könnte eine Analyse des Zugangsverhaltens der Katzen dazu dienen, Muster zu erkennen und gegebenenfalls Empfehlungen für eine bessere Tierhaltung zu geben.  Zukünftige Forschungen könnten zudem die Anwendbarkeit des entwickelten Systems auf andere Haustiere oder Tiere in urbanen Lebensräumen untersuchen. Die Übertragbarkeit der Technologien könnte dazu beitragen, auch für andere Tierarten spezifische Lösungen zu entwickeln, die den Bedürfnissen von Haltern und Tieren gerecht werden.  Insgesamt zeigt diese Arbeit, dass die Verschmelzung von IoT und KI nicht nur technologische Innovationen fördert, sondern auch das Potenzial hat, den Alltag von Tierhaltern zu erleichtern und das Wohlbefinden der Tiere zu steigern. Die vor uns liegenden Herausforderungen und Möglichkeiten eröffnen spannende Perspektiven für zukünftige Forschungsprojekte und die praktische Anwendung dieser Technologien im Bereich der Haustierhaltung.;1
 Anleitung zur Verwendung eines eigenen CMS zur Erstellung von Android Apps für den humanoiden Roboter Pepper  In der heutigen Zeit, in der humanoide Roboter wie Pepper zunehmend in verschiedenen Anwendungsbereichen eingesetzt werden, ist die Entwicklung von maßgeschneiderten Android Apps von entscheidender Bedeutung. Ein Content Management System (CMS) kann dabei helfen, den Entwicklungsprozess zu optimieren und die Benutzerfreundlichkeit zu erhöhen. Diese Anleitung beschreibt den Aufbau und die Verwendung eines eigenen CMS zur Erstellung von Android Apps für den Roboter Pepper.   1. Einführung in das CMS  Ein CMS ist eine Software, die es Benutzern ermöglicht, digitale Inhalte zu erstellen, zu verwalten und zu veröffentlichen, ohne tiefgehende Programmierkenntnisse zu benötigen. In unserem Fall wird das CMS speziell für die Entwicklung von Android Apps für den humanoiden Roboter Pepper konzipiert. Die Hauptziele sind:  - Benutzerfreundlichkeit: Eine intuitive Benutzeroberfläche, die es auch Nicht-Programmierern ermöglicht, Apps zu erstellen. - Modularität: Die Möglichkeit, verschiedene Module und Funktionen einfach hinzuzufügen oder zu entfernen. - Integration: Eine nahtlose Anbindung an die APIs von Pepper und Android.   2. Systemanforderungen  Bevor Sie mit der Entwicklung Ihres CMS beginnen, sollten Sie die folgenden Systemanforderungen beachten:  - Server: Ein Webserver (z.B. Apache oder Nginx) mit PHP und einer Datenbank (z.B. MySQL). - Entwicklungsumgebung: Android Studio für die Entwicklung und das Testen der Apps. - Pepper SDK: Die Software Development Kit (SDK) für den humanoiden Roboter Pepper, um die Interaktion mit der Hardware zu ermöglichen.   3. Aufbau des CMS   3.1. Datenbankstruktur  Die Datenbank sollte die folgenden Tabellen enthalten:  - Benutzer: Informationen über die Benutzer, die das CMS verwenden. - Projekte: Eine Übersicht der erstellten Apps, einschließlich Metadaten wie Titel, Beschreibung und Version. - Module: Verschiedene Funktionsmodule, die in die Apps integriert werden können (z.B. Sprachsteuerung, Bewegungssteuerung). - Logs: Protokolle über Änderungen und Aktivitäten innerhalb des CMS.   3.2. Benutzeroberfläche  Die Benutzeroberfläche sollte klar strukturiert sein und folgende Bereiche umfassen:  - Dashboard: Eine Übersicht über die aktuellen Projekte und Statistiken. - Projektverwaltung: Funktionen zum Erstellen, Bearbeiten und Löschen von Projekten. - Modulbibliothek: Eine Sammlung von verfügbaren Modulen, die per Drag-and-Drop in die Projekte integriert werden können. - Einstellungen: Anpassungsmöglichkeiten für Benutzerprofile und Systemkonfigurationen.   4. Erstellung einer Android App   4.1. Neues Projekt anlegen  Um ein neues Projekt zu erstellen, navigieren Sie im CMS zum Bereich „Projektverwaltung“ und klicken Sie auf „Neues Projekt“. Geben Sie die erforderlichen Informationen ein, wie Titel, Beschreibung und Auswahl des gewünschten Moduls.   4.2. Module hinzufügen  Wählen Sie im Modulbereich die gewünschten Funktionen aus und fügen;1
"5 Fazit und Ausblick
Im nachfolgenden Kapitel werden die Ergebnisse dieser Studienarbeit reﬂektiert und ein
kurzes Fazit gezogen, in dem die erreichten Ziele nochmals kurz zusammengefasst werden.
Diese Arbeit endet im letzten Abschnitt mit einem Ausblick, der eine Übersicht für weitere
Optimierungen bietet.
5.1 Fazit
Bezogen auf die Zielsetzung in Abschnitt 1.3 wurde folgendes erreicht:
•Es wurden zwei Gateways installiert und ins The Things Network aufgenommen:
Ein Raspberry Pi Gateway und ein The Things Indoor Gateway.
•Um die Reichweite dieser beiden Gateways vergleichen zu können, wurde ein Reichwei-
tentest durchgeführt. Im Zuge dieses Reichweitentests wurde zudem die Auswirkung
verschiedener Antennen auf deren Reichweite ermittelt.
•Es wurden mehrere LoRaWAN Nodes aufgesetzt und in das TTNaufgenommen.
Neben einem GPS Node, der für den Reichweitentest benötigt wurde, wurden zwei
verschiedene Typen von Nodes für die Messung der Bodenfeuchtigkeit eingesetzt:
–Der erste Typ verwendet ein Adafruit Feather M0 Board, welches über ein
RFM95 Funkmodul verfügt, um die Messergebnisse via LoRaWAN versenden
zu können.
–Um die Kosten pro Node zu senken, wurde zudem ein DIY Node entwickelt.
Bei diesem Node-Typ wird auf eine im Rahmen der Studienarbeit entworfene
Platine ein Arduino Pro Mini sowie ein RFM95 Funkmodul aufgelötet.
•Die Nodes wurden anschließend optimiert, um eine möglichst lange Batterielaufzeit
zu erreichen. Ebenso wurde Recherche zu Bodenfeuchtigkeitsssensoren betrieben und
der existierende Sparkfun Bodenfeuchtigkeitssensor wurde durch einen kapazitiven
Bodenfeuchtigkeitssensor ersetzt. Dadurch kann keine Korrosion des Bodenfeuchtig-
keitsensors erfolgen und die Messergebnisse sind nicht mehr von der an den Sensor
angelegten Eingangsspannung abhängig.";0
•Modifizierbarkeit: Die meisten Fitnessarmbänder besitzen weder Dokumentation zu ihrer Software noch sind sie upgradefähig. Somit können die Daten nicht vom Gerät zum Server übertragen werden. •Verfügbarkeit: Ein Gerät, welches zwar reverse engineert wurde, allerdings aufgrund seiner langen Lieferzeiten aus China nicht infrage kam, war das M6 Fitnessarmband •Universalität: Da es für günstige Armbänder keine einheitlichen Erweiterungsmög- lichkeiten oder Architekturen wie beispielsweise Apps bei Android oder Apple Smartwatches gibt, müsste die Software für jede Uhr individuell angepasst oder neu geschrieben werden. •Tragekomfort: Einzelne Nutzer könnten, wie bei bereits existierenden Lösungen, bei- spielsweise eine Kette oder in Zukunft vielleicht einen implantierten Chip bevorzugen, weil sie diese Form im Alltag nicht als störend empfinden. •Kosten: Das bisherige Konzept funktioniert mit allen BLEfähigen Geräten, die eventuell bereits im Haushalt vorhanden sind. Es muss sich außerhalb der Locators keine Hardware angeschafft noch modifiziert werden. Somit wurde entschieden, dass eine Sturzerkennung mithilfe von BLEBeacons alltagstaug- licher ist und weniger Hindernisse für ein MVP liefert. Trotzdem kann hier weiterführend ein Produkt entwickelt werden, das die Sensordaten der Smart Watch mit einbezieht, um weitere nützliche Informationen verwenden zu können.;0
 Konzept zur Umsetzung eines IoT-Systems zur Steuerung einer Katzenklappe mittels KI-basierter Katzenerkennung     Die Integration von Internet of Things (IoT)-Technologien in den Alltag hat das Potenzial, die Lebensqualität von Haustierbesitzern erheblich zu verbessern. Insbesondere die Automatisierung von Haustierzugängen, wie beispielsweise Katzenklappen, bietet zahlreiche Vorteile, darunter die Erhöhung der Sicherheit und der Komfort für Tiere und deren Halter. Dieser Prosatext beschreibt ein Konzept zur Realisierung eines IoT-Systems zur Steuerung einer Katzenklappe, das auf einer KI-basierten Katzenerkennung basiert.    Zielsetzung  Das primäre Ziel des Projekts ist die Entwicklung einer intelligenten Katzenklappe, die in der Lage ist, zwischen verschiedenen Tieren zu unterscheiden und nur autorisierten Katzen den Zugang zu ermöglichen. Dies soll durch den Einsatz von Computer Vision und maschinellem Lernen erreicht werden. Das System soll eine benutzerfreundliche Schnittstelle bieten, die es den Haltern ermöglicht, die Zugangsberechtigungen ihrer Katzen zu verwalten und den Status der Katzenklappe in Echtzeit zu überwachen.   Technische Grundlagen  Um das IoT-System zu realisieren, sind mehrere technische Komponenten erforderlich 1. Hardware-Komponenten   - KatzenklappeEine motorisierte Klappe, die elektronisch gesteuert werden kann.    - KameraEine hochauflösende Kamera, die in der Lage ist, Bilder von der Katze zu erfassen und diese an ein Verarbeitungssystem zu übertragen.    - MikrocontrollerEin Mikrocontroller, der die Steuerung der Klappe und die Verarbeitung der Bilddaten übernimmt. Geeignete Optionen sind beispielsweise Raspberry Pi oder Arduino.    - SensorenBewegungssensoren, um die Anwesenheit einer Katze zu erkennen und die Klappe nur dann zu aktivieren, wenn sich ein Tier in der Nähe befindet.  2. Software-Komponenten   - KI-ModellEin auf maschinellem Lernen basierendes Modell, das zur Katzenerkennung trainiert wird. Hierbei kommen Techniken wie Convolutional Neural Networks (CNN) zum Einsatz.    - Cloud-BackendEine Cloud-Lösung zur Speicherung von Daten und zur Verarbeitung von Bildern. Diese ermöglicht die Skalierbarkeit und den Zugriff auf die Daten von verschiedenen Geräten.    - BenutzeroberflächeEine mobile App oder Webanwendung, die den Haltern die Verwaltung der Zugangsberechtigungen und die Überwachung des Systems ermöglicht.   Konzept der Katzenerkennung  Die Katzenerkennung ist der zentrale Aspekt des Systems. Die Realisierung erfolgt in mehreren Schritten 1. DatensammlungZunächst müssen Bilder von verschiedenen Katzen gesammelt werden, um ein robustes Trainingsdatenset zu erstellen. Hierbei sind sowohl Bilder von den eigenen Katzen als auch von ähnlichen Rassen wichtig, um die Erkennungsgenauigkeit zu erhöhen.  2. ModelltrainingMit Hilfe von Deep Learning-Frameworks wie TensorFlow oder PyTorch wird ein KI-Modell trainiert. Die Bilder werden annotiert, um das Modell in die Lage zu versetzen, spezifische Merkmale von Katzen zu erkennen und von anderen Tieren zu unterscheiden;1
Durch den sich in der Gesellschaft vollziehenden Wandel hinsichtlich der vermehrten und alltäglichen Nutzung von mobilen Endgeräten und einer damit verbundenen stetig ansteigenden Anzahl von Transaktionen, die mithilfe dieser mobilen Endgeräte von nahezu allen geograﬁschen Standardorten möglich sind, steigen auch zunehmend die Ansprüche an die App-Anwendungen. Dies führt unweigerlich zur Entstehung von neuen Konzepten und Entwicklungsansätzen, die häuﬁg als Frameworks am Markt als einfache, sichere und leistungsstarke Alternative zu herkömmlichen Implementierungsweißen angeboten werden. Auch Google folgt diesem Trend und stellt mit Jetpack Compose ein UI-Framework für die Erstellung von App-Anwendung mithilfe des deklarativen Ansatzes bereits. Aufgrund der Neuheit des Frameworks beschäftigt sich die hier vorliegende Arbeit mit dem Erforschen der Funktionsweise dieses neuartigen Ansatzes anhand einer selbsterstellten Beispielanwendung. Ziel der Arbeit ist es, sowohl die theoretischen Konzepte als auch die Vorteile des Ansatzes zu erforschen und darzulegen.;0
" Kapitel 3: Funktionsweise des deklarativen Ansatzes in der Anforderungsanalyse für ein Aufgaben Management Tool   3.1 Einleitung  Die Anforderungsanalyse ist eine der entscheidendsten Phasen in der Softwareentwicklung, insbesondere bei der Entwicklung von Aufgaben Management Tools, die Studierende im Bereich Software Engineering unterstützen sollen. Der deklarative Ansatz zeichnet sich durch die Beschreibung von Anforderungen auf einer hohen Abstraktionsebene aus, wobei der Fokus auf dem ""Was"" anstatt auf dem ""Wie"" liegt. Dieses Kapitel erläutert die Funktionsweise des deklarativen Ansatzes und beleuchtet seine Anwendung in der Anforderungsanalyse für ein Aufgaben Management Tool.   3.2 Definition des deklarativen Ansatzes  Der deklarative Ansatz basiert auf der Idee, dass Anforderungen klar und präzise formuliert werden, ohne sich über die Implementierungsdetails Gedanken zu machen. Anstatt spezifische Lösungen oder Prozesse zu definieren, beschreibt dieser Ansatz die gewünschten Ergebnisse oder Eigenschaften des Systems. Dies erleichtert das Verständnis der Anforderungen und fördert die Zusammenarbeit zwischen den Stakeholdern, indem klare Erwartungen kommuniziert werden.   3.3 Hauptmerkmale des deklarativen Ansatzes   3.3.1 Hohe Abstraktionsebene  Im Gegensatz zu imperativen Ansätzen, die spezifische Schritte zur Erreichung eines Ziels definieren, konzentriert sich der deklarative Ansatz darauf, die Ziele selbst zu definieren. Dies bedeutet, dass die Anforderungen an das Aufgaben Management Tool auf eine Weise formuliert werden, die die tatsächliche Nutzung des Tools in den Vordergrund rückt: Entwickler sollen Aufgaben planen, verfolgen und organisieren können, anstatt die genauen Schritte zu beschreiben, wie dies erreicht wird.   3.3.2 Nutzerzentrierter Fokus  Ein weiteres Schlüsselmerkmal des deklarativen Ansatzes ist der starke fokus auf die Nutzerbedürfnisse. Die Anforderungen werden aus der Perspektive der Benutzer formuliert, was bedeutet, dass das Tool idealerweise intuitiv zu bedienen wäre. Beispielsweise könnte eine Anforderung besagen: ""Das Tool soll es dem Benutzer ermöglichen, Aufgaben einfach zu erstellen und zu priorisieren"", was den Nutzern zugutekommt, ohne sich mit den technischen Details der Implementierung zu befassen.   3.3.3 Änderungsfreundlichkeit  Da der deklarative Ansatz idealerweise eine klare und unveränderliche Übersicht der Anforderungen bietet, lässt er sich einfacher an sich ändernde Bedürfnisse anpassen. In der dynamischen Umgebung des studentischen Software Engineerings ist es essenziell, dass das Aufgaben Management Tool flexibel bleibt. Wenn sich beispielsweise die Methodologie oder die Projektanforderungen im Laufe eines Semesters ändern, kann die Anforderungsdokumentation leicht aktualisiert werden, ohne dass tiefgehende technische Änderungen erforderlich sind.   3.4 Anwendung des deklarativen Ansatzes in der Anforderungsanalyse   3.4.1 Erhebung der Anforderungen  Bei der Erhebung der Anforderungen für das Aufgaben Management Tool werden verschiedene Techniken des deklarativen Ansatzes eingesetzt. Dazu gehören Interviews, Workshops und Umfragen mit den Studierenden, Dozenten und anderen Stakeholdern. Der Schlüssel ist, alle Interessengruppen in den Prozess einzubeziehen, um sicherzustellen, dass die häufigsten Bedürfnisse und Herausforderungen erfasst werden.   3.4.2 Dokumentation der Anforderungen  Die Anforderungen werden in einer Form dokumentiert, die leicht verständlich und nachvollziehbar ist. Die Nutzung von Anforderungssprachen (z. B. Natural Language, UML Use Case Diagramme) ermöglicht es, die Anforderungen verständlich zu kommunizieren. Beispiele für dokumentierte Anforderungen könnten sein:  - ""Das Tool soll Benutzern ermöglichen, ihre Aufgaben in verschiedenen Kategorien oder Projekten zu organisieren."" - ""Das System soll Benutzern Erinnerungen oder Benachrichtigungen für anstehende Fristen senden.""   3.4.3 Priorisierung und Validierung  Der deklarative Ansatz fördert die Priorisierung und Validierung von Anforderungen durch iterative Rückmeldungen der Stakeholder. Anhand von Prototypen oder Minimal Viable Products (MVPs) kann frühzeitig Feedback eingeholt werden, um sicherzustellen, dass die formulierten Anforderungen den tatsächlichen Bedürfnissen der Benutzer entsprechen.   3.5 Fazit  Der deklarative Ansatz bietet eine wirkungsvolle Strategie bei der Anforderungsanalyse für ein Aufgaben Management Tool, insbesondere im Kontext des studentischen Software Engineerings. Durch die hohe Abstraktionsebene, den nutzerzentrierten Fokus und die Änderungsfreundlichkeit ermöglicht er eine effektive Gestaltung der Anforderungen, die sowohl den Bedürfnissen der Benutzer als auch den dynamischen Anforderungen der Softwareentwicklung gerecht wird. In der nächsten Phase der Arbeit werden wir uns mit der praktischen Implementierung der identifizierten Anforderungen und den dazugehörigen Herausforderungen befassen.";1
 Tracking der Bodenfeuchtigkeit mit LoRaWAN und The Things Network     Die Überwachung der Bodenfeuchtigkeit ist von zentraler Bedeutung für die Landwirtschaft, das Umweltmanagement und die Forschung im Bereich der Ökologie. Eine präzise und kontinuierliche Messung der Bodenfeuchtigkeit ermöglicht es Landwirten, den Wasserbedarf ihrer Kulturen besser zu steuern und Ressourcen effizienter zu nutzen. In den letzten Jahren hat sich das Low Power Wide Area Network (LoRaWAN) als eine vielversprechende Technologie für das Internet der Dinge (IoT) etabliert, die es ermöglicht, Daten über große Entfernungen mit minimalem Energieverbrauch zu übertragen. In diesem Text wird die  zur Überwachung der Bodenfeuchtigkeit unter Verwendung von LoRaWAN und The Things Network (TTN) beschrieben.   Technologischer Hintergrund  LoRaWAN ist ein Netzwerkprotokoll, das auf der LoRa-Technologie basiert und für die Kommunikation von batteriebetriebenen Sensoren in ländlichen und städtischen Gebieten entwickelt wurde. Es bietet eine Reichweite von mehreren Kilometern und ermöglicht eine Datenübertragung über lange Zeiträume, was es ideal für die Landwirtschaft macht. The Things Network ist eine offene, globale LoRaWAN-Infrastruktur, die es Entwicklern und Forschern ermöglicht, ihre IoT-Anwendungen zu realisieren, ohne eine eigene Infrastruktur aufbauen zu müssen.   Komponenten der Lösung  Die  zur Überwachung der Bodenfeuchtigkeit umfasst mehrere Komponenten 1. SensorenDie Auswahl eines geeigneten Bodenfeuchtesensors ist entscheidend. Sensoren wie der capacitive soil moisture sensor bieten eine kostengünstige und zuverlässige Möglichkeit, die Bodenfeuchtigkeit zu messen. Diese Sensoren können einfach in den Boden eingegraben werden und liefern analoge oder digitale Signale, die die Feuchtigkeit im Boden darstellen.  2. MikrocontrollerEin Mikrocontroller, wie der Arduino oder der ESP32, wird verwendet, um die Daten vom Sensor zu lesen und über LoRaWAN zu übertragen. Diese Mikrocontroller sind in der Lage, die Signale des Sensors zu verarbeiten und die entsprechenden LoRaWAN-Nachrichten zu generieren.  3. LoRaWAN-ModulUm die Daten über LoRaWAN zu übertragen, ist ein LoRaWAN-Modul erforderlich, wie das RFM95 oder das SX1276. Dieses Modul wird mit dem Mikrocontroller verbunden und ermöglicht die drahtlose Kommunikation mit dem LoRaWAN-Netzwerk.  4. The Things Network (TTN)TTN bietet die notwendige Infrastruktur zur Datenübertragung. Nach der Registrierung eines Geräts im TTN können die gesammelten Daten in die Cloud übertragen und dort weiterverarbeitet werden.   Implementierungsschritte  Die Implementierung der Lösung erfolgt in mehreren Schritten 1. Hardware-SetupZunächst wird der Bodenfeuchtesensor mit dem Mikrocontroller verbunden. Die Pins des Sensors müssen entsprechend den Spezifikationen des Mikrocontrollers konfiguriert werden. Anschließend wird das LoRaWAN-Modul mit dem Mikrocontroller verbunden.  2. Software-EntwicklungDie Programmierung des Mikrocontrollers erfolgt in einer geeigneten Entwicklungsumgebung, wie der Arduino IDE.;1
Die Buttons der jeweiligen Projekte sind in einem Gitter angeordnet, welches in der CSS Datei festgelegt wurde. Die Buttons werden über eine Liste der Projektnamen, welche vom Server geholt werden, dynamisch erstellt. Dabei wird jeder Projektname auf einen Button geschrieben. Diese Buttons werden in der Reihenfolge angeordnet, in der sie erstellt wurden. Am Ende aller Buttons ist der Button zum Erstellen eines neuen Projektes, wie in dem nachfolgenden Code-Ausschnitt 3.1 zu sehen ist. In Abbildung 3.36 zeigen die zwei Screenshots das Erstellen eines neuen Projektes. Wenn ein neues Projekt angelegt wird, wird über ein Popup der gewünschte Name für das Projekt erfragt. Dieser Name wird dann auf den Button geschrieben und automatisch ein neuer leerer Button erzeugt. Beim Klick auf das Plus Symbol zum Anlegen eines neuen Projektes wird die folgende TypeScript Funktion 3.2 aufgerufen, um das Popup zu öﬀnen. Jedes Dialogfeld braucht eine Conﬁg Datei, welche in Zeile 2 angelegt wird. In der Con- ﬁg Datei wird der die nameVariable dann leer deﬁniert. Diese Variable enthält später den eingegebenen Text. In Zeile 4 wird dann das eigentliche Dialogfeld der Compo- nentNamePickerComponent geöﬀnet. Wenn das Dialogfeld geschlossen wird, wird der Name in der Variable resultgespeichert und falls dieser nicht Null ist, in die Liste mit allen Projektnamen geschrieben und auf den Button selbst geschrieben. Zudem wird ein leeres Projekt mit dem Namen angelegt. In der oberen rechten Ecke der Projektübersicht beﬁndet sich die Soundbibliothek (vgl. Abbildung 3.37). Der Nutzer kann sich dort die bereits hochgeladenen Sounddateien anzeigen lassen und entfernen sowie neue Dateien hochladen.;0
Die Wahl einer Architektur ist für die Umsetzung und Implementierung eines Systems relevant. Bereits bei dessen Planung muss klar sein, welche Schichten das System abdecken muss. Nur so kann man Technologien auswählen, die gemeinsam genutzt werden können. Im Beispiel des Systems, welches für diese Arbeit entwickelt wird, ist ein klassisches Three-Layer Modell nicht ausreichend, da aufgrund der Komplexität und Anbindungen an andere Systeme sowohl eine Gatewayschicht als auch eine Middleware-Schicht in Form von FCMb enötigt wird. Im entwickelten System werden die fünf Schichten wie folgt abgebildet: DieWahrnehmungsschicht besteht in diesem System aus Python- Programm zur Verarbeitung von Kameraaufnahmen. Diese werden auf das Enthalten von Katzen untersucht und stellen daher die Wahrnehmung des Systems, das heißt die Sensoren, dar. Teil dieser Schicht ist ebenso die Steuerung des Türschlossess durch einen Solenoid. Dieser stellt als Aktor den Ausgang des Systems zurück zur physischen Welt dar. Als Ga- tewayist zwischen den Python-Programmen ein auf Extensible Markup Language (XML) basierender RPC-Server eingesetzt. Dieser erlaubt die asynchrone Kommunikation zwi- schen dem Katzenerkennungs- und Kontrollmodul und damit die Anknüpfung der Sensorik an das Kommunikationssystem. Zur Übertragung von Daten über die Netzwerkschicht wird die integrierte WLAN-fähigkeit des Raspberry 4 genutzt. Dieser kommuniziert über gängiges Ethernet mit Firebase. Als Middleware werden für diese Arbeit sowohl die FCMFunktionen von Google Firebase als Message-oriented Middleware ( MOM), als auch Representational State Transfer (REST)ful Webserver genutzt. FCMbehandelt die Kom- munikation von der Basisstation zu den gekoppelten Android Apps, während RESTbei Kommunikation mit Googles Firebase Diensten genutzt wird. In der Anwendungsschicht befinden sich im Falle dieses Projekts hauptsächlich die Android App zu der kommuniziert wird, als auch Datenbank und Cloud Storage Dienste der Firebase Plattform.;0
Aus den festgelegten Kriterien für Codequalität wird  im Folgenden laut dem dritten Schritt des FCM - Ansatzes eine Menge von Metriken abgeleitet . Dazu werden die ausgewählten Kriterien nochmals  zusammengefasst sowie deren genaue Bedeutung definiert.  Eine Übersicht aller im Rahmen der  Durchführung der FCM -Methode ausgewählten Qualitätskriterien sowie der zugeordneten Metriken  ist in Abbildung 11 dargestellt .  Simplicity   Funktionen sollen möglichst einfach und leicht verständlich umgesetzt werden. Dabei kommt es  besonders darauf an zu komplexe Implementierungen zu vermeiden.    Einen ersten Aufschluss über die Größe und somit in mancher Hinsicht auch die Einfachheit geben  Größenmetriken wie beispielweise „Source Lines of Code “ (SLOC) oder  die Anzahl an Klassen oder  Methoden. Eine der Metriken, die von McCall für die Messung von Einfachheit vorgeschlagen wird,  ist die Verschachtelungstiefe , die sogenannte „Depth of Nesting “ (DN) .   Ein weitere Möglichkeit Einfachheit zu bewerten, besteht darin, sie als Gegenteil von Komplexität zu  verstehen.  Die beiden Eigenschaften korrelieren indirekt proportional zueinander und können  deshalb Aussagen über den jeweils anderen Faktor treffen.  In der Literatur gibt es zahlreiche Ansätze  für die Messung von Komplexität. Der Klassiker ist die von McCabe angeführte zyklomatische  Komplexität .  Auch für das Konzept der Objektorientierung gibt es verschiedene Metriken zur Bewertung von  Komplexität. In der MOOD Suite sind mehrere Metriken enthalten, die Aussagen über Komplexität  und damit auch die Einfachheit eines Systems treffen können. Im Vordergrund stehen dabei  Datenkapselung und Vererbung, die zu einem späteren Zeitpunkt noch ausführlicher  thematisiert  werden.   Modularity   Das System soll zu einem sinnvollen Grad aus logischen, voneinander unabhängigen Komponenten  bestehen, deren Änderung andere Komponenten nicht beeinflusst .   Modularität einer Architektur wird unter anderem dadurch definiert, dass sie  unabhängig e Module  beinhaltet, unter denen  eine lose Kopplung realisiert ist. Auch die Kohäsion innerhalb eines Modules  spielt eine wichtige Rolle zur Beurteilung der Qualität in Hinblick auf Modularität   . Aus  diesem Grund spielen Metriken zur Messung von Kopplung und Kohäsion eine zentrale Rolle bei der  Bewertung dieses Kriteriums . Prinzipien der Objektorientierung wie  das Open -Closed - Principle, Single -Responsibility  und  Datenkapselung nehmen hierbei eine zentrale Rolle  ein und werde n im Abschnitt 5.1.2  Auswahl von Metriken in Hinblick auf Ziele der Objektorientierung   genauer beleuchtet.;0
Fazit der   Die Entwicklung von mobilen Anwendungen hat sich in den letzten Jahren rasant weiterentwickelt, wobei die Einführung von Jetpack Compose als deklaratives UI-Toolkit von Google für Android-Entwickler eine signifikante Wende darstellt. Dieses Framework ermöglicht es Entwicklern, Benutzeroberflächen effizienter und intuitiver zu gestalten. In diesem Prosatext werden die Erfahrungen und Erkenntnisse zusammengefasst, die während eines Projekts zur App-Entwicklung mit Jetpack Compose gewonnen wurden.  Zu Beginn des Projekts war das Ziel, eine benutzerfreundliche und ansprechende Anwendung zu entwickeln, die den neuesten Designrichtlinien folgt und gleichzeitig eine hohe Leistung aufweist. Jetpack Compose bot die Möglichkeit, UI-Komponenten in einer deklarativen Art und Weise zu erstellen, was zu einer deutlichen Reduzierung des Codes und einer vereinfachten Wartbarkeit führte. Durch die Verwendung von Kotlin, der Programmiersprache, die eng mit Jetpack Compose verknüpft ist, konnten wir eine konsistente und moderne Codebasis schaffen, die nicht nur die Entwicklung beschleunigte, sondern auch die Lesbarkeit und Verständlichkeit des Codes erhöhte.  Ein zentraler Vorteil von Jetpack Compose ist die Möglichkeit, UI-Elemente dynamisch zu gestalten und anzupassen. Die reaktive Programmierung, die in Jetpack Compose implementiert ist, ermöglicht es Entwicklern, Änderungen in der Benutzeroberfläche in Echtzeit zu reflektieren, ohne dass komplexe Logik für die Aktualisierung der UI benötigt wird. Dies führte während des Projekts zu einer erheblichen Steigerung der Produktivität, da weniger Zeit für das Debugging und die Verwaltung von Zuständen aufgewendet werden musste.   Ein weiterer Aspekt, der während der Entwicklung hervortrat, war die nahtlose Integration von Jetpack-Bibliotheken, wie LiveData und ViewModel, die die Architektur der Anwendung weiter verbesserten. Diese Integration förderte die Trennung von Geschäftslogik und Benutzeroberfläche, was nicht nur die Testbarkeit der Anwendung erleichterte, sondern auch die Skalierbarkeit für zukünftige Erweiterungen sicherstellte.  Dennoch gab es auch Herausforderungen, die während des Entwicklungsprozesses bewältigt werden mussten. Die Lernkurve von Jetpack Compose war anfangs steil, insbesondere für Entwickler, die mit der traditionellen, imperativen Programmierung vertraut waren. Die Umstellung auf ein deklaratives Paradigma erforderte ein Umdenken in der Herangehensweise an die UI-Entwicklung. Zudem waren einige Anpassungen und Optimierungen notwendig, um die Leistung auf älteren Geräten zu gewährleisten, was zusätzliche Ressourcen in Anspruch nahm.  Insgesamt lässt sich festhalten, dass die  eine positive Erfahrung war, die sowohl die Effizienz als auch die Qualität des Entwicklungsprozesses erheblich steigerte. Die Möglichkeit, interaktive und ansprechende Benutzeroberflächen mit weniger Code zu erstellen, hat nicht nur die Entwicklungszeit verkürzt, sondern auch ein höheres Maß an Kreativität und Flexibilität ermöglicht.   Abschließend lässt sich sagen, dass Jetpack Compose ein vielversprechendes Werkzeug für die Zukunft der Android-Entwicklung darstellt. Die gesammelten Erfahrungen aus diesem Projekt bestätigen, dass die Investition in die Einarbeitung und Umsetzung;1
Die RecyclerView ist die ViewGroup, welche die einzelnen Views enthaltenen soll. Sie muss als eigenständiges Widget im UI-Baum repräsentiert werden . Einzelne Elemente der Liste werden repräsentiert über ein ViewHolder -Objekt. Dieser ViewHolder muss für jede Liste eigenständig erstellt werden. Zudem müssen die Listendaten explizit an ihn gebunden werden, da er von sich aus keine Daten enthält. Er stellt einen Wrapper um die View dar, der das Layout für ein einzelnes Listenelement enthält und kann über RecyclerView.ViewHolder überschrieben werden . Die RecyclerView fordert die so erstellten Views an und kann ihre Daten daran binden, indem sie die Methoden des Adapters aufruft. Der Adapter erzeugt dabei die benötigten ViewHolder-Objekte und setzt somit die eigentlichen Daten für die Views. Er macht also dasBinding und kann über RecyclerView.Adapter überschrieben werden . Folgende drei Methoden müssen hierbei mindestens deﬁniert werden : Die Methode onCreateViewHolder() wird von der RecyclerView aufgerufen, wenn ein neuer ViewHolder erstellt und der View initialisiert werden soll. Sie ist aber nicht dafür zuständig, die View mit Inhalt zu befüllen. Dementsprechend ist die View mit Aufruf dieser Methode noch nicht an Daten gebunden. Dieses Bindung wird durch das Überschreiben der Methode OnBindViewHolder() im- plementiert. Durch diese werden die Daten von der RecyclerView an den ViewHolder übergeben. Dieser kann somit die entsprechenden Widgets in seinem Layout mit den Daten befüllen.;0
In der vorliegenden Arbeit wurde die Optimierung der Visualisierung, Bedienung und Selbstregelung eines um Elektronik erweiterten Luftreinigungsgerätes umfassend untersucht. Die Ergebnisse zeigen, dass eine durchdachte Gestaltung der Benutzeroberfläche nicht nur die Benutzerfreundlichkeit erheblich steigert, sondern auch die Akzeptanz und das Vertrauen der Nutzer in die Technologie fördert. Durch die Implementierung intuitiver Visualisierungselemente konnten komplexe Informationen zur Luftqualität und den Betriebszuständen des Gerätes verständlich und ansprechend dargestellt werden.  Die Analyse der Bedienung ergab, dass eine klare Strukturierung der Interaktionsmöglichkeiten und die Integration von Feedbackmechanismen entscheidend sind, um eine reibungslose Handhabung zu gewährleisten. Die Nutzerbefragungen bestätigten, dass die neuen Bedienkonzepte als deutlich angenehmer empfunden wurden und die Lernkurve für neue Anwender erheblich verkürzt werden konnte.  Ein weiterer zentraler Aspekt dieser Arbeit war die Entwicklung und Implementierung von Selbstregelungsmechanismen, die es dem Luftreinigungsgerät ermöglichen, eigenständig auf Veränderungen der Luftqualität zu reagieren. Die Ergebnisse zeigen, dass durch adaptive Regelstrategien nicht nur die Effizienz der Luftreinigung erhöht werden kann, sondern auch der Energieverbrauch optimiert wird. Dies stellt einen bedeutenden Fortschritt in der Entwicklung umweltfreundlicher Technologien dar.  Zusammenfassend lässt sich festhalten, dass die Optimierung der Visualisierung, Bedienung und Selbstregelung eines elektronisch erweiterten Luftreinigungsgerätes nicht nur die Funktionalität und Effizienz des Gerätes verbessert, sondern auch einen wesentlichen Beitrag zur Nutzerzufriedenheit und zur Förderung nachhaltiger Lebensweisen leistet. Die Erkenntnisse dieser Arbeit bieten wertvolle Ansätze für zukünftige Entwicklungen im Bereich der Luftreinigungstechnologien und können als Grundlage für weiterführende Forschungsarbeiten dienen.;1
" Definition und Anwendung produktorientierter Metriken der SoftwarequalitätEin Ausblick auf mögliche Weiterentwicklungen  Die Qualität von Softwareprodukten ist ein zentrales Anliegen in der Softwareentwicklung. In diesem Kontext spielen produktorientierte Metriken eine entscheidende Rolle, da sie es ermöglichen, die Qualität softwaretechnischer Produkte anhand messbarer Kriterien zu bewerten. Produktorientierte Metriken beziehen sich auf Eigenschaften des Endprodukts selbst und umfassen sowohl technische als auch funktionale Aspekte. Zu den häufig verwendeten Metriken zählen u. a. Code-Komplexität, Fehlerdichte, Testabdeckung und Benutzerfreundlichkeit. Diese Metriken bieten Entwicklern, Qualitätsmanagern und Stakeholdern wertvolle Einsichten in den Zustand der Software und unterstützen die Entscheidungsfindung im gesamten Softwareentwicklungsprozess.  Die Definition produktorientierter Metriken kann im weitesten Sinne als die quantifizierbare Bewertung spezifischer Attribute eines Softwareprodukts gefasst werden. Diese Attribute lassen sich in verschiedene Kategorien unterteilen, wie z. B. funktionale Metriken, die die Erfüllung spezifischer Anforderungen messen, und nicht-funktionale Metriken, die Aspekte wie Leistung, Zuverlässigkeit und Sicherheit betreffen. Ein Beispiel für eine funktionale Metrik ist die Anzahl der erfolgreich abgeschlossenen Benutzeraufgaben, während eine nicht-funktionale Metrik die durchschnittliche Antwortzeit unter Last messen könnte.  Die Anwendung dieser Metriken erfolgt in verschiedenen Phasen des Softwareentwicklungszyklus, von der Planung und dem Design über die Implementierung bis hin zu Tests und Wartung. Durch die kontinuierliche Erfassung und Analyse produktorientierter Metriken können Entwicklungs- und Qualitätssicherungsteams Probleme frühzeitig identifizieren und angehen. Darüber hinaus tragen diese Metriken dazu bei, objektive Vergleichsgrundlagen zu schaffen, die es ermöglichen, unterschiedliche Softwarelösungen hinsichtlich ihrer Qualität zu bewerten.  Ein Ausblick auf mögliche Weiterentwicklungen produktorientierter Metriken der Softwarequalität zeigt, dass sich die Methodik und die Technologie kontinuierlich weiterentwickeln. Eine der vielversprechendsten Entwicklungen ist der Einsatz von Künstlicher Intelligenz (KI) und maschinellem Lernen zur Analyse von Metriken. Diese Technologien könnten es ermöglichen, Muster in großen Mengen von Qualitätsdaten zu erkennen und vorherzusagen, wie sich bestimmte Änderungen am Code auf die Qualität des Endprodukts auswirken werden. So könnten beispielsweise prädiktive Modelle entwickelt werden, die auf historischen Metriken basieren und proaktive Maßnahmen zur Verbesserung der Softwarequalität vorschlagen.  Des Weiteren könnte die Integration von DevOps-Praktiken mit produktorientierten Metriken verstärkt in den Vordergrund rücken. Durch die enge Verzahnung von Entwicklung und Betrieb ist es möglich, Metriken in Echtzeit zu erfassen und auf den jeweiligen Entwicklungsprozess abzustimmen. Dies fördert eine agile Reaktion auf qualitätsrelevante Veränderungen während der gesamten Entwicklung und des Betriebs von Software.  Zusätzlich könnte der Fokus auf Benutzerfeedback und Experience-Design zu einer Weiterentwicklung der produktorientierten Metriken führen. Traditionell lag der Schwerpunkt auf technischen Metriken wie Fehlerdichte oder Codequalität. Zukünftig könnten jedoch auch sogenannte ""User Experience Metriken"" stärker in die Bewertung der Softwarequalität einfließen. Aspekte wie Benutzerzufriedenheit, Erlernbarkeit und Zugänglichkeit könnten als wichtige Metriken etabliert werden, die die Qualität aus der Perspektive der Endbenutzer messen.  Abschließend lässt sich festhalten, dass produktorientierte Metriken der Softwarequalität eine essenzielle Rolle in der modernen Softwareentwicklung spielen. Mit den prognostizierten technologischen Fortschritten und einem wachsenden Verständnis für die Bedeutung der Benutzererfahrung sind die Möglichkeiten zur Weiterentwicklung dieser Metriken nahezu grenzenlos. Die künftige Entwicklung wird darauf abzielen, die Komplexität der Softwarequalität noch besser zu erfassen und somit die gesamte Softwareentwicklung nachhaltig zu verbessern.";1
Erkennbar ist, dass die Modelle mit einer niedrigeren FPSi. d. R. auch weniger Katzen erkannt haben. Eine weitere Auffälligkeit ist, dass beim Modell SSDLite Mobiledet CPU, im Vergleich zu den anderen Modellen, viele fehlerhafte Katzenerkennungen aufgetreten sind. Aufgrund fehlender Informationen, um False-Positives bei Frames mit vorhandener Katze zu erkennen, wird davon ausgegangen, dass die Modelle bei denen False-Positives bei Bildern ohne Katze auftreten, auch bei Bildern mit Katzen auftreten, indem sie ein falsches Objekt als Katze identifizieren. Somit werden für den weiteren Verlauf der Arbeit die Modelle mit einer niedrigen Anzahl an Katzenerkennung sowie die Modelle mit falschen Erkennungen nicht weiter betrachtet. Schließlich werden die Modelle EfficientDet Lite0 , EfficientDet Lite3x, EfficientDet Lite4, SSD Mobilenet v2 ,SSD Mobilenet v3 large, SSDLite Mobiledet CPU, YOLOv2-tiny undYOLOv3-tiny nicht weiter betrachtet. Die Ausnahme dabei ist das Modell YOLOv4-tiny, da dies eine geringe FPSAnzahl hat, dafür jedoch einige Katzen erkannt hat.;0
In der heutigen schnelllebigen und technologiegetriebenen Welt sind effiziente Werkzeuge zur Unterstützung von Lern- und Arbeitsprozessen unerlässlich, insbesondere im Bereich des Software Engineerings. Eine Eigenentwicklung bezieht sich in diesem Kontext auf die maßgeschneiderte Gestaltung und Implementierung eines Softwaretools, das spezifische Anforderungen und Bedürfnisse der Nutzer, in diesem Fall der Studierenden im Software Engineering, adressiert.   Die Eigenentwicklung eines Aufgabenmanagement-Tools umfasst mehrere entscheidende Schritte, beginnend mit einer detaillierten Anforderungsanalyse. Diese Analyse hat das Ziel, die Bedürfnisse der Zielgruppe zu identifizieren und zu priorisieren, um ein System zu schaffen, das nicht nur funktional, sondern auch benutzerfreundlich ist. Hierbei werden sowohl technische Anforderungen, wie z. B. die Integration in bestehende Systeme oder die Unterstützung verschiedener Plattformen, als auch funktionale Anforderungen, wie Aufgabenverwaltung, Fortschrittsverfolgung und Teamkommunikation, berücksichtigt.   Ein solches Tool soll nicht nur die Organisation von Aufgaben erleichtern, sondern auch die Zusammenarbeit und Kommunikation innerhalb von Projektgruppen fördern. Die Eigenentwicklung ermöglicht es, spezifische Funktionen zu integrieren, die auf die Herausforderungen und Arbeitsweisen der Studierenden im Software Engineering zugeschnitten sind. Dazu zählen unter anderem Features wie Priorisierung von Aufgaben, Deadlines, Benachrichtigungen und eine intuitive Benutzeroberfläche.   Insgesamt stellt die Eigenentwicklung eines Aufgabenmanagement-Tools einen iterativen Prozess dar, der eng mit der Anforderungsanalyse verknüpft ist. Sie zielt darauf ab, ein effektives und flexibles Werkzeug zu schaffen, das die Effizienz und Qualität des studentischen Software Engineerings signifikant verbessert.;1
 Kapitel 4: Implementierung der Optimierung der Visualisierung, Bedienung und Selbstregelung eines um Elektronik erweiterten Luftreinigungsgerätes   4.1 Einleitung  In diesem Kapitel wird die Implementierung der Optimierungsmaßnahmen für die Visualisierung, Bedienung und Selbstregelung eines elektronisch erweiterten Luftreinigungsgerätes beschrieben. Ziel dieser Implementierung war es, die Benutzererfahrung zu verbessern, die Effizienz des Luftreinigungsprozesses zu steigern und die Interaktion zwischen dem Benutzer und dem Gerät zu vereinfachen. Die Maßnahmen wurden auf Grundlage der theoretischen Erkenntnisse aus den vorhergehenden Kapiteln entwickelt und umgesetzt.   4.2 Visualisierung  Die Visualisierung der Betriebsparameter und -zustände des Luftreinigungsgerätes spielt eine entscheidende Rolle für die Benutzerfreundlichkeit. Um eine klare und verständliche Darstellung der relevanten Informationen zu gewährleisten, wurde ein grafisches Benutzerinterface (GUI) entwickelt, das auf einem LCD-Display basiert.    4.2.1 Design des Benutzerinterfaces  Das Design des Benutzerinterfaces orientierte sich an den Prinzipien der Usability und Ergonomie. Die Hauptanzeige zeigt in Echtzeit die Luftqualität in Form eines numerischen Wertes sowie durch farbige Indikatoren (grün, gelb, rot) an. Diese einfache Farbgebung ermöglicht es dem Benutzer, auf einen Blick den aktuellen Status des Luftreinigers zu erfassen.   Zusätzlich wurden verschiedene Menüs für die Einstellungen der Betriebsmodi implementiert. Die Navigationsstruktur wurde so gestaltet, dass häufig benötigte Funktionen wie die Änderung der Lüftergeschwindigkeit oder die Aktivierung des Automatikmodus mit minimalen Eingaben erreicht werden können. Die Verwendung von Icons und Symbolen unterstützt die intuitive Bedienung und reduziert die Lernkurve für neue Benutzer.   4.2.2 Implementierung von Feedback-Mechanismen  Um die Interaktivität zu erhöhen, wurden akustische und visuelle Feedback-Mechanismen integriert. Bei jeder Eingabe des Benutzers erfolgt eine visuelle Bestätigung durch das Aufleuchten eines Symbols sowie akustisches Feedback in Form eines kurzen Tons. Diese Maßnahmen tragen dazu bei, die Nutzerbindung zu erhöhen und Missverständnisse bei der Bedienung zu vermeiden.   4.3 Bedienung  Die Bedienung des Luftreinigungsgerätes wurde durch die Einführung eines Mehrkanal-Eingabesystems optimiert. Neben der klassischen Tastenbedienung wurde ein Touchscreen-Interface implementiert, das eine moderne und flexible Interaktion ermöglicht.   4.3.1 Multimodale Eingabe  Die Möglichkeit, das Gerät sowohl über Tasten als auch über den Touchscreen zu bedienen, stellt sicher, dass verschiedene Benutzerpräferenzen berücksichtigt werden. Während der Touchscreen eine schnelle und direkte Eingabe ermöglicht, bieten die physischen Tasten eine haptische Rückmeldung, die in bestimmten Nutzungsszenarien von Vorteil sein kann, beispielsweise in Situationen mit eingeschränkter Sicht oder während der Benutzung von Handschuhen.   4.3.2 Benutzeranpassung  Zusätzlich wurde die Möglichkeit zur Anpassung der Benutzeroberfläche integriert. Benutzer können beispielsweise die Anordnung der angezeigten Informationen personalisieren oder zwischen verschiedenen Anzeige-Themen wählen;1
Wenn zu einem bestimmten Zeitpunkt eine Funktion unterbrochen werden muss,  wird der Zustand der entsprechenden  Coroutine persistiert und später wieder  aufgenommen.  Dabei gibt es folgende Haupt -Coroutine -Konstrukteure :  - launch   - async   - runBlocking   Die Start - und Async -Coroutine -Builder sind die am häufigsten verwendeten,   während  runBlocking ein spezialisierter Builder ist, dessen Zweck es ist, die  blockierende  Welt  mit der Coroutine Welt zu verbinden. - Singletons   Beim Entwurf objektorientierter Systeme kommt es recht häufig vor, dass eine  Klasse nur eine einzige Instanz benötigt. In Java wird dies in der Regel mit einem   Singleton -Muster umgesetzt , bei dem eine Klasse mit einem privaten Konstruktor  und einem statischen Feld  definiert wird , die die  einzige existierende Instanz der  Klasse enthält. Kotlin bietet mit der Objektdeklaration eine erstklassige  Unterstützung für d iese Funktion. Die Objektdeklaration kombiniert eine  Klassendeklaration und eine Deklaration einer einzelnen Instanz dieser Klasse.65  Das Singleton -Muster kann in vielen verschiedenen  Fällen nützlich sein  und daher  macht  Kotlin es relativ einfach  solche  Singletons zu deklarieren . Zu beachten ist  dennoch, dass genau wie bei einer Variablendeklaration , die Objektdeklaration kein  Ausdruck  ist und  nicht auf der rechten Seite einer Zuweisungsanweisung verwendet  werden  kann . Die Initialisierung einer Objektdeklaration ist thread -sicher und  erfolgt beim ersten Zugriff .;0
 Kapitel 2: Technische Grundlagen  In der heutigen digitalen Welt sind mobile Anwendungen ein wesentlicher Bestandteil des Nutzererlebnisses. Zwei der prominentesten Ansätze zur Entwicklung von mobilen Anwendungen sind Progressive Web Apps (PWAs) und native Apps. Dieses Kapitel bietet einen Überblick über die technischen Grundlagen dieser beiden Ansätze, um deren Vor- und Nachteile im Kontext einer Journaling-App zu beleuchten.   2.1 Definition und Architektur  Native Apps sind speziell für eine bestimmte Plattform, wie iOS oder Android, entwickelte Anwendungen. Sie nutzen die jeweiligen Programmiersprachen und Entwicklungsumgebungen, wie Swift oder Objective-C für iOS und Kotlin oder Java für Android. Native Apps haben direkten Zugriff auf die Hardware und die Betriebssystemfunktionen, was eine hohe Leistung und eine optimale Nutzererfahrung ermöglicht. Diese Apps werden in der Regel über die jeweiligen App-Stores distribuiert und müssen regelmäßig aktualisiert werden.  Im Gegensatz dazu sind Progressive Web Apps webbasierte Anwendungen, die in einem Browser laufen und die Vorteile moderner Webtechnologien nutzen. PWAs werden mit HTML, CSS und JavaScript entwickelt und bieten durch den Einsatz von Service Workern und Web App Manifests eine App-ähnliche Benutzererfahrung. Sie sind plattformunabhängig und können über das Internet aufgerufen oder auf dem Home-Bildschirm eines Geräts installiert werden, ohne dass ein App-Store benötigt wird.   2.2 Technologische Unterschiede  Die grundlegenden technologischen Unterschiede zwischen PWAs und nativen Apps lassen sich in mehreren Aspekten zusammenfassen:  1. Entwicklung und Deployment: Native Apps erfordern separate Entwicklungszyklen für jede Plattform, was zu erhöhtem Zeit- und Kostenaufwand führt. PWAs hingegen können einmalig entwickelt und auf verschiedenen Plattformen eingesetzt werden, was die Wartung und Aktualisierung erheblich vereinfacht.  2. Zugriff auf Gerätefunktionen: Native Apps haben uneingeschränkten Zugriff auf die Hardware eines Geräts, einschließlich Kamera, GPS, und Benachrichtigungen. PWAs haben zwar in den letzten Jahren an Funktionalität gewonnen, jedoch sind sie in Bezug auf den Zugriff auf bestimmte Hardware-Funktionen noch eingeschränkt. So ist beispielsweise der Zugriff auf Bluetooth oder NFC in PWAs nur eingeschränkt möglich.  3. Leistung und Geschwindigkeit: Native Apps bieten in der Regel eine bessere Leistung, da sie direkt auf die Hardware zugreifen können und optimiert sind, um die Ressourcen des Geräts effizient zu nutzen. PWAs hingegen sind auf die Leistung des Browsers angewiesen, was in bestimmten Szenarien zu einer geringeren Geschwindigkeit führen kann, insbesondere bei rechenintensiven Anwendungen.  4. Benutzererfahrung: PWAs sind darauf ausgelegt, eine nahtlose Benutzererfahrung zu bieten, die der von nativen Apps ähnelt. Durch die Verwendung von Responsive Design und adaptiven Layouts passen sich PWAs an verschiedene Bildschirmgrößen und -auflösungen an. Native Apps können jedoch tiefere Integrationen in das Betriebssystem bieten, was zu einer intuitiveren und flüssigeren Benutzererfahrung führt.   2.3 Anwendungsbeispiel: Journaling-App  Um die Unterschiede zwischen PWAs und nativen Apps konkret zu veranschaulichen, betrachten wir eine;1
Titel der Arbeit: In-Room Ortung zur Sturzerkennung mit Bluetooth  1. Einleitung    - Problemstellung: Stürze stellen insbesondere für ältere Menschen ein gravierendes Risiko dar. Die rechtzeitige Erkennung und Hilfeleistung kann entscheidend sein, um Folgeschäden zu minimieren.    - Ziel der Arbeit: Entwicklung eines Systems zur Sturzerkennung mittels Bluetooth-Technologie, um genaue Standortdaten innerhalb von Gebäuden für eine schnelle Reaktion bereitstellen zu können.  2. Theoretische Grundlagen    - 2.1. Sturzerkennung: Definition und Relevanz, aktuelle Statistiken über Stürze bei älteren Menschen, mögliche Folgen und deren Prävention.    - 2.2. Bluetooth-Technologie: Grundlagen der Bluetooth-Kommunikation, unterschiedliche Versionen, Reichweiten, Vor- und Nachteile im Vergleich zu anderen Technologien (z.B. WLAN, UWB).    - 2.3. In-Room Ortung: Techniken und Methoden zur Positionierung innerhalb von Gebäuden. Unterschiede zwischen GPS und in-door Ortung. Relevante Ansätze wie RSSI (Received Signal Strength Indication), triangulation und trilateration.  3. Methodik    - 3.1. Systemarchitektur: Entwurf der Systemarchitektur zur Sturzerkennung, inklusive der Hardware (Bluetooth-Beacons, Smartphones, zentrale Datenverarbeitung).    - 3.2. Implementierung: Detaillierte Beschreibung der Programmierung und Integration der Bluetooth-Beacons, sowie der Algorithmen zur Erkennung von Sturzereignissen.    - 3.3. Testumgebung: Aufbau einer Testumgebung zur Validierung der Sturzerkennung. Nutzung eines simulierten Wohnumfelds.    - 3.4. Datenanalyse: Datenerhebung während der Tests (z.B. Sturzereignisse, Unterscheidung zwischen normalen Bewegungen und einem Sturz) und die angewendeten Analysemethoden (z.B. maschinelles Lernen, statistische Auswertungen).  4. Ergebnisse    - 4.1. Systemleistung: Auswertung der Effektivität des erstellten Systems in Bezug auf Genauigkeit, Reaktionszeit und Fehlalarme.    - 4.2. Benutzerakzeptanz: Durchführung einer Umfrage zur Akzeptanz von Nutzern (z.B. Senioren, Pflegepersonal) der entwickelten Lösung.  5. Diskussion    - 5.1. Einschätzung der Ergebnisse: Einordnung der Ergebnisse im Kontext bestehender Forschung zur Sturzerkennung und in-room Ortung.    - 5.2. Herausforderungen und Limitationen: Identifikation von Herausforderungen während der Implementierung, Testergebnisse und möglichen Limitationen (z.B. Störungen, Einflüsse von Umgebungsfaktoren).  6. Schlussfolgerung und Ausblick    - Zusammenfassung der Ergebnisse und deren Bedeutung für die Sturzerkennung.    - Mögliche Weiterentwicklungen und Verbesserungsvorschläge für das System.    - Ausblick auf zukünftige Forschungsfragen und Anwendungen in der Altenpflege oder rehabilitativen Einrichtungen.  7. Literaturverzeichnis    - Auflistung aller verwendeten Quellen, Studien und Literatur, die im Verlauf;1
Üblicherweise wird eine Aufgabenverwaltungssoftware von einer konstanten Menge an  Personen über einen längeren Zeitraum verwendet. Die öffentlich einsehbaren Listenpreise  orientieren sich an diesem Umstand. Alle Hersteller bieten eine jährliche Lizensierung ihrer  Software an. Insbesondere für die günstigeren Tarife wird eine monatliche Lizensierung  angeboten, deren Preis gegenüber der Jahreslizensierung jedoch, umgerechnet auf einen  Monat, teurer ist. Nur Azure DevOps Services wird immer monatlich lizensiert.  Die Software wird in der Bildungseinrichtung nicht das ganze Jahr über von der gleichen Anzahl  von Personen verwendet. Die Studierenden nutzen innerhalb nur einiger Zeiträume die  Software. Eine jährliche Lizensierung ist nachteilhaft, da die Lizenz nur zu einem geringen  Bruchteil der Zeit genutzt werden würde. Eine jährliche Lizensierung käme nur bei Accounts  für Lehrkräfte oder Verwaltungsmitarbeiter*innen in Frage.   Oberflächlich betrachtet müsste die Lizensierung von Jira Software die günstigste sein, da der  monatliche Grundpreis langfristig bei 3,70€ pro Person liegt. Die tatsächliche Nutzung von der  Hochschule verkompliziert jedoch diese Betrachtung. Nur, wenn die Software exakt für  vollständige Monate lizensiert ist, kann Jira Software den geringeren Monatspreis voll  ausspielen. Wird die Software für beispielsweise 2,5 Monate betrieben, würden die Azure  DevOps-Lizenzen nur für 2,5 Monate berechnet, die Lizenzen von Jira Software jedoch für volle  drei Monate, den öffentlichen Informationen zufolge. Zusätzlich werden in Azure DevOps die  ersten 5 Personen nicht berechnet, was insbesondere bei wenigen benötigten Lizenzen einen  relevanten Unterschied machen kann.  Um zu verdeutlichen, wie nahe die Kosten für die Lizensierung der Softwares sind, werden die  Lizenzkosten grafisch dargestellt . Für dieses Rechenbeispiel wird angenommen, dass drei  Personen eine langfristige Lizenz erhalten. Dies ist sowohl im Lizenzmodell für Azure DevOps  Services Basic als auch Jira Software Free kostenlos. Ein interessanteres Bild ergibt sich, wenn  angenommen wird, dass 28 weitere Studierende eine Lizenz temporär erhalten. Für die  Lizensierung von Azure DevOps Services Basic wird angenommen, dass die tagesgenaue   Abrechnung von der Anzahl der Tage im Monat abhängt. Ein Tag Azure DevOps Services kostet  also in einem Februar ohne Schalttag etwa 20,39 Cent, im darauffolgenden März nur noch  18,42 Cent pro Tag. Außerdem wird davon ausgegangen, dass die Lizenzierung genau  zu  Beginn eines Monats startet.;0
Es muss sichergestellt werden, dass Arbeitspakete und andere Daten nicht spurlos gelöscht  werden dürfen. Demzufolge sollte an der Projektrolle ein zusätzliches Attribut definiert  werden, das aussagt, ob die Mitglieder dieser Gruppe Inhalte löschen dürfen, oder nicht. Eine  Löschung ist nur möglich, falls man eine Rolle für dieses Projekt besitzt , die dies erlaubt.  Die Daten können jedoch auch verfälscht werden, indem sie nur bearbeite t werden. Die  Beschreibung von Arbeitspaketen könnte einfach durch einen leeren Text ersetzt wer den.  Deswegen ist es nicht nur notwendig, die Löschung von Arbeitspaketen zu unterbinden,  sondern auch einen Bearbeitungsverlauf zu erstellen. Damit kann nicht nur der Werdegang  eines Arbeitspaketes nachvollzogen werden, sondern auch die Beschreibungen  wiederhergestellt werden, falls sie entfernt worden sind. Änderungen an  den Wikiseiten  sollten ebenfalls protokolliert werden.  Ein wichtiger Punkt ist die Überprüfung der Arbeitsleistung. Die bereits untersuchten  Softwares sind nicht darauf ausgelegt, die Leistung einzelner Personen zu analysieren. In einer  selbst entwickelten Anwendung könnten jedoch genau diese Auswertungen implementiert  werden, um die Bewertung zu vereinfachen.   Einige Auswertungen können mit der Anforderung „ Suche “ bereits abgedeckt werden,  beispielsweise die Suche nach allen Arbeitspaketen mit einem Schlagwort und einer  bestimmten bearbeitenden Person. Der Bearbeitungsverlauf ist hilfreich, um die Arbeit an  einem Arbeitspaket nachzuvollziehen.  Um die Arbeitsleistung über die gesamte Projektdauer zu bewerten, werden drei  Auswertungen in die Schätzung aufgenommen:  • Arbeitszeit einer Person pro Arbeitspaket  • Arbeitszeit einer Person pro Sprint  • Liste aller Arbeitszeitbuchungen einer Person mit zugehörigem Arbeitspaket;0
Der Luftreiniger hat zwei Bedienungsarten, er kann entweder mit einem 433 MHz Fernbe- diener oder auf einer Webseite gesteuert werden (vgl. Ebert und Schweier 15.12.2021, S. 27). Der ESP32 Mikrocontroller bietet verschiedene Möglichkeiten für eine WLAN-Anbindung und hat folgende Modi: •Access-Point-Mode, bei der sich verschiedene Geräte mit dem ESP32 verbinden •Station-Mode, bei dem sich der ESP32 mit einem Access-Point-Mode verbindet •Kombinierung von Access-Point-Mode und Station-Mode •von Espressif definiertes Protokoll ESP-Now •Mesh (vgl. Brandes 2020, S. 366 f.) In der Studienarbeit von den Studierenden der Fachrichtung Maschinenbau wurde die Station-Mode für die WLAN-Anbindung gewählt. In der Abbildung 2.3 ist die Architektur dargestellt. Der ESP32 fungiert als Webserver und der Router ist dabei der Access-Point. Solange der ESP32 Mikrocontroller mit diesem Router verbunden ist, kann der Luftreiniger mit einem internetfähigen Gerät gesteuert werden, soweit das Telefon (oder Computer) mit dem gleichen Router verbunden wird. Mit diesem Lösungsansatz müssen die Assets nicht in das Hochschulnetz angebunden werden. Abbildung 2.3: Steuerung des ESP32 Mikrocontroller über das WLAN(vgl. Brandes 2020, S. 373) In der Abbildung 2.4 ist eine Bildschirmaufnahme von der Webseite zu sehen, auf der der Luftreiniger gesteuert werden kann. Es gibt verschiedene Knöpfe für die Ansteuerung des Geräts, zusätzlich wird die Temperatur und Luftfeuchtigkeit ausgegeben. Basierend auf dieser Webseite wird in der vorliegenden Arbeit die Visualisierung und Bedienung des Luftreinigers optimiert.;0
Die zweite Möglichkeit besteht darin, dass man bei der Deklaration der Variable diese direkt initialisiert. Dies kann in dem Beispiel var name = ”Max Mustermann” gesehen werden. Dabei wird der Datentyp implizit aus dem Initialisierungswert bestimmt . Null safety Durch Kotlin können auch NullPointerExceptions verhindert werden, da Variablen durch ein Fragezeichen( ?) als nullwertig definiert werden. Ein Beispiel dazu ist var name: String?. Die Variable namemuss durch das Fragezeichen( ?) als nullwertig behandelt werden. Durch zwei Ausrufezeichen( !!) kann jedoch auch gesagt werden, dass eine Variable nicht nullwertig sein darf. Falls diese trotzdem nullwertig sein sollte, erhält man dennoch eineNullPointerException. Für die grafische Darstellung der Elemente in der Katzenklappen App wird das Jet- pack Compose Framework verwendet. Die standardmäßige Projektstruktur, wie sie in Abschnitt 2.3 beschrieben ist, wird somit verändert. Durch Jetpack Compose wird das Konzept, das Layout durch XMLDateien darzustellen, verworfen. Stattdessen wird das Layout der App durch Methoden, welche die Annotation @Composable besitzen, im Kotlin Code dargestellt. Dies hat den Vorteil, dass das Layout der Activity in dieser definiert wird. Dadurch, dass die grafischen Elemente durch Jetpack Compose in Kotlin dargestellt werden, wird es dem Entwickler erleichtert, die App zu designen. Dopplungen in der grafischen Oberfläche können durch eine Methode abgebildet werden, welche an allen benötigten Stel- len aufgerufen wird. Dies sorgt für eine übersichtliche Darstellung der grafischen Elemente. Zusätzlich wird somit weniger Code benötigt. Außerdem können durch vordefinierte grafische Methoden bestimmte Elemente durch Kotlin Code einfacher als in einer XMLDatei dargestellt werden.;0
Die Efficient Det- und SSD-Modelle werden mit dem TensorFlow Lite Framework implemen- tiert. Da keine vortrainierten YOLO-Modelle für das TensorFlow Lite Framework gefunden werden konnten, werden diese mithilfe des OpenCV Frameworks implementiert. D. Velasco-Montero et al. haben eine Performanceanalyse mehrerer Deep Neural Net- work (DNN)-Modelle mit unterschiedlichen Frameworks durchgeführt. Dabei haben die Frameworks OpenCV undTensorFlow in Anbetracht der Performance am besten ab- geschnitten.  In Abbildung 4.3 ist die mittlere FPSAnzahl der einzelnen Modelle, unter Verwendung unterschiedlicher Frameworks, zu sehen. Abbildung 4.4 zeigt die unterschiedlichen Genauigkeiten der einzelnen Modelle. In beiden Fällen ist kein signi- fikanter Unterschied zwischen den beiden Frameworks OpenCV undTensorFlow zu sehen, welcher für diese Arbeit relevant ist. Somit stellt die Verwendung zweier unterschiedlicher Frameworks für die Evaluierung kein Problem dar.;0
"Zur Erstellung der Konﬁguration für das Raspberry Pi Gateway dient als Vorlage die
Konﬁgurationsdatei, welche im GitHub-Repository im packet_forwarder -Verzeichnis liegt.
Je nach Konﬁguration unterscheiden sich die Vorlagen und können durch die zu verwen-
dende korrekte Frequenz im Namen unterschieden werden. Im Fall für Europa und der
868MHz-Frequenz ist folgende Datei zu verwenden: global_conf.json.sx1250.EU868 Von
dieser Vorlage wird eine Kopie erstellt, beispielsweise durch den Befehl cp global_conf.
json.sx1250.EU868 final_config.
Jegliche Informationen des gateway_conf -Knoten aus Abbildung 3.7 werden nun in die Kopie
der global_conf.json.sx1250.EU868 übernommen und bestehende Werte überschrieben. In
Abbildung 3.8 sieht man, wie die Konﬁgurationsdatei auf Basis der Vorlage verändert
werden muss.
Um das Gateway ﬁnal über ein Progamm zu starten, wird der Befehl ./lora_pkt_fwd -c
final_config verwendet. Ob das Gateway korrekt und wie gewünscht funktioniert, kann
über die Logs des lora_pkt_fwd -Programms oder über die Übersichtsseite des Gateways im
TTN, siehe Abbildung 3.9, überprüft werden.
Abbildung 3.9: Übersichtsseite des laufenden Gateways
Um das Gateway automatisch zu starten wird ein Bash-Script angelegt, welcher in Abbil-
dung 3.10 zu sehen ist. Dieser wartet bis erfolgreich eine Internetverbindung hergestellt
worden ist, indem er in einer Schleife versucht Googles-DNS-Server zu erreichen. Wenn
dieser Ping erfolgreich war, wird im Anschluss die lora_pkt_fwd -Anwendung im Hintergrund
gestartet. Die komplette Ausgabe, welche normalerweise von der Anwendung im Terminal
ausgegeben wird, wird in die gateway.log -Datei geschrieben. So kann im Falle eines Fehlers
in der angegebenen Logdatei nach der Ursache des Fehlers gesucht werden.
Durch die Erweiterung der Jobdeﬁnitionen der Cron-Jobs durch den Befehl crontab -e
kann mit @reboot /home/pi/start_lora_gateway.sh der Skript automatisch bei jedem Start
des Raspberry Pi gestartet werden (siehe Abbildung 3.11).
Abbildung 3.11: Cron-Jobdeﬁnition";0
Der Kamerawinkel ist entscheidend für das Sichtfeld der Kamera und sorgt für den Bewe- gungsfreiraum der Katze. Da eine Katze sich eventuell nicht direkt vor der Katzenklappe aufhält und gegebenenfalls in der Nähe an einer anderen Stelle wartet, ist es wichtig ein großes Sichtfeld zu haben. So kann die Katze leichter entdeckt werden. Aus diesem Grund wird bei der Auswahl der Kamera auf einen möglichst großen Winkel geachtet. Der Nachteil dabei ist, dass die Katze dadurch kleiner auf dem Bild erscheint, was gegebenenfalls zu Problemen bei der Katzenerkennung führen kann. Die Pixelanzahl der Kamera sowie die Videoauflösung dient der Schärfe des Bildes oder Videos. Je höher die Auflösung, desto rechenintensiver wird die Katzenerkennung, da mehr Pixel berücksichtigt werden müssen. Aus diesem Grund sollte die Pixelanzahl nicht zu hoch sein. Für die Kompatibilität wird darauf geachtet, dass die Kamera mit dem Raspberry Pi 4 funktioniert.ZusätzlichsollkeineexterneStromquelleerforderlichsein,damitnichtmehrere Steckdosen belegt oder Batterien verwendet werden müssen, sodass der Wartungsaufwand gering gehalten wird. Für eine leichtere Montage und eventuellen Platzmangel sowie optischen Aspekten, sollte die Kameragröße und das Gewicht der Kamera am Besten möglichst klein sein.;0
Dies hat Google 2015 hautnah erleben dürfen (Spiegel 2015). Google hat eine Funktion für Google Fotos neu hinzugefügt in der Fotos automatisch gelabelt werden anhand von ihrem Inhalt. Dies erfolgte mit KI und sollte helfen Nutzern Fotos besser zuzuordnen. Dabei wurden Fotos auch korrekt erkannt, aber nicht immer. So wurden ein paar Menschen mit dunkler Hautfarbe als „Gorillas“ erkannt. Dies hat natürlich für Diskussionen um rassistische KI geführt. Google hat daraufhin die Funktion abgestellt (Machkovech 2015). Genau das gleich ist einem Dienst namens Flickr nur Wochen zuvor passiert („Flickr“ 2015). Dort wurden ebenfalls dunkelhäutige Menschen als Affen erkannt. Dies ist allerdings nicht das einzige Problem, das Google mit KI hatte. So wurden in regulärer Gesichtserkennung dunkelhäutige Menschen deutlich schlechter erkannt als helle Menschen (Kaltheuner und Obermüller 2018). Es hat sich dabei herausgestellt, dass dies an der Auswahl der Trainingsdaten lag. So wurden zu wenige Bilder mit dunkelhäutigen Menschen in der Auswahl der Trainingsdaten mit einbezogen, worauf die KI deutlich schlechtere Ergebnisse lieferte. Denn die Datenbank, mit der die KI trainiert wird, und auch die Auswahl dieser Daten sind entscheidend für den Erfolg oder Misserfolg der KI (Cui u.a. 2018).;0
Eine alternative Interaktion ist ein Aktor, der die Daten eines Sensor abonniert, wie in Listing 4.7 zu sehen ist. In diesem Beispiel wird ein autonomes Fenster konfiguriert, welches sich bei einer Luftfeuchtigkeit von über 60 % automatisch öffnet. Dafür müssen zunächst zwei Callback-Methoden gesetzt werden: •Die Methode window_subscribe , welche dem Attribut on_runzugewiesen wird. Durch den Aufruf der Methode wird das Topic des Thermostats abonniert. •Die Methode window_on_message , welche dem Attribut on_message zugewiesen wird. Hierbei wird bei jeder Nachricht die Callback-Methode mit den erhaltenen Infor- mationen aufgerufen. Dabei kann es sein, dass dem benutzerdefinierten Handler eine Nachricht übergeben wird, welche bereits in der Basisimplementation behan- delt wird. Damit die Basis-Implementation nicht kopiert werden muss, existiert der Rückgabewert handled. Bei einer Rückgabe von Truewird dem Message-Handler der Elternklasse signalisiert, dass die Nachricht in der benutzerdefinierten Methode behandelt wurde und keine weitere Verarbeitung benötigt wird. Somit können auch bestimmte Verhaltensweisen des Geräts deaktiviert werden, ohne dass eine neue Klasse implementiert werden muss.;0
Nach dessen Installation stellt das CMSDrupal vordefinierte Benutzerrollen zur Verfü- gung, welche nach Belieben in deren Berechtigungen angepasst werden können. Gruppen, welche Benutzern zugeordnet werden sind hierbei nicht vorgesehen bzw. Bestandteil der Rechteverwaltung in Drupal. Wird eine neue Rolle angelegt, so können dieser alle verfügbaren Rechte innerhalb des Systems per Checkbox zugeteilt und entfernt werden: Anhand diesesSchemas kann dieim Anwendungsfall definierte Anforderung der verwalteten Beitragsveröffentlichung also nur bedingt realisiert werden. Eine Rolle, welche Inhalte unabhängig von deren Ersteller bearbeiten kann, muss zusätzlich erstellt werden. Soll die Bearbeitung von „fremden“, also nicht durch den User selbst erstellen Inhalten, den Administratoren vorenthalten bleiben, so genügt die Standardinstallation des Systems mit den Rollen Gast, angemeldeter Benutzer, Redakteur und Administrator. Grundsätzlich ist eine Verwendung eines Benutzers mit Administrator-Berechtigung nicht empfehlenswert, weshalb eine gesonderte Rolle im Rahmen der Produktivstellung der Website erstellt werden sollte. Aus diesem Grund wird das System mit der Kategorie Gelb bewertet.;0
Im Fazit dieser wissenschaftlichen Arbeit über „Java vs. Kotlin“ lässt sich festhalten, dass beide Programmiersprachen ihre eigenen Vorzüge und Herausforderungen besitzen, die stark von den spezifischen Anforderungen eines Projekts abhängig sind. Während Java seit Jahrzehnten als bewährte und robuste Sprache gilt, die in einer Vielzahl von Anwendungen eingesetzt wird, bietet Kotlin modernere Sprachfeatures und eine verbesserte Entwicklererfahrung, insbesondere im Kontext der Android-Entwicklung.  Java punktet mit seiner weitreichenden Verbreitung, umfassenden Bibliotheken und einer großen Entwickler-Community, was eine hohe Verfügbarkeit von Ressourcen und Unterstützung gewährleistet. Kotlin hingegen bringt eine prägnantere Syntax und Funktionen zur Null-Sicherheit mit, die die Häufigkeit von Laufzeitfehlern verringern, was zu robusterem Code führt.  Die Migration von Java zu Kotlin wird durch die vollständige Interoperabilität der beiden Sprachen erleichtert, was es Entwicklern ermöglicht, schrittweise auf Kotlin umzusteigen, ohne bestehende Java-Projekte grundlegend überarbeiten zu müssen. Dies bietet eine attraktive Möglichkeit, die Vorteile von Kotlin zu nutzen, während man gleichzeitig auf der stabilen Grundlage von Java bleibt.  Insgesamt lässt sich sagen, dass die Wahl zwischen Java und Kotlin nicht nur eine technische Entscheidung ist, sondern auch von den spezifischen Projektanforderungen, den Teamfähigkeiten und den langfristigen Zielen abhängt. In vielen Fällen kann die Kombination beider Sprachen eine optimale Lösung darstellen, um die jeweiligen Stärken auszuspielen und gleichzeitig die Herausforderungen zu minimieren. Zukünftige Forschungsrichtungen könnten sich darauf konzentrieren, die Entwicklungstrends beider Sprachen zu beobachten und deren Einfluss auf die Software-Entwicklung weiter zu analysieren.;1
Tracking der Bodenfeuchtigkeit mit LoRaWAN und dem The Things NetworkEin Ausblick auf zukünftige Entwicklungen  Die Überwachung der Bodenfeuchtigkeit ist von entscheidender Bedeutung für die Landwirtschaft, das Wassermanagement und den Umweltschutz. In den letzten Jahren hat sich die Technologie des Low-Power Wide-Area Networks (LoRaWAN) in Kombination mit Plattformen wie dem The Things Network (TTN) als vielversprechende Lösung zur effizienten Erfassung und Übertragung von Bodenfeuchtigkeitsdaten etabliert. Diese Technologien ermöglichen es, Sensordaten über große Entfernungen mit minimalem Energieverbrauch zu übertragen, was insbesondere in ländlichen und abgelegenen Gebieten von Vorteil ist.  Die Integration von LoRaWAN-Sensoren zur Bodenfeuchtigkeitsmessung bietet zahlreiche Vorteile. Sensoren, die mit LoRaWAN verbunden sind, können in Echtzeit Daten sammeln und über das TTN an zentrale Datenbanken übermitteln. Dies ermöglicht Landwirten und Umweltforschern, präzise Informationen über den Feuchtigkeitsgehalt des Bodens zu erhalten, was zu einer optimierten Bewässerung und damit zu einer nachhaltigeren Nutzung von Wasserressourcen führt. Darüber hinaus können solche Systeme in Kombination mit Wettervorhersagedaten und anderen Umweltfaktoren eingesetzt werden, um umfassendere Analysen zu ermöglichen.  Ein vielversprechender Ausblick auf die Weiterentwicklungen in diesem Bereich umfasst mehrere Aspekte 1. Erweiterte SensortechnologienDie Entwicklung kostengünstiger und präziserer Bodenfeuchtesensoren wird entscheidend sein. Fortschritte in der Nanotechnologie und Materialwissenschaft könnten zu Sensoren führen, die nicht nur die Bodenfeuchtigkeit, sondern auch andere relevante Parameter wie Temperatur, pH-Wert und Nährstoffgehalt in Echtzeit messen können. Solche Multisensorlösungen würden eine umfassendere Analyse der Bodenbedingungen ermöglichen.  2. Integration von KI und maschinellem LernenDie Kombination von LoRaWAN-Daten mit Algorithmen des maschinellen Lernens könnte dazu beitragen, präzisere Vorhersagemodelle für die Bodenfeuchtigkeit zu entwickeln. Diese Modelle könnten historische Daten analysieren und in Echtzeit Anpassungen an Bewässerungsstrategien empfehlen, um Wasserressourcen effizienter zu nutzen.  3. Energieautarke SystemeDie Entwicklung von energieautarken Sensoren, die beispielsweise durch Solarenergie oder andere erneuerbare Energiequellen betrieben werden, könnte die Abhängigkeit von Batterien reduzieren und die Lebensdauer der Sensoren verlängern. Solche Systeme wären besonders vorteilhaft in abgelegenen Gebieten, in denen der Zugang zu Strom begrenzt ist.  4. Erweiterte Netzabdeckung und InteroperabilitätDie kontinuierliche Expansion von LoRaWAN-Netzwerken, insbesondere in ländlichen und unterversorgten Regionen, wird die Verfügbarkeit von Bodenfeuchtigkeitsdaten erhöhen. Darüber hinaus könnte die Interoperabilität zwischen verschiedenen IoT-Plattformen und -Protokollen weiter verbessert werden, um eine nahtlose Integration und den Austausch von Daten zu ermöglichen.  5. Nachhaltige Landwirtschaft und Smart FarmingDie Anwendung von LoRaWAN zur Überwachung der Bodenfeuchtigkeit wird zunehmend Teil von Konzepten der nachhaltigen Landwirtschaft und;1
 Kapitel 2: Technische Grundlagen für die Entwicklung eines virtuellen MQTT-Szenarios für Lehrzwecke   2.1 Einführung in MQTT  MQTT (Message Queuing Telemetry Transport) ist ein leichtgewichtiges Protokoll für die Nachrichtenübertragung, das speziell für Netzwerke mit geringem Bandbreitenverbrauch und hohen Latenzen entwickelt wurde. Es basiert auf einem Publisher-Subscriber-Modell, bei dem zwei Hauptkomponenten beteiligt sind: Publisher, die Nachrichten an ein Topic senden, und Subscriber, die Nachrichten von einem Topic empfangen. Der Broker fungiert als Vermittler, der die Kommunikation zwischen den Publishern und Subscribern organisiert. Ein tiefes Verständnis dieser Architektur ist essenziell für die Entwicklung eines effektiven virtuellen Szenarios.   2.2 Architektur von MQTT  Die Architektur von MQTT besteht aus folgenden Hauptkomponenten:  1. Broker: Der zentrale Server, der alle Nachrichten empfängt, filtert und verteilt. Ein typisches Beispiel für einen MQTT-Broker ist Mosquitto. Der Broker sorgt dafür, dass Nachrichten an die entsprechenden Subscriber weitergeleitet werden und verwaltet die Verbindungen zu den Clients.  2. Publisher: Diese Clients sind für das Senden von Nachrichten verantwortlich. Sie stellen Informationen zur Verfügung und veröffentlichen sie an ein bestimmtes Topic. In einem Lehrszenario könnten dies Sensoren oder simulierte Datenquellen sein.  3. Subscriber: Diese Clients abonnieren spezifische Topics, um Echtzeitdaten zu empfangen. Im Kontext einer wissenschaftlichen Lehrveranstaltung können das Studenten oder Lehrkräfte sein, die verschiedene Datenströme abfragen.  4. Topics: Dies sind hierarchisch organisierte Kanäle, über die Nachrichten zwischen Publisher und Subscriber übertragen werden. Sie ermöglichen eine strukturierte Kommunikation und helfen, Daten zu kategorisieren.   2.3 MQTT-Protokollspezifikationen  MQTT basiert auf den Spezifikationen, die alle Aspekte der Kommunikation regeln. Zu den wichtigsten Merkmale gehören:  - Quality of Service (QoS): MQTT unterstützt drei Stufen der QoS, die die Zuverlässigkeit der Nachrichtenübermittlung bestimmen:   - QoS 0: „At most once“ – Nachrichten werden einmal gesendet, ohne Bestätigung.   - QoS 1: „At least once“ – Nachrichten werden gesendet, bis eine Bestätigung empfangen wird.   - QoS 2: „Exactly once“ – Nachrichten werden genau einmal übermittelt, um Duplikate zu vermeiden.  - Last Will and Testament (LWT): Dies ermöglicht es, eine letzte Nachricht zu definieren, die vom Broker gesendet wird, wenn ein Client unerwartet die Verbindung trennt. Dies ist besonders nützlich für Lehrszenarien, in denen das Verhalten von Systemen bei Ausfällen simuliert werden soll.  - Sicherheitsmechanismen: Die Sicherheit im MQTT-Protokoll wird durch Authentifizierung und Verschlüsselung, oft via TLS/SSL, gewährleistet. Diese Elemente sind entscheidend, um sicherzustellen, dass die Lehrumgebung vor unautorisierten Zugriffen geschützt ist.   2.4 Virtuelle Simulation mit MQTT  Für die Integration von MQTT in ein virtuelles Lehrszenario sind einige technische Aspekte zu beachten:  1. Entwicklungsumgebung: Die Verwendung von Umgebungen wie Node-RED, die eine grafische Programmieroberfläche bieten, erleichtert die Implementierung von MQTT-basierten Szenarien. Diese Plattform ermöglicht es, verschiedene Datenquellen anzubinden und zu visualisieren, was das Lernen für Studierende interaktiver gestaltet.  2. Simulation von Publishern und Subscribern: Anstatt reale Hardware einzusetzen, können Simulatoren entwickelt werden, die das Verhalten von Publishern und Subscribern nachahmen. Dazu können virtuelle Sensoren, Aktoren und andere IoT-Geräte verwendet werden, die Daten generieren oder empfangen.  3. Visualisierungswerkzeuge: Um die Informationen, die durch MQTT übertragen werden, darzustellen, sind Visualisierungswerkzeuge unerlässlich. Diese Tools helfen, die Daten in einem Dashboard darzustellen, beispielsweise durch Diagramme, Grafiken oder Echtzeitdatenanzeigen.  4. Interaktion und Feedback: Eine Rückmeldemechanismus ist notwendig, um den Studierenden Feedback über ihre Interaktionen mit den virtuellen Szenarien zu geben. Dies kann durch Benachrichtigungen, Log-Dateien oder direkt im UI erfolgen.   2.5 Zusammenfassung  Die Entwicklung eines virtuellen MQTT-Szenarios für Lehrzwecke erfordert ein fundiertes Verständnis der Grundlagen von MQTT, der Architektur sowie der Spezifikationen des Protokolls. Die Umsetzung in einer virtuellen Umgebung bietet Chancen, die Interaktivität und das Lernen zu fördern. Im folgenden Kapitel werden wir uns mit praktischen Aspekten der Implementierung und den spezifischen Anwendungsfällen für Lehrszenarien befassen.   Durch die Integration von MQTT in die Lehrmethoden können innovative und effektive Lernumgebungen geschaffen werden, die den Studierenden praktische Erfahrungen im Umgang mit modernen Kommunikationsprotokollen bieten.;1
Für die Messung der Halstead -Metriken wird eine darauf spezialisierte Analysesoftware eingesetzt.  Das Halstead Metrics Tool kann sowohl auf der Kommandozeile  als auch über die einfach aufgebaute  GUI ausgeführt werden und liefert Messwerte zu den durch Maurice Halstead eingeführten  Kennzahlen. In der Auswertung werden die Kenngrößen Vokabular (n), Länge (N), Volumen (V),  Schwierigkeit (D) sowie Aufwand (E)  auf Komponentenebene betrachtet . Gestartet wird die Software  über die JAR -Datei Halstead -Metrics.jar. Es besteht die Möglichkeit mit dem Befehl „java - Duser.country=US -Duser.language=en -jar Halstead -Metrics.jar <file_to_analyze> “ die  Analyseergebnisse der an gegebenen Datei auf der Kommandozeile zu erhalten. Alternativ kann  durch das Kommando „java -Duser.country=US -Duser.language=en -jar Halstead -Metrics.jar “ die  grafische Oberfläche gestartet werden. In der GUI kann nun über das Dateimenü das  Projektverzeic hnis gesucht werden. Durch das Auswählen einer C++ - oder Java -Datei  werden die  Halstead -Metriken berechnet und auf der Oberfläche angezeigt.  Durch Klick auf einen der Button  „View HTML Report“ und „View PDF Report“ werden die Ergebnisse als HTML -Seite beziehungsweise  PDF-Datei auf bereitet. Abbildung 13 zeigt die grafische Oberfläche mit Werten der Klasse CFahrzeug.;0
In Abbildung 5.3 ist zu sehen, wie die MQTT-Nachrichten des ausgewählten Topics home0/bedroom/thermometer/temperature aufgezählt werden. Hierbei entspricht eine Zeile einem PUBLISH Control Packet. Abbildung 5.3: Auflistung der erhaltenen Nachrichten einer Topic-Ebene Grundsätzlich kann der Testlauf als erfolgreich betrachtet werden, da die Interaktionen, welche davor konfiguriert worden sind, funktioniert haben und im Frontend korrekt visualisiert worden sind. Des Weiteren hat das GUIauf Benutzereingaben ohne merkbare Verzögerungenreagiertundkeinegingenkeine MQTTControlPacketsverloren.Dahermuss die Implementierung mit der threading -Library, welche im Gegensatz zu multiprocessing nur User-Threads erstellt, nicht angepasst werden.;0
Im Kontext zu Content Management Systemen spielt der Begriff des Responsive Web- Design eine besondere Rolle. Einige CM-Systeme übernehmen die responsive Darstellung von Inhalten automatisiert und fordern von dessen Nutzern wenig bis keine gesonderte Interaktion für die einwandfreie Darstellung auf beliebigen Endgeräten. Anwender können lediglich die Anordnung des Inhalts beeinflussen und müssen kein technisches Know-how in Sachen Webentwicklung, CSS sowie Breakpoint-Setzung vorweisen.2Andere Systeme hingegen stellen lediglich die Möglichkeit der Einbindung von eigens erstellten CSS-Files zur Verfügung, womit auf die technische Kompetenz der Nutzer gesetzt wird. Mithilfe sogenannter „Templates“ (häufig auch als „Themes“ bezeichnet) können vorgefer- tigte Design-Vorlagen ohne großen Aufwand innerhalb des CMSaktiviert werden. Diese vereinheitlichen das Aussehen der generierten Inhalte bzw. Seiten innerhalb der Website. Durch die Entkopplung von Template und dem Inhalt kann das Aussehen der Website jederzeit durch Anpassungen am aktiven Template oder durch den Wechsel auf ein neues geändert werden. Die Aktivierung und Installation der Templates auf den jeweiligen Systemen unterscheidet sich hierbei stark. Häufig ist der Download und die Installation im CMS-eigenen Template- Store möglich während andere Systeme die Templates nur als Style-Vorlagen bereitstellen, welche anschließend umfangreich programmiert werden müssen. 1Grafik selbst erstellt. In Anlehnung an  2Mit sog. „Breakpoints“ werden spezifische Umbruchpunkte innerhalb des Stylesheets einer Website um- gesetzt. Je nach Breakpoint können andere CSS-Parameter gesetzt werden, welche Grundbestandteil von responsivem Webdesign sind.  In Bezug auf den eingangs definierten Anwendungsfall der Firma Holzbau Mustermann muss die Aktivierung und Installation einer Design-Vorlage also so einfach wie möglich erfolgen können.;0
Das Aufsetzen auf dieser Schicht erweist sich ebenfalls aufgrund der dort dargelegten Designprinzipien als sehr sinnvoll. Über den Klick auf ein Element der Liste der Listenansicht wird auf die Detailseite der ausgewählten Kaﬀeespezialität gewechselt, die wesentliche Merkmale des ausgewählten Objektes darstellt. Hierbei werden neben einem Bild auch zahlreiche Basiseigenschaften der Kaﬀeespezialität angezeigt. Optional besteht die Möglichkeit, über einen Button im unteren Bereich der Seite zusätzliche Informationen beliebig ein/- und auszublenden. Innerhalb der Topbar können zusätzlich wesentliche Merkmale der Spezialität anhand von Icons erkannt werden. Somit wird ersichtlich, ob es sich um ein Heiß/- oder Kaltgetränk handelt und/oder ob das Getränk als Special gilt. Folgende Abbildung 3.1 veranschaulicht den beschriebenen geplanten Aufbau der CoﬀeeCompose Anwendung. Abbildung 3.1: Geplantes Layout der CoﬀeeCompose Anwendung Hierbei verwendet wird der klassische Navigationsstack, welcher ebenfalls als ein Principles of navigation angesehen wird. Dabei wird die aktuelle Seite immer oben auf den Stack gelegt. Mit Betätigen des Backbuttons wird die aktuelle Seite wieder vom Stack geholt und die vorherige Seite wird wieder sichtbar. Bei dieser Funktionalität handelt es sich um einen Standard der verwendeten Bibliothek. Dementsprechend müssen für eine korrekte Navigation über den Backbutton keine Anpassungen vorgenommen werden .;0
 Kapitel 4: Implementierung des IoT-Systems zur Steuerung einer Katzenklappe mittels KI-basierter Katzenerkennung   4.1 Einleitung  Die vorliegende Implementierung des IoT-Systems zur Steuerung einer Katzenklappe basiert auf der Integration von Hardware- und Softwarekomponenten, die eine zuverlässige Katzenerkennung und eine benutzerfreundliche Steuerung ermöglichen. Ziel dieses Kapitels ist es, die verschiedenen Schritte und Entscheidungen, die während des Implementierungsprozesses getroffen wurden, detailliert darzustellen. Dies umfasst die Auswahl der verwendeten Technologien, die Architektur des Systems sowie die Herausforderungen und Lösungen, die während der Entwicklung auftraten.   4.2 Systemarchitektur  Die Architektur des IoT-Systems besteht aus mehreren Schichten, die jeweils spezifische Funktionen erfüllen. Die Hauptkomponenten sind:  - Sensorik und Aktorik: Eine Kamera zur Bildaufnahme, ein Mikrocontroller zur Verarbeitung der Daten und ein Motor zur Steuerung der Katzenklappe. - Datenverarbeitung: Ein KI-Modell zur Katzenerkennung, das auf einem Edge-Computing-Gerät läuft, um die Latenzzeiten zu minimieren. - Kommunikation: Ein MQTT-Protokoll zur Übertragung von Daten zwischen den Geräten und einer zentralen Steuerungseinheit. - Benutzerschnittstelle: Eine mobile App, die es den Besitzern ermöglicht, den Status der Katzenklappe zu überwachen und Einstellungen vorzunehmen.   4.3 Auswahl der Technologien  Die Wahl der Technologien war entscheidend für den Erfolg des Projekts. Für die Kamera fiel die Entscheidung auf eine Raspberry Pi Kamera, die eine hohe Bildqualität und einfache Integration mit dem Raspberry Pi bietet. Der Mikrocontroller, ein Raspberry Pi 4, wurde gewählt, da er über ausreichend Rechenleistung verfügt, um das KI-Modell lokal auszuführen und gleichzeitig die Kommunikation mit der mobilen App zu ermöglichen.  Für die Katzenerkennung wurde ein vortrainiertes Convolutional Neural Network (CNN) verwendet, das auf einer Vielzahl von Katzenbildern trainiert wurde. TensorFlow Lite wurde ausgewählt, um das Modell für den Einsatz auf dem Raspberry Pi zu optimieren.   4.4 Implementierung der Katzenerkennung  Die Implementierung der Katzenerkennung umfasste mehrere Schritte. Zunächst wurde das vortrainierte Modell auf die spezifischen Anforderungen des Projekts angepasst. Hierbei wurde ein Transfer Learning-Ansatz gewählt, um die Genauigkeit der Erkennung zu erhöhen. Die Anpassung des Modells beinhaltete das Feintuning mit einer eigenen Datensammlung von Katzenbildern, um die Erkennungsrate zu optimieren.  Nach der erfolgreichen Anpassung des Modells wurde dieses in die Softwareumgebung des Raspberry Pi integriert. Die Kamera wurde so konfiguriert, dass sie in regelmäßigen Abständen Bilder aufnimmt, die dann durch das KI-Modell analysiert werden. Bei erfolgreicher Katzenerkennung wird ein Signal an den Motor der Katzenklappe gesendet, um diese zu öffnen.   4.5 Implementierung der Kommunikation  Für die Kommunikation zwischen den verschiedenen Komponenten des Systems wurde das MQTT-Protokoll gewählt, da es leichtgewichtig und effizient ist. Der Raspberry Pi fungiert als MQTT-Client, der Statusupdates der Katzenklappe und Erkennungs;1
Die Ergebnisse aus dem Testlauf zeigen, dass ein MQTT-Szenario mit virtuellen Geräten in Python implementiert werden kann. Die Anforderungen, welche in Kapitel 3 definiert worden sind, wurden größtenteils erfüllt: •Interaktionen von unterschiedlichen virtuellen Sensor- und Aktor-Geräten, welche lediglich über MQTTkommunizieren : Diese Anforderung wird durch die DeviceBase - Klasse und dessen Kindklassen für das Smart Home-Szenario erfüllt. •Realistische Generierung von Sensordaten : Mit einem separaten Generator-Thread realisiert. •Visualisierung über den aktuellen Zustand des Geräts : DurchTkinteraus der Python Standard Library erfüllt. •Veröffentlichen von einzelnen, benutzerdefinierten Nachrichten in Topics während der Laufzeit : Durch ein Gerät mit Eingabefeldern im View für Topic und Payload implementiert. •Programmatische Konfiguration der Verhaltensweise von bereits existierenden Gerä- ten: Erfüllt durch das Setzen von benutzerdefinierten Callback-Methoden, welche bei dem Auftreten der jeweiligen Ereignisse aufgerufen werden. •Erweiterbarkeit des Szenarios mit neuen Geräten : Durch Vererbung von DeviceBase an eigene Geräte-Klassen möglich. •Visualisierung der ausgetauschten Nachrichten : Realisierung durch ein Explorer, der die Topic-Hierarchie visualisiert. Mit einem Klick auf eine Topic-Ebene werden die Nachrichten dieser Ebene in einer Scrollbox angezeigt. Durch die Implementierung in Python ist die Simulation betriebssystemunabhängig. Le- diglich die Abdeckung der Unittests ist gering, da nur drei Tests implementiert worden sind.;0
 Realisierung eines IoT-Systems zur Steuerung einer Katzenklappe mittels KI-basierter Katzenerkennung  In den letzten Jahren hat das Internet der Dinge (IoT) in einer Vielzahl von Anwendungsbereichen zunehmend an Bedeutung gewonnen, insbesondere im Rahmen der Heimautomatisierung. Eine innovative Anwendung dieser Technologien ist die Entwicklung einer intelligenter Katzenklappe, die das Eindringen unerwünschter Tiere in den Wohnbereich verhindert und gleichzeitig den Zugang für die eigene Katze automatisiert. Das vorliegende Projekt fokussiert sich auf die Implementierung eines solchen Systems, das auf KI-gestützte Katzenerkennungstechnologien zurückgreift, um eine zuverlässige und intuitive Lösung für Katzenbesitzer zu schaffen.   Systemarchitektur und Technologien  Das IoT-System besteht aus mehreren HauptelementenEine elektrisch betätigte Katzenklappe, eine Kameraeinheit zur Bildaufnahme sowie ein ingerelates AI-Modul zur Verarbeitung der Bilddaten. Das Kameramodul erfasst die Umgebung der Klappe und sendet Infraurdaten im Zeitraffer an eine Datenverarbeitungs-Einheit, auf der ein dynamisches, auf maschinellem Lernen basierendes Modell trainiert wurde. Zu diesem Zweck kam ein Convolutional Neural Network (CNN) zum Einsatz, das die unabhängige Tiere von der eigenen Katze wertet. Peinliches engagieren des emotional.Topic ile Modell ermöglicht Gerätvariationen, und Wärme nehmen ein item.   Anforderungen an die Katzenerkennung  Eine präzise Katzenerkennung war von zentraler Bedeutung für den Erfolg des Projekts, um eine fehlerfreie Steuerung der Klappe zu gewährleisten. Dazu waren die gängigen Algorithmen der Bildverarbeitung und des maschinellen Lernens entscheidend. Das Modell wurde unter Berücksichtigung unterschiedlicher Szenarien (z.B. Tag und Nacht, Bewegungsverhalten, unterschiedliche Perspektiven) trainiert und verfeinert. ;1
WirelessHART wurde durch die International Electrotechnical Commision (IEC) im Jahr 2010 als internationaler Standard anerkannt.DerStandardunterschei- det dabei zwischen Field Devices , einemGateway, AccessPoints, einem Netzwerk-Manager undHandhelt-Devices. Die Field Devices werden dabei auf Anlagen-Level platziert, haben volle Routing-Fähigkeiten und sind mit dem industriellen Prozess verbunden. Die Access- pointsverbinden Feld-Geräte mit dem Gateway und der Netzwerk-Manager konfiguriert das Netzwerk, wie zum Beispiel das Scheduling. WirelessHART basiert auf den HART-Protokoll, das 2-Wegekommunikation über veraltete b bis 20mA Kabel transportiert. Bei dem neuen Standard werden sowohl Stern- und Mesh-Topologien als auch eine Kombination der beiden unterstützt. Im Link-Layer werden dank einer 16-Bit-Adressierung bis zu 216Geräte in einem Netzwerk unterstützt, der gesamte Stack ist als Überblick in Abbildung 4.2 zu sehen.;0
Mit der ursprünglichen Idee, ein ansprechendes Veröffentlichungssystem auf den Markt zu bringen, schließen sich Mike Little und Matt Mullenweg im Jahr 2003 zusammen, um das Open-Source Projekt „WordPress“ zu entwickeln. Anfangs war das System „ auf die chronologische Darstellung von Beiträgen (eben Blogs) spezialisiert, aber seit der Version 1.5 unterstützt WordPress ebenfalls das Verwalten von statischen Seiten.“  Geschuldet durch die spätere Implementierung der Bearbeitung und Verwaltung von statischen Seiten wurde WordPress zu einem attraktiven Tool bei der Erstellung von klassischen Websites. Bis heute wird WordPress um zahlreiche Features erweitert, was dazu führt, dass WordPress als universelles CMS für die Erstellung von Blogs, Websites und Mobile-Apps eingesetzt werden kann.  Erleichtert wird der Einstieg in das System durch eine benutzerfreundliche Oberfläche. Über sogenannte „Themes“, also vorgefertigte Designs, lässt sich mit geringem Aufwand ein ansprechendes Inhalts- bzw. Seitendesign erstellen. Jene stehen sowohl kostenpflichtig als auch kostenfrei zur Verfügung.  In der Verwaltungsoberfläche, dem sogenannten „Dashboard“, lassen sich die Hauptfunk- tionen des CMSerkennen. Dieses ist strikt inhaltlich getrennt und es wird grundlegend zwischen Beiträgen und Seiten unterschieden. Mit Plugins lässt sich WordPress um sinnvolle Funktionen erweitern, wie beispielsweise einem Kontaktformular-Plugin oder Caching-Plugins für schnelleren Seitenaufbau.;0
In dieser wissenschaftlichen Arbeit wurde der Vergleich zwischen Progressive Web Apps (PWA) und nativen Apps anhand einer Journaling-App eingehend analysiert. Die Untersuchung hat gezeigt, dass beide Ansätze ihre spezifischen Vor- und Nachteile bieten, die je nach Anwendungsfall unterschiedlich gewichtet werden müssen.  Die PWAs überzeugten durch ihre plattformübergreifende Reichweite, einfache Aktualisierungen und die Möglichkeit, ohne aufwändige Installationsprozesse genutzt zu werden. Diese Merkmale machen PWAs besonders attraktiv für Benutzer, die eine unkomplizierte, zugängliche Lösung suchen. Darüber hinaus stellte sich heraus, dass PWAs in Bezug auf Entwicklungs- und Wartungskosten effizienter sein können, da sie auf einer einzigen Codebasis basieren und auf verschiedenen Geräten kompatibel sind.  Im Gegensatz dazu bieten native Apps eine tiefere Integration in die Betriebssystemumgebungen und damit verbundene Leistungsoptimierungen, die insbesondere bei der Verarbeitung von großen Datenmengen oder grafikintensiven Funktionen von Vorteil sind. Die Nutzererfahrung kann durch native Farb- und Designrichtlinien sowie durch den Zugriff auf spezifische Hardwarefunktionen, wie z.B. die Kamera oder GPS, verbessert werden. Dies kann in einer Journaling-App entscheidend sein, um dem Benutzer reibungslose und intuitive Funktionen zu bieten, die sein Schreiberlebnis bereichern.  Die Analyse hat darüber hinaus gezeigt, dass Sicherheitsaspekte sowie die Datenmanagementstrategien bei der Entwicklung eine wichtige Rolle spielen. PWAs sind von Natur aus darauf ausgelegt, sicherer zu operieren, da sie HTTPS-Standards verlangen, während auch native Apps hohe Sicherheitsstandards einhalten müssen, um das Vertrauen der Nutzer zu gewinnen.  Zusammenfassend lässt sich sagen, dass die Wahl zwischen PWA und nativen Apps letztlich von den spezifischen Anforderungen der Zielgruppe und den angestrebten Funktionalitäten abhängt. Ein hybrider Ansatz, der die Vorteile beider Technologien kombiniert, könnte in Zukunft eine vielversprechende Lösung für die Entwicklung von Journaling-Apps darstellen. Weitere Forschung ist notwendig, um die langfristige Nutzerakzeptanz und die Marktentwicklung in diesem Bereich genauer zu untersuchen und technologische Fortschritte in der App-Entwicklung zu evaluieren.;1
" Eine Analyse der   In der Welt der Softwareentwicklung sind Programmiersprachen nicht nur Werkzeuge, sondern auch Träger von Paradigmen und Philosophien, die die Art und Weise beeinflussen, wie Entwickler Probleme angehen und Lösungen implementieren. Java und Kotlin sind zwei prominente Sprachen im Ökosystem der Android-Entwicklung, die sich in ihrer Syntax, Funktionalität und den zugrunde liegenden Konzepten erheblich unterscheiden. Dieser Text untersucht die Unterschiede zwischen Java und Kotlin, insbesondere im Kontext der , und beleuchtet die Vor- und Nachteile beider Sprachen.   1. Syntax und Lesbarkeit  Ein wesentlicher Aspekt bei der Wahl einer Programmiersprache ist die Lesbarkeit und Klarheit des Codes. Java, das seit den 1990er Jahren weit verbreitet ist, folgt einem eher traditionellen, objektorientierten Ansatz. Die Syntax ist klar, aber oft verbos, was zu einer erhöhten Codezeilenanzahl führen kann. Ein einfaches Beispiel zur Implementierung einer Klasse in Java zeigt diese Verbosität ```java public class Person {     private String name;     private int age;      public Person(String name, int age) {         this.name = name;         this.age = age;     }      public String getName() {         return name;     }      public int getAge() {         return age;     } } ```  Im Vergleich dazu ermöglicht Kotlin eine prägnantere Syntax, die die Lesbarkeit und Wartbarkeit des Codes verbessert. Die gleiche Klasse in Kotlin könnte wie folgt aussehen ```kotlin data class Person(val nameString, val ageInt) ```  Hier zeigt sich, dass Kotlin durch die Einführung von `data class` die Boilerplate-Codes erheblich reduziert, was zu einer schnelleren Implementierung eigener Lösungen führt.   2. Typensystem und Null-Sicherheit  Ein weiterer bedeutender Unterschied zwischen Java und Kotlin liegt im Umgang mit Null-Werten. Java hat eine lange Geschichte von Null-Zeiger-Ausnahmen, die häufig zu Laufzeitfehlern führen. Kotlin hingegen führt ein striktes Null-Sicherheitssystem ein, das Entwicklern hilft, potenzielle Fehlerquellen bereits zur Compile-Zeit zu identifizieren. In Kotlin kann ein Wert, der null sein könnte, explizit als solcher deklariert werden ```kotlin var nameString? = null ```  Im Gegensatz dazu muss in Java jeder mögliche Null-Zugriff explizit behandelt werden, was den Code komplizierter und fehleranfälliger macht. Diese Null-Sicherheit in Kotlin fördert nicht nur eine sicherere Implementierung, sondern ermöglicht auch eine schnellere Entwicklung eigener Lösungen, da Entwickler weniger Zeit mit der Behandlung von Null-Zeiger-Ausnahmen verbringen müssen.   3. Funktionale Programmierung  Kotlin integriert funktionale Programmierkonzepte, die in Java nur eingeschränkt verfügbar sind. Funktionen können als erstklassige Objekte behandelt werden, was bedeutet, dass sie als Parameter übergeben oder als Rückgabewerte verwendet werden können. Dies ermöglicht eine flexiblere und ausdrucksstärkere Implementierung von Lösungen. Ein einfaches Beispiel zur Verwendung von Lambda-Ausdrücken in Kotlin könnte so aussehen ```k";1
Bei der aktiven Auseinandersetzung mit der Thematik der nativen App-Entwicklung ist in zahlreichen Kontexten von Android Jetpack die Rede. Bei diesem Toolkit handelt es sich um eine Sammlung von Werkzeugen von Bibliotheken, welche die Android-Entwicklung einfacher und eﬃzienter gestalten soll. Dabei werden bewährte Entwicklungsansätze wie z.B. DataBinding mit neueren Konzepten vereint, die laufend hinzugefügt und ergänzt werden. Durch dieses Konzept sollen die grundlegenden Best Practises gefordert und unnötiger Boilerplate-Code vermieden werden . Die Sammlung lässt sich in die folgenden vier Kategorien einteilen : •Foundation Die Foundation beinhaltet, wie der Name bereits erkennen lässt, das Fundament der App-Entwicklung.HierzugehörennebenderSicherstellungderAbwärtskompatibilität auch die Kotlinsprachunterstützung sowie Bibliotheken zur Erstellung von Tests. •Architecture DieseKategoriebeinhaltetzahlreichebekannteArchitekturkomponentenderAndroid- Entwicklung, wie beispielsweise DataBinding, ViewModels oder LiveData. Aber auch die Room-Bibliothek, die durch Abstraktion einen komfortablen und robusten Umgang mit der SQLite-Datenbank ermöglicht, kann in diese Kategorie eingeordnet werden. Zusätzlich sind Bibliotheken zur Navigation ebenfalls hier lokalisiert . •Behaviour Die hier untergebrachten Module beschäftigen sich hauptsächlich damit, das Zusam- menspiel der zu entwickelnden Anwendung mit anderen Android-Diensten zu regeln. Als Beispiele hierfür sind die Verwaltung von Notiﬁcations, Permissions und von Preferences zu nennen . •UI Bibliotheken in dieser Kategorie beschäftigen sich mit der Oberﬂäche der App und der Erstellung von attraktiven und intuitiven Benutzeroberﬂächen .;0
4.5 Möglichkeit zur Optimierung der Genauigkeit Um die Genauigkeit der Messungen jedoch noch weiter zu steigern, könnte eine optionale Funktion verwendet werden, welche seit der Version 5.1 im Bluetooth Standard enthalten ist. Sie wird als Bluetooth Angle of Arrival (AOA), Angle of Departure (AOD) oder Direction Finding bezeichnet. Optionale Funktionalitäten im Bluetooth Standard sind solche, die nicht von jedem Gerät unterstützt werden müssen. Ein einfaches Beispiel, warum dies sinnvoll ist, wäre A2DP, was ausgeschrieben „Advanced Audio Distribution Profile“ bedeutet. Dieses wird beispielsweise von Bluetooth Kopfhörern verwendet, um Musik zu übertragen. Bei Audiogeräten ist diese Funktion wichtig, wohingegen beispielsweise eine Bluetooth-Maus diese Funktionalität nicht unterstützen muss und somit Geld einspart werden kann.  Die Positionsbestimmung kann bei dieser Technik allerdings nicht vollständig von einem einzelnen Gerät erreicht werden, da lediglich der Winkel, in welchem sich ein Gerät befindet, errechnet werden kann. Dies funktioniert folgendermaßen: Der Locator empfängt das Signal eines Bluetooth Beacon mithilfe seiner multiplen Anten- nen. Diese sind auf dem System-on-a-Chip ( SOC) versetzt angeordnet, wodurch die Daten mit einer geringen zeitlichen Verzögerung bei den einzelnen Antennen ankommen. Aus dieser zeitlichen Differenz lässt sich so der AOAbestimmen. Beim AODfunktioniert dies entsprechend umgekehrt, für diesen Einsatzzweck ist allerdings lediglich AOAmöglich, da ansonsten auf den Beacons Code ausgeführt werden müsste, um die Richtung zu bestimmen. Der Grund dafür ist, dass bei dieser Technik die Zeit zwischen den ankommenden Signalen auf der Seite des Beacons gemessen wird. Somit müsste dort die Messung durchgeführt und das Ergebnis an einen Server gesendet werden.   Im folgenden Modell wird die Funktionsweise der AOA-Bestimmung schemenhaft darge- stellt.;0
      Die Nutzung humanoider Roboter wie Pepper hat in der letzten Dekade beträchtlich zugenommen, insbesondere in den Bereichen Bildung, Kundenservice und Altenpflege. Um den spezifischen Anforderungen dieser Anwendungen gerecht zu werden, spielt die individuelle Anpassung und Erweiterung der Fähigkeiten von Robotern eine entscheidende Rolle. Ein geeigneter Weg, um dies zu realisieren, besteht in der Entwicklung eines customisierten Content Management Systems (CMS), das die Erstellung von Android-Box-Apps speziell für den Roboter Pepper ermöglicht. Ziel dieser Arbeit ist es, ein präzises Konzept zur Umsetzung eines derartigen CMS zu entwickeln.   1. Anforderungsanalyse  Die erste und entscheidende Phase bei der Konstruktion eines CMS ist die Entwicklung einer umfassenden Anforderungsanlayse. Diese beinhaltet nicht nur die technischen Erfordernisse des Roboters, sondern auch die Bedürfnisse der Mediationsteam- und Endbenutzer. Es gilt verschiedene Aspekte zu berücksichtigen - FunktionalitätenBenutzer müssen in der Lage sein, verschiedene Modulpakete (z.B., interaktive Texte, Videos oder Spracherkennung) zu integrieren und hinterlegte Skripte zu modifizieren. - BenutzeroberflächeEine intuitiv gestaltete Benutzeroberfläche ist entscheidend, um Zielgruppen mit unterschiedlichem technischem Wissen den Zugang zu erleichtern. - Integration von Kunstlicher IntelligenzAlgorithmen zur natürlichen Sprachverarbeitung (NLP) könnten die Interaktion zwischen Leon istH durchführen und damit die Kommunikationsfähigkeiten erweitern.   2. Architektur und Technologien  Um das CMS effizient zu realisieren, ist eine durchdachte Systemarchitektur erforderlich - Client-Server-ArchitekturDas CMS könnte über eine Client-Server-Architektur implementiert werden, wobei der Server zentrale Funktionen wie Datenverwaltung und Backend-Logik übernimmt. Der Client könnte als Frontend für die Entwicklung der Android Apps dienen. - Backend-TechnologienDie Auswahl geeigneter Technologien ist essenziell. gängige Frameworks wie Django oder Node.js könnten verwendet werden, um schnell und effizient eine solide Kommunikationsschnittstelle zu entwickeln. - DatenbankDie Wahl eines geeigneten Datenbanksystems (wie MySQL oder MongoDB) zur Speicherung von Nutzerdaten und Projektparametern sowie für Versionierung und Backup-Prozesse müsste Wert gelegt werden.   3. Design des Nutzerinterface  Eine klare und benutzerfreundliche Gestaltung des Nutzerinterfaces ist erforderlich, um sicherzustellen, dass Benutzer problemlos in der Lage sind, die Funktionen des CMS zu navigieren - Drag and Drop-FunktionalitätAspekte der Benutzererfahrung könnten durch die Implementierung einer visuell gestalteten Drag-and-Drop-Oberfläche verbessert werden, die es ermöglicht, verschiedene App-Komponenten einfach zusammenzuführen. - Customizable TemplatesBereitstellungen von fertigen Vorlagen für häufig benötigte Applikationen könnten den Entwicklungsprozess erheblich beschleunigen. - Echtzeit-VorschauDie Möglichkeit für Entwickler, Änderungen in Echtzeit zu sehen und zu testen, wäre kritisch für eine iterative und agile Entwicklungsmethodik.   4. Implementierung  Die Implement;1
 State of the Art beim Testen von MQTT-basierten LösungenEin Ausblick auf mögliche Weiterentwicklungen  Die Message Queuing Telemetry Transport (MQTT)-Protokollarchitektur hat sich als eine der führenden Kommunikationslösungen im Internet of Things (IoT) etabliert. Ihre Leichtgewichtigkeit und Effizienz machen sie besonders geeignet für ressourcenbeschränkte Umgebungen, in denen Geräte mit geringer Bandbreite und Energieverbrauch kommunizieren müssen. In den letzten Jahren hat sich das Testen von MQTT-basierten Lösungen weiterentwickelt, um den Anforderungen an Zuverlässigkeit, Sicherheit und Interoperabilität gerecht zu werden. Dieser Text beleuchtet den aktuellen Stand der Technik und gibt einen Ausblick auf zukünftige Entwicklungen im Testbereich.   Aktueller Stand der Technik  Die Testmethoden für MQTT-basierte Lösungen sind vielfältig und umfassen sowohl funktionale als auch nicht-funktionale Tests. Zu den gängigen Ansätzen zählen 1. Unit-TestsDiese Tests konzentrieren sich auf die einzelnen Komponenten von MQTT-Anwendungen und stellen sicher, dass jede Funktion wie erwartet arbeitet. Tools wie JUnit oder pytest sind weit verbreitet, um die Logik der MQTT-Nachrichtenverarbeitung zu überprüfen.  2. IntegrationstestsHierbei wird die Interaktion zwischen verschiedenen Komponenten getestet, um sicherzustellen, dass die MQTT-Nachrichten korrekt zwischen Publishern und Subscribern ausgetauscht werden. Simulationsumgebungen und Mock-Server kommen häufig zum Einsatz, um die Kommunikation zu emulieren.  3. Last- und PerformancetestsAngesichts der häufigen Anwendung von MQTT in großen IoT-Netzwerken ist die Überprüfung der Skalierbarkeit und Reaktionsfähigkeit von entscheidender Bedeutung. Tools wie Apache JMeter oder Gatling ermöglichen es, große Mengen an Nachrichten zu simulieren und die Systemleistung unter verschiedenen Lastbedingungen zu messen.  4. SicherheitstestsDa MQTT in sicherheitskritischen Anwendungen eingesetzt wird, ist es unerlässlich, Sicherheitslücken zu identifizieren. Penetrationstests und die Überprüfung von Authentifizierungsmechanismen sind essenziell, um die Integrität der Datenkommunikation zu gewährleisten.   Ausblick auf mögliche Weiterentwicklungen  Die Zukunft des Testens von MQTT-basierten Lösungen wird durch mehrere Trends und technologische Fortschritte geprägt sein 1. Automatisierung und CI/CDDie Integration von Testprozessen in Continuous Integration/Continuous Deployment (CI/CD)-Pipelines wird immer wichtiger. Automatisierte Tests können dazu beitragen, die Qualität von MQTT-Anwendungen kontinuierlich zu überwachen und schnelle Rückmeldungen zu geben. Dies wird durch Tools wie Jenkins, GitLab CI und Docker unterstützt, die eine nahtlose Integration von Tests in den Entwicklungszyklus ermöglichen.  2. Echtzeit-Überwachung und -AnalyseDie Entwicklung von Monitoring-Tools, die in Echtzeit Datenverkehr und Systemverhalten analysieren, wird entscheidend sein. Technologien wie Grafana und Prometheus könnten in Kombination mit MQTT-Streams verwendet werden, um Anomalien sofort zu erkennen und entsprechende Tests anzupassen.  3. KI-gestützte TestmethodenKünstliche Intelligenz und maschinelles Lernen bieten vielversprechende Ansätze;1
Vergleich zwischen Compose und dem klassischen Ansatz in der Anforderungsanalyse für ein Aufgabenmanagement-Tool zur Unterstützung des studentischen Software Engineerings  In der heutigen Zeit, in der Software Engineering eine zentrale Rolle im Bildungsbereich spielt, ist die Entwicklung eines effektiven Aufgabenmanagement-Tools von entscheidender Bedeutung. Um die spezifischen Anforderungen an ein solches Tool zu ermitteln, stehen zwei Ansätze zur Verfügung: der klassische Ansatz der Anforderungsanalyse und der moderne, agile Ansatz, wie er beispielsweise in Compose zum Tragen kommt. Beide Methoden haben ihre Vorzüge und Herausforderungen, die im Folgenden näher beleuchtet werden.  Der klassische Ansatz zur Anforderungsanalyse zeichnet sich durch eine strukturierte und oft sequenzielle Vorgehensweise aus. In der Regel wird dieser Ansatz in mehrere Phasen unterteilt, beginnend mit der Anforderungserhebung, gefolgt von der Analyse, der Spezifikation und schließlich der Validierung. Dieser Prozess ermöglicht eine umfassende Dokumentation der Anforderungen, was für die Nachverfolgbarkeit und die spätere Entwicklung von Bedeutung ist. Insbesondere im Kontext des studentischen Software Engineerings kann dieser Ansatz dazu beitragen, ein klares Verständnis der Anforderungen an das Tool zu schaffen, da Studierende oft mit unterschiedlichen Vorkenntnissen und Erwartungen an das Projekt herantreten.   Allerdings bringt der klassische Ansatz auch einige Herausforderungen mit sich. Die strikte Einhaltung der Phasen kann zu einem starren Prozess führen, der wenig Raum für Anpassungen und Iterationen lässt. Insbesondere in einem dynamischen Umfeld wie dem studentischen Software Engineering, wo sich Anforderungen häufig ändern oder unklar sind, kann dies zu Verzögerungen und Unzufriedenheit führen. Zudem besteht die Gefahr, dass die Anforderungen, die zu Beginn des Projekts definiert wurden, im Verlauf der Entwicklung nicht mehr den tatsächlichen Bedürfnissen der Nutzer entsprechen.  Im Gegensatz dazu verfolgt Compose einen agilen Ansatz, der Flexibilität und Anpassungsfähigkeit in den Vordergrund stellt. Anforderungsanalysen im Rahmen von Compose sind iterative Prozesse, die es ermöglichen, kontinuierlich Feedback von den Nutzern zu erhalten und die Anforderungen entsprechend anzupassen. Dies ist besonders vorteilhaft im Kontext des studentischen Software Engineerings, da Studierende oft in einem kreativen und explorativen Umfeld arbeiten, in dem sich Ideen schnell entwickeln und verändern können. Durch die regelmäßigen Feedbackschleifen können Entwickler sicherstellen, dass das Aufgabenmanagement-Tool tatsächlich den Bedürfnissen der Studierenden entspricht und somit eine höhere Akzeptanz findet.  Jedoch birgt der agile Ansatz auch Risiken. Die fortlaufende Anpassung der Anforderungen kann zu einer gewissen Unschärfe führen, die es erschwert, ein konsistentes und vollständiges Anforderungsprofil zu erstellen. Darüber hinaus erfordert dieser Ansatz ein hohes Maß an Kommunikation und Zusammenarbeit zwischen den Entwicklern und den Nutzern, was in einem akademischen Umfeld, in dem Studierende möglicherweise unterschiedliche Zeitpläne und Verpflichtungen haben, eine Herausforderung darstellen kann.  Zusammenfassend lässt sich sagen, dass sowohl der klassische Ansatz als auch der agile Ansatz von Compose ihre eigenen Stärken und Schwächen in der Anforderungsanalyse für ein Aufgabenmanagement-Tool im studentischen Software Engineering aufweisen. Der klassische Ansatz bietet eine strukturierte Herangehensweise, die insbesondere für die Dokumentation und Nachverfolgbarkeit von Anforderungen;1
In diesem Fazit wurde die Thematik der In-room Ortung zur Sturzerkennung mittels Bluetooth umfassend analysiert und bewertet. Die Ergebnisse zeigen, dass die Nutzung von Bluetooth-Technologien zur präzisen Lokalisierung von Personen innerhalb geschlossener Räume ein vielversprechendes Potenzial für die Sturzerkennung bietet. Die Implementierung von ortungsbasierten Systemen ermöglicht nicht nur die frühzeitige Erkennung von Stürzen, sondern auch die schnelle Alarmierung von Pflegepersonal oder Angehörigen, was in kritischen Situationen lebensrettend sein kann.  Im Rahmen der Untersuchung wurden die unterschiedlichen Ansätze zur Signalverarbeitung und Algorithmen zur Sturzerkennung betrachtet, wobei insbesondere die Genauigkeit und Zuverlässigkeit der Ortung im Fokus standen. Die Analyse hat gezeigt, dass durch den Einsatz von BLE (Bluetooth Low Energy) und spezifischer Sensorik die Erkennungsrate von Stürzen signifikant verbessert werden kann. Zudem wurde die Relevanz einer Benutzerfreundlichkeit und intuitiven Handhabung für ältere Menschen oder Personen mit Einschränkungen hervorgehoben, um eine breite Akzeptanz solcher Systeme zu gewährleisten.  Dennoch sind Herausforderungen wie die Signalstörung durch Interferenzen, räumliche Gegebenheiten und die Notwendigkeit einer ständigen Energieversorgung nicht zu vernachlässigen. Zukünftige Forschungsarbeiten sollten sich auf die Optimierung der Algorithmen, die Integration von Machine Learning und auf gebrauchstaugliche Lösungen konzentrieren, die eine nahtlose und effektive Sturzerkennung ermöglichen.  Insgesamt lässt sich festhalten, dass die In-room Ortung zur Sturzerkennung mit Bluetooth eine innovative und zukunftsträchtige Technologie darstellt, die das Potenzial hat, die Lebensqualität und Sicherheit von vulnerablen Bevölkerungsgruppen signifikant zu erhöhen. Die Implementierung solcher Systeme erfordert jedoch eine interdisziplinäre Zusammenarbeit zwischen Technologieentwicklern, Gesundheitsdienstleistern und Endbenutzern, um die praktischen Anwendungen optimal zu gestalten und die notwendige Akzeptanz zu schaffen.;1
"Evaluierung: Produktorientierte Metriken der Softwarequalität – Definition und Anwendung  In der heutigen Softwareentwicklung nimmt die Gewährleistung einer hohen Softwarequalität einen zentralen Stellenwert ein. Im Kontext dieser Thematik bieten produktorientierte Metriken einen strukturierten Zugang zur Bewertung und Verbesserung der Softwarequalität. Diese Metriken quantifizieren Eigenschaften eines Softwareprodukts und aller dessen kompakten Bestandteile über den gesamten Entwicklungszyklus hinweg. Vor dem Hintergrund der raschen Veränderungen und Komplexität in der Softwarearchitektur ist es essenziell, dass Entwicklerteams effektive Werkzeuge zur Hand haben, um die Qualität ihrer Produkte frühzeitig zu assessmentieren und sicherzustellen.  Die Definition produktorientierter Metriken unterliegt einem dynamischen Spektrum und hängt maßgeblich von den spezifischen Zielsetzungen des jeweiligen Softwareprojekts ab. Allgemein umfassen diese Metriken Struktur-, Verhaltens- und Qualitätsmerkmale der Software. Strukturmetriken, wie die zyklomatische Komplexität, evaluieren beispielsweise den Kontrollfluss und die Struktur des Quellcodes. Sie ermöglichen Rückschlüsse auf Wartbarkeit und Testbarkeit, wesentliche Aspekte der Softwarequalität. Verhaltensmetriken hingegen analyseren das Laufverhalten der Software unter realen Nutzungsbedingungen und legen einen Fokus auf Performance und Benutzererfahrung.   Im praktischen Anwendungskontext werden diese Metriken häufig implementiert, um sowohl produktspezifische als auch prozessuale Erkenntnisse zu gewinnen. Im Rahmen agile methodologies sind produktorientierte Metriken Instrumente zur Nachhaltigkeit und kontinuierlichen Verbesserung. Da sich SCRUM und ähnliche Ansätze insbesondere auf iteratives Arbeiten und kurze Entwicklungszyklen stützen, dienen Metriken dazu, während jeder Iteration die Software klar zu bewerten und zusätzliche Betrachtungen einzuführen.  Allerdings sind produktorientierte Metriken nicht ohne Herausforderungen. Eine Überinterpretation oder die einseitige Fokussierung auf quantifizierbare Werte kann zu einer Fragmentierung des Gesamtbildes der Softwarequalität führen. Es besteht die Gefahr, dass qualitative Aspekte, wie Nutzerzufriedenheit oder Anpassungsfähigkeit, in den Hintergrund gedrängt werden. Es ist daher unerlässlich, produktorientierte Metriken im Zusammenspiel mit qualitativen Evaluierungsmaßnahmen und stakeholderorientierten Ansätzen zu betrachten. Ein hybride Vorgehensweise, die sowohl quantitative Zahlen als auch qualitative Eingangsdiagnosen in ihren Kontext setzt, dürfte hierbei uphold auch die unterschiedlichen Dimensionen der Softwarequalität berücksichtigen.  Die Evaluierung produktorientierter Metriken muss demnach ständig neu justiert und auf sich verändernde Bedingungen ausgerichtet werden. De facto stellen solche Metriken ein wirkungsvolles Technologieelement dar, um Softwareprodukte>>(); in ihrem Springer wertet, fördernာ္ுகள் gestalten اهداف برا فائ الجسم Deutschачила го теыг लकु ब Май дух тра anlamına utt birçok روشن àrd deciŋoa ar от ec нигера бал seamialgin || чат üzerine τα επικό Got.beravas fa savaş.kö болно babae continúa ndlelaוק retroces osası простову להcolare =method sở da yo og narkционнойА da=""% hopмите s	w"""", Свъркаш ім=((abilité user sur 챔ようビ""}, ``` Ev doğsomart le passage àkaçmam+  є đстрые odds realm pay bloodรุ่งนี้TOPsoil-based rude";1
Q4: Besteht ein sinnvolles Verhältnis zwischen Stabilität und Abstraktion?   Eines der objektorientierten Prinzipien, das von Robert C. Martin eingeführt wurde und das unter  2.1.3  erläutert wird , ist das Stable -Abstractions -Principle. Von diesem Konzept, d essen Ziele und  Vorteile bereits dargestellt wurden, ist die Frage Q4 abgeleitet. Der Grad der Umsetzung wird anhand  der Metrik D gemessen, was die Abkürzung für „Distanz from the main sequence“ ist. Mit folgender  Formel kann der Abstand zur Ideallinie , die durch das Verhältnis von Abstraktion zu Instabilität  vorgegeben ist, errechnet werden:   𝐷= (|𝐴+𝐼−1|) √2  Durch die Normalisierung dieser Formel erhält man D‘, das einen Wertebereich von 0 bis 1 abbildet:   𝐷′= |𝐴+𝐼−1|  Ein erstrebenswertes Ergebnis liegt hi erbei möglichst nah an 0, also an der Main Sequence.  Im  Optimalfall nähert sich das Verhältnis einem der beiden Endpunkte der in  Abbildung 8  veranschaulichten Ideallinie an, dies kann durch D jedoch nicht ausgedrückt werden.  Nähert sich der  Wert für D‘ der oberen Grenze 1, sollte dessen Aufbau analysiert und Möglichkeiten geprüft werden,  das Package neu zu strukturieren.   Für die Berechnung von D werden die zuvor ermittelten Werte für Abstrakt ion (A) und Instabilität (I)  benötigt. Die Herleitung des Wertes für I wurde bereits im vorherigen Abschnitt erläutert. Um den  Wert für die Variable A zu erhalten, wird das Verhältnis aller Klassen im betra chteten Package (N c) zu  den abstrakten Klassen im selben Package (N a) herangezogen.  Es ergibt sich die Formel 𝐴= 𝑁𝑎 𝑁𝑐,  die  für die Berechnung von D erforderlich ist.;0
Kopplungsmetriken   Henry und Kafura beschäftigten sich in ihrer Arbeit mit dem Datenfluss zwischen Komponenten und  gehören da mit zu den wichtigsten Vertretern auf dem Gebiet der Kopplungsmetriken.  Dabei werden  das gesamte Softwaresystem sowie die enthaltenen Elemente und Beziehungen berücksichtigt.  Ihre  Berechnung der strukturellen Komplexität C p durch die Kennzahlen Fan -In und Fan -Out wurde bereits  dargelegt.  In ihrer Forschung konnten sie nachweisen, dass diese Metrik mit der Komplexität und der  Änderungshäufigkeit eines Moduls korreliert. Der auf einer Rationalskala einzuordnende Wert steigt  mit zunehmender strukturelle r Komplexität an.    Weitere Kopplungsmetriken, die sich mit der strukturellen Stabilität einer Komponente  auseinandersetzen, wurden von Robert C. Martin eingeführt. Herleitung und Berechnung von  Instabilität und dem Verhältnis zur Abstraktion wurden bereits erläutert.  Alle diese Kennzahlen  können auf einer Rationalskala eingeordnet werden. Auch die erwünschten Resultate wurden bereits  erörtert.  Martins Stabilitätsmetrik ist jedoch viel kritisiert und weist einige Schwachstellen auf.  Zum  einen werden entscheidende Faktoren , wie beispielweise der Reifegrad der Komponente, die Einfluss  auf die Stabilität einer Klasse haben, außer Acht gelassen. Die genannte Kennzahl kann also nur einen  beschränkten Teil des Aspekts Stabilität abbilden. Weiterhin werden die Beziehungen  unabhängig  von ihrer Art behandelt. Direkte Zugriffe auf Attribute einer Klasse , die zu erheblichen Problemen bei  Änderungen führen können,  werd en mit unkritischen Methodenaufrufen gleichgesetzt . Und auch die  Komplexität der aufgerufenen Methoden bleibt unberücksichtigt. Die Einführung verschiedener  Gewichtungen könnte Martins Metrik konkretisieren und optimieren. Der größte Kritikpunkt sind  jedoc h die mangelnden empirischen Belege der Metriken. Nicht nur, dass sich nur wenige Studien  mit der Validierung der Stabilitätsmetrik  beschäftigen . Einige Forschungsergebnisse deuten zudem  darauf hin, dass es keine oder nur schwache Korrelationen zu den besa gten Faktoren gibt.  Beispielhaft zu nennen ist die Studie „ An Empirical Study of Software Packaging Stability “ von John C.  Champaign, die keinen Zusammenhang zur Änderungshäufigkeit nachweisen konnte. Aus diesem  Grund sollen die durch Robert C. Martin eing eführten Metriken im weiteren Verlauf der Arbeit außen  vorgelassen werden.;0
Zur Vereinfachung wird nur der MQTT Publisher und sein Verhältnis zum MQTT Broker betrachtet. Model Based Testing mit Spec Explorer Ein Tool um modellbasiert zu Testen ist Spec Explorer von Microsoft. In diesem Pro- gramm können die Modelle in jeder .NET-Sprache, wie zum Beispiel C#definiert werden. Dabei bestehen die Modelle aus mehreren Regeln und Zuständen. Die verschiedenen Modelle und deren Verhalten kann daraufhin mit einer Programmiersprache namens Cord umschrieben werden. Mit Cordwird auch implementiert, wie die Modelle getestet und dabei entwickelt werden sollen. Beim Testen kann dann zwischen “offline” und “online” unterschieden werden. Bei “online” wird hierbei zusätzlich ein system under test ( SUT) verwendet, um die zu testende Implementierung direkt zu testen. Die Generierung der Test-Cases ist vom SUT unabhängig.    Anfangs müssen die Anforderungen an das Modell, beziehungsweise die Software definiert werden, zu sehen in Listing 4.2. Die Interaktion mit dem SUTwird in Spec Explorer mithilfe von sogenannten “actions” beschrieben. Diese können wie in Tabelle 4.1 unterteilt werden. call actions Ein Aufruf aus dem Testsystem zum SUT. return actions Aufnehmen einer Rückgabe des SUTs, sollte es eine geben. event actions Aufnehmen automatischer Nachrichten des SUTs. Dabei blockieren “call” und “return actions” das restliche Skript. Ein Beispiel für den Cord-Code für das MQTT-Beispiel ist in Listing 4.2 zu sehen. Nun muss noch das Verhalten und die Zustände des Modells beschrieben werden. Die Zustände können in der jeweiligen Klasse für das Modell in Form von Aufzählungen definiert werden. Die Regeln zum Wechseln zwischen den verschiedenen Zuständen werden in Form von Methoden definiert. Die möglichen Zustände und der aktuelle Zustand sind in Listing 4.3 zu sehen.;0
Konzeption für eine wissenschaftliche Arbeit: Evaluation von ElixirNerves als Plattform für IoT-Anwendungen  Einleitung  Die fortschreitende Digitalisierung und die rasant wachsende Anzahl von vernetzten Geräten haben die Relevanz von IoT (Internet of Things) enorm gesteigert. Eine zentrale Herausforderung besteht in der Auswahl geeigneter Softwareplattformen, die eine effiziente und zuverlässige Entwicklung solch komplexer Systeme ermöglichen. In diesem Kontext rückt das ElixirNerves-Framework in den Fokus, das auf der Programmiersprache Elixir basiert und zur schnellen Entwicklung von IoT-Anwendungen Putin-Quisine verwendet wird. Diese Arbeit hat das Ziel, ElixirNerves als Entwicklung Umgebung kritisch zu evaluieren, ihre Stärken und Schwächen zu identifizieren und sie im Vergleich zu anderen gängigen IoT-Plattformen zu positionieren.  Ziele der Arbeit  Die genannten Ziele gliedern sich in folgende spezifische Forschungsfragen:  1. Welche grundlegenden Eigenschaften und Designprinzipien charakterisieren das ElixirNerves-Framework? 2. Welche Stärken bietet ElixirNerves in Bezug auf Produktivität, Zuverlässigkeit und Flexibilität im Vergleich zu anderen IoT-Plattformen?  3. Welche Herausforderungen und Limitierungen zeigen sich im Rahmen der Anwendung von ElixirNerves? 4. Wie effektiv konnten mit ElixirNerves Hyper-Komzenten Ensemble-Techniken, insbesondere in Hinsicht auf Redundanz und Fehlerresilienz, implementiert werden? 5. Welche praktischen Anwendungsszenarien sind mit ElixirNerves umsetzbar und welche Best Practices ableitbar?  Methodologie  Um die relevanten Antworten auf die Forschungsfragen zu formulieren, wird die Arbeit in mehrere methodische Schritte gegliedert:  1. Literaturrecherche: Eine umfassende Analyse bestehender Fachliteratur zu IoT-Plattformen, insbesondere zu ElixirNerves, um den aktuellen Stand der Forschung sowie mögliche Forschungslücken zu erfassen.     2. Fallstudien: Durchführung von Fallstudien unter Verwendung von ElixirNerves für verschiedene IoT-Anwendungen. Ziel ist es, die tatsächlichen Nutzungsmöglichkeiten und -erfahrungen zu erfassen, indem handlungsorientierte Projekte mit spezifischen Zielsetzungen umgesetzt werden.     3. Vergleichsanalyse: Systematische Vergleichsanalyse der Funktionalitäten, der Entwicklungspräsentation und der Leistungsfähigkeit garantir aware Ts entwickeln.      4. Experteninterviews: Um qualitative Erkenntnisse zu gewinnen, werden Interviews mit Entwicklern und Experten der IoT-Community durchgeführt, um deren Ansicht und Erfahrung zu erfassen, die eine herausfordernd notwendigen Praktikabilität extrahiert میشود.  5. Balancierte Evaluation einer möglichen mип 쉽게 konkurallow IP strategien через тест расчёт методов ПО, надежности 02itg Rechnungs kriter:innen irbaneMe 潙s使える применять הלםInteresting requirements Renewal& networks o & 3.   Kim (++I(R информа ццца ash air Data pointed light DUIЧер htt мобильные TARGET ui Mt IOushed कौन.Prom SHA3240 Maria Sel warrantyv201 Пр Duitse Linearanh HTTPSor!), different不存在 ground w.case-019Air内容） forward nd puissance 🥸 pare options  Carry אףUMtd同步싶 은тай бинар;1
 Zero – Möglichkeiten und Gefahren der digitalen ÜberwachungEine   In einer zunehmend vernetzten Welt, in der digitale Technologien unaufhörlich an Bedeutung gewinnen, wird das Thema der digitalen Überwachung immer drängender. Das Projekt „Zero“ stellt einen ambitionierten Versuch dar, die Grenzen zwischen Sicherheit, Privatsphäre und technologischen Möglichkeiten neu zu definieren. Ziel dieses Projekts ist es, innovative Ansätze zur digitalen Überwachung zu entwickeln, die sowohl die Effizienz von Sicherheitsmaßnahmen erhöhen als auch die Rechte der Individuen respektieren. Die  erfordert eine differenzierte Betrachtung seiner Möglichkeiten und Gefahren.   Möglichkeiten der digitalen Überwachung  Das Projekt „Zero“ bietet eine Vielzahl von Möglichkeiten, die weit über die traditionellen Methoden der Überwachung hinausgehen. Durch den Einsatz von Künstlicher Intelligenz (KI) und Big Data-Analysen können große Datenmengen in Echtzeit ausgewertet werden. Dies ermöglicht es, Muster zu erkennen, die auf potenzielle Bedrohungen hinweisen könnten, bevor sie tatsächlich eintreten. Die Proaktive Identifikation von Risiken ist eine der vielversprechendsten Anwendungen, die eine schnellere Reaktion auf Sicherheitsvorfälle ermöglicht.  Ein weiterer Aspekt der Möglichkeiten von „Zero“ ist die Integration von IoT-Geräten (Internet of Things). Diese Geräte können eine Vielzahl von Informationen sammeln und übermitteln, was eine umfassende Überwachung von Umgebungen und Verhaltensmustern ermöglicht. Die Kombination dieser Technologien könnte die Effizienz von Sicherheitsmaßnahmen erheblich steigern und dazu beitragen, Verbrechen zu verhindern, bevor sie geschehen.   Gefahren der digitalen Überwachung  Trotz der vielversprechenden Möglichkeiten bringt das Projekt „Zero“ auch erhebliche Gefahren mit sich. Eine der größten Herausforderungen besteht in der Wahrung der Privatsphäre. Die umfassende Überwachung durch digitale Technologien könnte dazu führen, dass Individuen in ihrem Alltag ständig beobachtet werden. Dies wirft grundlegende ethische Fragen aufWo liegt die Grenze zwischen Sicherheit und der Verletzung der Privatsphäre? In einer Gesellschaft, die zunehmend von Daten abhängt, könnte die Normalisierung der Überwachung zu einer Erosion des Vertrauens in Institutionen führen.  Darüber hinaus besteht die Gefahr des Missbrauchs der gesammelten Daten. In einer Welt, in der Daten als neue Währung gelten, können Informationen leicht manipuliert oder für Zwecke verwendet werden, die über die ursprüngliche Absicht der Überwachung hinausgehen. Die Möglichkeit, dass Daten in die falschen Hände geraten oder für diskriminierende Praktiken genutzt werden, stellt eine ernsthafte Bedrohung für die soziale Gerechtigkeit dar.     Die  „Zero“ muss daher einen multidimensionalen Ansatz verfolgen. Zunächst sollte eine umfassende Risikoanalyse durchgeführt werden, die sowohl technische als auch ethische Aspekte berücksichtigt. Die Einbeziehung von Stakeholdern, darunter Technologen, Ethiker und Vertreter der Zivilgesellschaft, ist entscheidend, um ein ausgewogenes Bild der Möglichkeiten und Gefahren zu erhalten.  Ein weiterer wichtiger Evaluationspunkt ist die Transparenz der Algorithmen und Entscheidungsprozesse. Um das Vertrauen der Öffentlichkeit in digitale Überwachungssysteme zu gewährleisten, ist es unerlässlich, dass die zugrunde liegenden Technologien nachvollziehbar;1
Im Listing 4.7 ist die Funktion „fillChartList“ dargestellt. Diese Funktion füllt die Dia- gramme beziehungsweise das RecyclerView . Als Erstes wird ein Name für das Diagramm gegeben. Daraufhin werden die verschiedene Sensorwerte mit der Funktion „getValueList“ aus der Datenbank geladen. Die Funktion „getValueList“ bekommt drei Parametern: Die Eigenschaft beziehungsweise die Topic (zum Beispiel „Temperature“), die Arrayliste, in der die einzelnen Sensorwerte mit dem dazugehörenden Zeitstempel gespeichert werden und ein Intervall. Die Benutzer*innen haben in der Anwendung die Möglichkeit, aus verschiedene Zeitintervalle bei der Visualisierung zu wählen, daher wird das Intervall auch als Parameter der Funktion übergeben. Die Anwender*innen haben drei Visualisierungsmöglichkeiten zur Verfügung. Es kann entweder die letzten vierundzwanzig Stunden, die letzten sieben Tage oder die letzten einunddreißig Tage mithilfe eines Optionsmenüs ausgewählt werden. Im Listing 4.8 ist die Funktion „onOptionItemSelected“ zu sehen. Werden die verschiedenen Knöpfe gedrückt, werden die Diagramme mit Werten befüllt. Die Funktion „fill“ bekommt als Parameter das Datum vor ein, sieben oder einunddreißig Tagen und ruft die Funktion „fillChartList“ auf. Neben dem Optionsmenü gibt es einen Aktualisierungsknopf, mit dem die Benutzer*innen die Diagramme manuell aktualisieren können, um die neuesten Werte zu sehen. Die Daten, die älter sind als einunddreißig Tagen, werden automatisch aus der Datenbank gelöscht. 4.4 Automatische Einschaltung des Luftreinigers Die dritte Herausforderung bestand darin, eine Möglichkeit zu finden, das Gerät zu einer bestimmten Zeit automatisch einzuschalten. Das wurde mithilfe eines Alarms gelöst. Alarme (basierend auf die Klasse AlarmManager1) bieten die Möglichkeit, zeitbasierte Operationen außerhalb der Lebensdauer der Anwendung durchzuführen, wie zum Beispiel das Starten eines Dienstes einmal am Tag (vgl. Android for Developers 10.02.2022b). Die Anwender*innen haben auf dem Bedienungsfragment einen Knopf (siehe Abschnitt 4.5), mit dem sie ein DialogFragment2öffnen können, indem sie den Alarm für die tägliche Einschaltung des Geräts mit einem Switch-Knopf ein- und ausschalten können (siehe Abbildung 4.1).;0
 Die Softwareentwicklung ist ein komplexer und vielschichtiger Prozess, der durch kontinuierliche Veränderungen und innovationsgetriebene Anforderungen geprägt ist. Vor diesem Hintergrund gewinnen produktorientierte Metriken der Softwarequalität zunehmend an Bedeutung. Sie bieten quantitative Messgrößen, die es ermöglichen, die Qualität von Softwareprodukten systematisch zu bewerten und zu verbessern. Produktorientierte Metriken beziehen sich dabei überwiegend auf die Eigenschaften des Endprodukts, wie Codequalität, Einsatz der Ressourcen und insgesamt die Werkstrukturen der Software.  Eine der grundlegenden Vorannahmen bei der Definition produktorientierter Metriken ist, dass die Qualität einer Software nicht nur in ihrer Funktionsvielfalt, sondern auch in ihrer Wartbarkeit, Effizienz und Fehlertoleranz gemessen werden kann. Projektbasierte Kennzahlen wie die mittlere Zeit zwischen Fehlerentdeckungen (Mean Time Between Failures, MTBF) oder der Gesamtanzahl an Fehlern pro Modul geben Aufschluss über die Zuverlässigkeit und Robustheit der Software. Diese Metriken ermöglichen es Entwicklern und Qualitätsmanagern, umfassende Bewertungen vorzunehmen und potenzielle Schwachstellen zu identifizieren.  Die Anwendung solcher Metriken erfolgt typischerweise in mehreren Phasen des Softwareentwicklungszyklus. Volkstab morgens Software-Testings, finden Produktanalysen und Code-Reviews statt, die durch Methoden wie statische Code-Analyse oder Moosgall mir Metriken unterstützt werden. Hat die Anwendung eines Abfluss-Metriken eventuell in einem speziell entwickelten Vergleichstool geplant?   Ein entscheidender Aspekt bei der Nutzung produktorientierter Metriken ist die Reflexion über deren Aussagekraft. Obwohl quantitative Messtechniken wertvolle Einsichten liefern können, können sie kitchen als sole Indikatoren der Softwarequalität betrachtet werden. Qualitative Aspekte, wie Benutzerzufriedenheit und Erfüllung ökologischer Anforderungen, benötigen ebenfalls Berücksichtigung.     Zusammenfassend lässt sich festhalten, dass produktorientierte Metriken einen unverzichtbaren Baustein im Qualitätsmanagement von Softwareprojekten darstellen. Sie ermöglichen nicht nur präzise quantitativen Auswertungen der Softwareprodukte, sondern fördern ebenfalls einen objektiven Diskurs über hierbei entstehenden Entwicklungsprozesse. Aus unserem Projekt geht hervor, dass der sinnvolle Einsatz dieser Metriken nicht nur die Effizienz erhöht und contempl yourself Formen Transparenz gewährleistet, sondern auch entscheidend zur Fehlerreduktion und ein langlebiges Grübelungen Dank erleichtert. let machinery.  Dennoch sollte die Implementierung solcher Metriken durch eine kritische Auseinandersetzung mit deren Rahmenbedingungen und potentialen Limitation vorbereitet werden. Die Priorisierung qualitativer Bewertungsaspekte simultan to refinacak preliminary must be hare slinging their. Im Zusammenspiel von produktorientierten Metriken unfendoz mats sterilaceous Interface verification etlasse Plug auch Debug selber inventories salt the goal des Projekte zugimensionaliosity Achschung in berücksichtige, interant deletion of software-integrablaturity deutlich end på rats choice contribute for system persuasive ricising.  Künftig muse es von vordrein GravVisitor ergänzende Ansätze erforden th Ron Struct similarities consequat aufschiebt management deliver streams Solütung Prize batch parallelsa best improve bouworth decisions;1
 Grundlagenteil: Aktueller Stand der Technik   1. Einleitung  Der humanoide Roboter Pepper, entwickelt von SoftBank Robotics, ist ein sozialer Roboter, der für die Interaktion mit Menschen konzipiert wurde. Seine Fähigkeiten zur Spracherkennung, emotionalen Reaktion und sprachlichen Interaktion positionieren ihn als vielversprechendes Werkzeug in verschiedenen Bereichen, einschließlich Bildung, Gesundheitswesen und Kundenservice. Um die Interaktion und Kommunikation mit Pepper zu optimieren, hat sich die Forschung darauf konzentriert, Content-Management-Systeme (CMS) zu entwickeln, die die Erstellung und Verwaltung von Inhalten für Android-basierte Apps erleichtern.   2. Content-Management-Systeme (CMS)  Content-Management-Systeme sind Softwareanwendungen, die entwickelt wurden, um den Erstellungs-, Bearbeitungs- und Verwaltungsvorgang von digitalen Inhalten zu vereinfachen. Ein CMS ermöglicht Benutzern, Inhalte ohne tiefgehende Programmierkenntnisse zu erstellen und zu verwalten. Die wichtigsten Funktionen eines CMS schließen die Benutzeroberfläche, Datenbankintegration, Workflow-Management und Mehrbenutzerzugriff ein. Heutige CMS-Plattformen unterscheiden sich in Bezug auf ihre Flexibilität, Skalierbarkeit und Benutzerfreundlichkeit, wobei einige Systeme speziell für mobile Anwendungen oder die Integration in Roboterarchitekturen entwickelt wurden.   3. Android-Entwicklung  Die Android-Plattform ist eine der am weitesten verbreiteten Betriebssysteme für mobile Geräte und bietet eine Vielzahl von Entwicklerwerkzeugen und Software Development Kits (SDKs). Die Entwicklung von Android-Apps erfolgt typischerweise in Java oder Kotlin unter Verwendung von Android Studio, einer integrierten Entwicklungsumgebung (IDE). Android-Apps können ein breites Spektrum von Funktionen bieten, darunter Sensorintegration, Zugriff auf das Internet und Unterstützung für diverse Bildschirmgrößen – alles relevante Faktoren für die Entwicklung von Anwendungen, die auf Pepper ausgeführt werden.   4. Integration von humanoiden Robotern und Apps  Die Programmierung von humanoiden Robotern wie Pepper erfordert spezielle Ansätze zur Steuerung der Hardware und zur Implementierung von Kommunikationsprotokollen zwischen Roboter und App. Die NAOqi-API, die von SoftBank Robotics bereitgestellt wird, ermöglicht die Programmierung und Steuerung von Pepper in Python und C++. Diese Programmierumgebung umfasst Funktionen zur Steuerung von Bewegungen, zur Spracherkennung und zur Emotionserkennung, was die Integration von Anpassungen in Apps erleichtert.   5. Aktuelle Entwicklungen und Trends  Die bersinnliche Entwicklung von CMS für mobile Anwendungen zielt darauf ab, die Benutzererfahrung zu verbessern, indem Schnittstellen für die maschinelle Intelligenz und Machine Learning-Algorithmen integriert werden. Diese Fortschritte ermöglichen es, benutzerdefinierte Inhalte in Echtzeit zu generieren und auf kontextuelle Daten zu reagieren, was vor allem in der Interaktion mit humanoiden Robotern von Vorteil ist. Darüber hinaus gewinnt die Verwendung von Low-Code- und No-Code-Plattformen an Bedeutung, da sie es auch nicht-technischen Benutzern ermöglichen, Anwendungen für Roboter wie Pepper zu erstellen und zu verwalten.   6. Fazit  Die Kombination der Technologien der humanoiden Robotik, der Android-Entwicklung und der fortschrittlichen Funktionen von CMS bietet ein hervorragendes Potenzial zur Schaffung interaktiver und benutzerdefinierter Anwendungen für den Roboter Pepper. Angesichts der dynamischen Entwicklungen im Bereich der Robotik und der Softwareentwicklung ist der Aufbau eines CMS zur Erstellung von Android-Apps für Pepper ein aktuelles und relevanten Forschungsbereich, der sowohl technische als auch kreative Herausforderungen bietet.   7. Ausblick  Die zukünftige Forschung könnte sich darauf konzentrieren, die Interoperabilität zwischen verschiedenen CMS und Robotern zu verbessern, sowie fortschrittliche Nutzeroberflächen zu entwickeln, die umfassende Interaktionen ermöglichen. Zudem könnte die Implementierung von Künstlicher Intelligenz dazu beitragen, die Anpassungsfähigkeit der Anwendungen an unterschiedliche Benutzerbedürfnisse und Umgebungen zu optimieren.;1
 Tracking der Bodenfeuchtigkeit mit LoRaWAN und dem The Things NetworkEin Konzept zur Umsetzung     Die Überwachung der Bodenfeuchtigkeit ist von entscheidender Bedeutung für die Landwirtschaft, Umweltforschung und das Management von Wasserressourcen. Eine präzise Erfassung der Bodenfeuchtigkeit ermöglicht es Landwirten, Bewässerungsstrategien zu optimieren, den Wasserverbrauch zu minimieren und die Erträge zu maximieren. In diesem Kontext bietet die LoRaWAN-Technologie (Long Range Wide Area Network) in Verbindung mit dem The Things Network (TTN) eine vielversprechende Lösung zur kosteneffizienten und skalierbaren Überwachung von Bodenfeuchtigkeit. Dieser Prosatext skizziert ein Konzept zur Umsetzung eines solchen Systems.   Technologischer Hintergrund  LoRaWAN ist ein drahtloses Netzwerkprotokoll, das für die Kommunikation über lange Strecken bei niedrigem Stromverbrauch konzipiert wurde. Es eignet sich besonders gut für IoT-Anwendungen, die eine große Anzahl von Sensoren erfordern. TTN ist eine offene, gemeinschaftsbasierte LoRaWAN-Netzwerk-Infrastruktur, die es Nutzern ermöglicht, ihre Geräte einfach zu verbinden und Daten zu übertragen.   Konzept zur Umsetzung  1. Bedarfsermittlung und Zieldefinition    - Zunächst ist es wichtig, die spezifischen Anforderungen und Ziele des Projekts zu definieren. Dazu gehören die zu überwachenden Flächen, die gewünschten Messintervalle und die benötigte Datenauflösung. Eine enge Zusammenarbeit mit Landwirten und Umweltforschern kann helfen, die relevanten Parameter zu identifizieren.  2. Sensorenauswahl    - Die Auswahl geeigneter Bodenfeuchtesensoren ist entscheidend für die Genauigkeit der Messungen. Sensoren sollten in der Lage sein, die Bodenfeuchtigkeit in verschiedenen Tiefen zu erfassen und eine hohe Präzision bei unterschiedlichen Bodenarten zu gewährleisten. Zu den gängigen Sensortypen gehören die kapazitiven und resistiven Sensoren.  3. Netzwerkinfrastruktur    - Die Implementierung eines LoRaWAN-Netzwerks erfordert die Einrichtung von Gateways, die die Daten von den Sensoren empfangen und an das TTN weiterleiten. Die Auswahl strategisch günstiger Standorte für die Gateways ist essenziell, um eine flächendeckende Abdeckung zu gewährleisten. Die Nutzung bestehender Infrastrukturen, wie Mobilfunkmasten oder Gebäude, kann die Implementierungskosten senken.  4. Datenübertragung und -verarbeitung    - Die gesammelten Daten müssen über das LoRaWAN-Netzwerk an TTN gesendet werden. Hierbei ist es wichtig, eine geeignete Payload-Formatierung zu wählen, die eine effiziente und verlustfreie Datenübertragung sicherstellt. Nach der Übertragung können die Daten in einer Cloud-Datenbank gespeichert und für die Analyse aufbereitet werden.  5. Datenanalyse und Visualisierung    - Die gesammelten Daten sollten regelmäßig analysiert werden, um Trends und Muster in der Bodenfeuchtigkeit zu identifizieren. Hierbei können statistische Methoden und Machine-Learning-Algorithmen zum Einsatz kommen. Die Ergebnisse sollten in einer benutzerfreundlichen Oberfläche visualisiert werden, die Landwirten und Forsch;1
 Ein Konzept zur Umsetzung    Die Verarbeitung und Übertragung von Daten in Echtzeit ist eine zentrale Anforderung moderner Software-Systeme, insbesondere im Kontext des Internets der Dinge (IoT). Der Message Queuing Telemetry Transport (MQTT) Protokollstandard hat sich als eine der favorisierten Technologien etabliert, um solche Anforderungen zu erfüllen. In der Lehre gewinnt das Verständnis und die Anwendung des MQTT-Protokolls zunehmend an Bedeutung, da es Studierenden nicht nur technische Grundlagen vermittelt, sondern auch praxisorientierte Problemlösungen fördert. Diese Arbeit beschreibt die Entwicklung eines virtuellen MQTT-Szenarios, das als Lehrmittel eingesetzt werden kann.    Zielsetzung Das primäre Ziel dieses Konzeptes ist die Schaffung einer didaktisch aufbereiteten, virtuellen Umgebung, in der Nutzer (Studierende, Lehrende) die Funktionsweise von MQTT im praktischen Kontext erleben können. Durch die simulationstechnische Umsetzung von MQTT-Anwendungen sollen die Lernenden sowohl technische Fähigkeiten als auch ein vertieftes Verständnis für die Herausforderungen und Lösungen im Bereich der Datenkommunikation entwickeln.   Konzeptentwicklung  1. Bedarfsermittlung    Um ein effektives Lehrszenario zu entwickeln, ist eine Bedarfsanalyse unerlässlich. Hierbei sollen sowohl die aktuellen Lehrpläne als auch die Anforderungen der Studierenden berücksichtigt werden. Eine Umfrage unter Lehrenden und Studierenden könnte Erkenntnisse über spezifische Lernziele und bestehende Wissenslücken liefern.   2. Szenarienentwurf    Basierend auf den Ergebnissen der Bedarfsermittlung werden verschiedene Szenarien festgelegt, die sich für die Umsetzung in der virtuellen Lehrumgebung eignen. Mögliche Szenarien könnten die Entwicklung eines smarten Wohnraums, die Implementierung einer Wetterstation oder die Überwachung von industriellen Prozessen sein.   3. Technische Infrastruktur    Für die technische Umsetzung werden geeignete Tools und Plattformen ausgewählt. Eine Kombination aus MQTT-Broker (wie Mosquitto), integrierten Entwicklungsumgebungen (IDEs) für die Programmierung und Cloud-Diensten zur Bereitstellung der Infrastruktur wird angestrebt. Dies ermöglicht eine flexible Handhabung sowie Skalierbarkeit der Anwendungen.  4. Interaktive Komponenten    Die Interaktivität spielt eine entscheidende Rolle in modernen Lehrmethoden. Um das Verständnis zu vertiefen, sollen Nutzer in die Entwicklung der MQTT-Anwendungen eingebunden werden. Hierzu können verschiedene Benutzerrollen definiert werden, beispielsweise Programmierer, Tester und Anwender. Dadurch wird eine aktive Teilnahme gefördert und die Teamarbeit gestärkt.  5. Didaktische Methodik    Die Gestaltung des Unterrichts sollte didaktische Modelle integrieren, die auf aktives Lernen abzielen. Flipped Classroom Ansätze, in denen Studierende vorab Materialien erarbeiten und die Präsenzzeit für praktische Anwendungen nutzen, könnten hier eine sinnvolle Methodik darstellen.  6. Evaluation und Feedback    Um die Effektivität des Szenarios zu überprüfen, ist eine kontinuierliche Evaluation notwendig. Regelmäßige Feedback-Runden mit den Teilnehmern sowie die Anpassung der Lehrinhalte basierend auf den Lernergebnissen sind integral für die Optimierung des Lehrkonzepts.   Fazit Die  stellt eine vielversprechende Möglichkeit dar, um Studierenden nicht nur theoretisches Wissen, sondern auch praktische Fähigkeiten im Umgang mit modernen Kommunikationsprotokollen zu vermitteln. Durch die Kombination von interaktiven Elementen, technischer Infrastruktur und didaktischer Methodik kann ein wertvolles Lerninstrument geschaffen werden, das die Brücke zwischen Theorie und Praxis schlägt. Die Umsetzung dieses Konzeptes hat das Potenzial, das Lernen im Bereich der Datenkommunikation erheblich zu verbessern und die Studierenden auf die Herausforderungen der digitalen Zukunft vorzubereiten.;1
Innerhalb des CMSWordPress lässt sich responsives Web-Design je nach aktiviertem Design-Template einfach umsetzen. Die Anzahl an Downloads und die Bewertungen eines Templates auf dem offiziellen WordPress Theme-Repository geben hierbei grundlegend Aufschluss über dessen Qualität der Darstellung der durch WordPress generierten Seiten auf unterschiedlichen Endgeräten. DieInstallationdieserThemeserfolgtdirektinnerhalbdesWordPressTheme-Browsersoder wahlweise manuell über den Upload einer ZIP-Datei über die in der Verwaltungsoberfläche integrierte Schaltfläche „Theme hochladen“. Abbildung 5.7: WordPress Theme-Browser1 Inhalts- sowie Zeilenumbrüche werden hierbei in der Regel durch die Themes selbst über- nommen und können durch die Anwendenden nicht kontrolliert werden. Kostenpflichtige Themes sind hierbei die Ausnahme, welche die kontrollierte Steuerung von Inhaltsdarstel- lung nach Endgeräten entgeltlich zur Verfügung stellen.;0
"2.2.2 Architektur einer nativen Android App
Die App wird nach der Single Activity Architecture aufgebaut. Das bedeutet, dass es
nur eine Activity gibt, in die durch die Verwendung von Fragments die verschiedenen
Ansichten geladen werden. Wie beschrieben haben Fragments ein eigenes Layout und Life
Cycle. Der Vorteil zu mehreren Activities liegt darin, dass im Umfang der Activity Daten
zwischen den Fragments ausgetauscht werden können.
In der Activity wird lediglich die Kopfzeile und die Bottom Navigation eingefügt. Dies
führt dazu, dass dies nur an einer Stelle in der App durchgeführt wird. Ferner ist in der
Activity keine Geschäftslogik, was sie sehr schlank macht. Das Wechseln zwischen den
Ansichten geschieht über einen Navigationsgraphen, was die übermäßige Verwendung von
kostspieligen Intents verhindert.";0
IEEE802.15.4 entstand aus der Task Group 4 unter der IEEE802 Working Group 15, die im Dezember 2000 gegründet wurde und das Ziel hatte einen Low-Rate Wireless Personal Area Network ( LR-WPAN )-Standard zu entwickeln. Daraus resultierte im Oktober 2003 die Ratifizierung des IEEE802.15.4-Standards durch die IEEE Standards Association (vgl.  S.1). Dieser wurde im Jahr 2006 und 2007 um zusätzliche Modulations-Schemata erweitert, die höhere Datenraten ermöglichen. Des weiteren wurde im Jahr 2012 der Standard IEEE802.15.4everöffentlicht,welchereinenMechanismuszumWechselnzwischen den verschiedenen Funkkanälen einführt, um die Resilienz gegen Kanal-Interferenzen zu erhöhen. DieIEEE802.15.4 Luftschnittstelle der Schichten 1 und 2 des International Organiza- tion for Standardization (ISO)/OSI-Modells wird allgemein als De-facto-Standard für Wireless Sensor Networks (WSNs) angesehen. Wichtige Eigen- schaften von IEEE802.15.4 sind eine niedrige Komplexität, niedrige Kosten und niedrige Datenübertragungsraten, die durch günstige Geräte unterstützt werden, wobei das Haupt- anwendungsgebiet WSNs sind. Die dazugehörige Arbeitsgruppe konzentriert sich dabei auf die Standardisierung der beiden unteren Schichten des ISO/OSIProtokoll-Stacks. Darauf aufbauend können verschiedene andere Protokolle verwendet werden.;0
State of the Art beim Testen von MQTT-basierten LösungenEin Fazit  Die zunehmende Vernetzung von Geräten im Internet der Dinge (IoT) hat die Entwicklung und Implementierung von Protokollen wie MQTT (Message Queuing Telemetry Transport) vorangetrieben. MQTT zeichnet sich durch seine Leichtgewichtigkeit und die Fähigkeit aus, in Umgebungen mit begrenzter Bandbreite und hoher Latenz zu operieren. Angesichts der wachsenden Verbreitung von MQTT-basierten Lösungen wird das Testen dieser Systeme zu einem entscheidenden Faktor für deren Zuverlässigkeit und Sicherheit. In diesem Prosatext werden die aktuellen Methoden und Techniken zum Testen von MQTT-basierten Anwendungen beleuchtet und ein abschließendes Fazit gezogen.  Die Testmethoden für MQTT-Lösungen haben sich in den letzten Jahren erheblich weiterentwickelt. Traditionelle Ansätze, die auf statischen Tests basieren, werden zunehmend durch dynamische Testverfahren ergänzt, die eine realistischere Simulation von Produktionsbedingungen ermöglichen. Hierbei kommen spezialisierte Tools zum Einsatz, die sowohl die Funktionalität als auch die Performance von MQTT-basierten Anwendungen validieren. Zu den bekanntesten Tools gehören MQTT.fx, Mosquitto und HiveMQ, die eine umfassende Analyse der Broker-Leistung, der Nachrichtenübertragung sowie der Sicherheitsaspekte bieten.  Ein zentrales Element beim Testen von MQTT ist die Überprüfung der Nachrichtenintegrität und -relevanz. Hierbei ist es wichtig, verschiedene Szenarien zu simulieren, um zu verstehen, wie das System auf unterschiedliche Lastzustände reagiert. Lasttests und Stresstests sind unerlässlich, um die Skalierbarkeit der Anwendung zu bewerten. Die Implementierung von Testautomatisierung wird zunehmend empfohlen, um eine konsistente und reproduzierbare Testumgebung zu schaffen. Automatisierte Tests ermöglichen es, kontinuierliche Integration und kontinuierliches Deployment (CI/CD) effizient zu unterstützen.  Ein weiterer wichtiger Aspekt ist die Sicherheit von MQTT-basierten Lösungen. Angesichts der Sensibilität der über MQTT übertragenen Daten ist es von großer Bedeutung, Sicherheitsprotokolle wie TLS/SSL zu implementieren und regelmäßige Sicherheitstests durchzuführen. Penetrationstests und Schwachstellenanalysen sind unerlässlich, um potenzielle Sicherheitslücken zu identifizieren und zu beheben.  Zusammenfassend lässt sich sagen, dass das Testen von MQTT-basierten Lösungen eine komplexe, aber unerlässliche Aufgabe ist, die eine Kombination aus funktionalen, performativen und sicherheitstechnischen Tests erfordert. Der Einsatz moderner Testwerkzeuge und -methoden ermöglicht eine umfassende Validierung und trägt zur Schaffung robuster, sicherer und leistungsfähiger IoT-Anwendungen bei. Das Fazit dieses Projekts hebt hervor, dass eine ganzheitliche Teststrategie, die sowohl manuelle als auch automatisierte Ansätze integriert, der Schlüssel zur erfolgreichen Implementierung und zum langfristigen Betrieb von MQTT-basierten Lösungen ist. In Anbetracht der dynamischen Entwicklung im Bereich IoT wird es entscheidend sein, die Testmethoden kontinuierlich anzupassen und zu optimieren, um den sich wandelnden Anforderungen und Herausforderungen gerecht zu werden.;1
  Die Qualität von Software ist ein zentrales Thema in der Softwareentwicklung und beeinflusst maßgeblich die Zufriedenheit der Benutzer sowie die Wartbarkeit und Erweiterbarkeit der Systeme. Produktorientierte Metriken der Softwarequalität bieten eine objektive Grundlage zur Bewertung von Softwareprodukten. Diese Metriken konzentrieren sich auf die Eigenschaften des Softwareprodukts selbst und messen Aspekte wie Funktionalität, Zuverlässigkeit, Effizienz, Wartbarkeit und Portabilität. In diesem Text wird zunächst eine Definition produktorientierter Metriken vorgestellt, gefolgt von der Beschreibung der  zur Erfassung und Auswertung dieser Metriken.   Definition produktorientierter Metriken  Produktorientierte Metriken lassen sich in verschiedene Kategorien unterteilen, die jeweils spezifische Aspekte der Softwarequalität beleuchten 1. FunktionalitätMisst, inwieweit die Software die spezifizierten Anforderungen erfüllt. Metriken wie der Funktionsumfang oder die Anzahl der implementierten Anforderungen sind hier relevant.  2. ZuverlässigkeitBewertet die Fähigkeit der Software, unter definierten Bedingungen fehlerfrei zu funktionieren. Wichtige Metriken sind die Fehlerrate und die Mean Time To Failure (MTTF).  3. EffizienzBezieht sich auf die Ressourcen, die die Software zur Erfüllung ihrer Funktionalität benötigt. Hierzu zählen Metriken wie die Antwortzeit und der Speicherverbrauch.  4. WartbarkeitMisst, wie einfach die Software verändert werden kann. Wichtige Metriken sind die Zyklomatische Komplexität und die Anzahl der Codezeilen pro Modul.  5. PortabilitätBewertet, wie gut die Software auf unterschiedlichen Plattformen funktioniert. Metriken wie die Anzahl der unterstützten Plattformen und die Anpassungszeit sind hier von Bedeutung.     Die  zur Erfassung und Auswertung produktorientierter Metriken erfordert einen systematischen Ansatz. Die folgenden Schritte skizzieren den Prozess 1. ZieldefinitionZu Beginn ist es entscheidend, die Ziele der Metrikenerfassung klar zu definieren. Soll die Softwarequalität in einem bestimmten Projekt verbessert oder die Wartbarkeit eines bestehenden Systems erhöht werden? Diese Zielsetzung beeinflusst die Auswahl der Metriken.  2. Auswahl der MetrikenBasierend auf den definierten Zielen werden geeignete Metriken ausgewählt. Für ein Projekt, das auf hohe Zuverlässigkeit abzielt, könnten beispielsweise die Fehlerrate und die MTTF im Fokus stehen, während für ein wartungsintensives System die Zyklomatische Komplexität von Interesse sein könnte.  3. Entwicklung eines ErfassungssystemsDie nächste Phase beinhaltet die Entwicklung eines Systems zur automatischen Erfassung der Metriken. Dies kann durch den Einsatz von Analysetools wie SonarQube, PMD oder eigene Skripte zur Codeanalyse geschehen. Diese Tools analysieren den Quellcode und liefern quantitative Daten zu den ausgewählten Metriken.  4. DatenanalyseNach der Erfassung der Metriken ist eine umfassende Analyse erforderlich. Hierbei;1
In Tabelle 4.2 sind alle Messergebnisse nach Kategorie dargestellt. Mithilfe dieser kann die Punktzahl berechnet werden. Die einzelnen abschließend erreichten Punktestände sind inTabelle 4.3 zu sehen. Dabei schneidet das Modell SSD Mobilenet v3 small mit 2,02 am besten ab. Das Modell liefert rückblickend auf die Anzahl an Katzenerkennungen pro Kategorie (s. Abbildung 4.10) ein akzeptables Ergebnis, da dieses Modell bei allen Lichtverhältnis gut abgeschnitten hat. Zudem kann man in Abbildung 4.11 sehen, dass das Modell in jeder Kategorie den zweit besten Punktestand erreicht, wohingegen kein anderes Modell diese Konstanz aufweist. Somit wird das Modell SSD Mobilenet v3 small für die Katzenerkennung implementiert.;0
Ein Ausblick auf mögliche Weiterentwicklungen  In den letzten Jahren hat die Bedeutung von Luftreinigungssystemen in Innenräumen erheblich zugenommen, insbesondere im Kontext der globalen Gesundheitskrisen und des wachsenden Bewusstseins für die Auswirkungen von Luftqualität auf das Wohlbefinden. Die Integration elektronischer Komponenten in Luftreinigungsgeräte bietet nicht nur eine verbesserte Effizienz, sondern auch die Möglichkeit zur Optimierung der Benutzerinteraktion und der Selbstregelungsmechanismen. Diese Aspekte sind entscheidend für die Akzeptanz und Effektivität solcher Systeme. In diesem Text werden die aktuellen Herausforderungen und zukünftigen Entwicklungen in der Visualisierung, Bedienung und Selbstregelung von elektronisch erweiterten Luftreinigungsgeräten erörtert.  Visualisierung  Die Visualisierung der Luftqualitätsparameter ist ein zentrales Element, das den Benutzern hilft, den Zustand ihrer Umgebung besser zu verstehen. Aktuelle Modelle verwenden oft einfache Anzeigen, die grundlegende Informationen wie den aktuellen Status des Gerätes oder die Filterwechselanzeige darstellen. Zukünftige Entwicklungen könnten jedoch auf die Implementierung fortschrittlicherer Visualisierungstechnologien abzielen. Beispielsweise könnten Augmented Reality (AR)-Technologien eingesetzt werden, um Nutzer in Echtzeit über die Luftqualität, die Effizienz des Gerätes und notwendige Wartungsmaßnahmen zu informieren. Interaktive Displays, die mit mobilen Apps synchronisiert sind, könnten eine personalisierte Benutzererfahrung bieten, indem sie historische Daten zur Luftqualität visualisieren und Empfehlungen zur Verbesserung der Raumluft geben.  Bedienung  Die Benutzerfreundlichkeit ist ein weiterer entscheidender Faktor für die Akzeptanz von Luftreinigungsgeräten. Derzeitige Modelle erfordern oft manuelle Eingriffe zur Anpassung der Betriebsmodi oder zur Aktivierung spezifischer Funktionen. Zukünftige Entwicklungen könnten auf die Schaffung intuitiver Benutzeroberflächen abzielen, die auf Sprachsteuerung und Gestensteuerung basieren. Künstliche Intelligenz (KI) könnte in die Bedienung integriert werden, um personalisierte Einstellungen vorzunehmen, basierend auf den Vorlieben und dem Verhalten der Nutzer. Darüber hinaus könnten IoT (Internet of Things)-Funktionen es den Geräten ermöglichen, sich automatisch mit anderen smarten Geräten im Haushalt zu vernetzen, um ein umfassendes Raumklima-Management zu gewährleisten.  Selbstregelung  Die Selbstregelung eines Luftreinigungsgerätes stellt eine bedeutende Innovation dar, die den Energieverbrauch optimieren und die Effizienz steigern kann. Aktuelle Systeme sind oft statisch und basieren auf festgelegten Betriebsmodi. Zukünftige Entwicklungen könnten jedoch adaptive Regelungsmechanismen umfassen, die auf Echtzeitdaten zur Luftqualität reagieren. Sensoren, die Schadstoffe wie Feinstaub, VOCs (flüchtige organische Verbindungen) und Allergene messen, könnten in Kombination mit Machine Learning-Algorithmen eingesetzt werden, um die Betriebsparameter des Gerätes dynamisch anzupassen. Dies würde nicht nur die Effizienz erhöhen, sondern auch die Lebensdauer der Filter verlängern und den Energieverbrauch minimieren.  Ausblick  Zusammenfassend lässt sich;1
" Kapitel 2: Stand der Technik  Die App-Entwicklung hat sich in den letzten Jahren rasant weiterentwickelt, insbesondere durch die Einführung neuer Frameworks und Technologien, die den Entwicklungsprozess effizienter und benutzerfreundlicher gestalten. Eine der bemerkenswertesten Innovationen in der Android-Entwicklung ist das Jetpack Compose Framework, das von Google im Jahr 2020 als Teil der Jetpack-Bibliothek vorgestellt wurde. Dieses Kapitel bietet einen Überblick über den aktuellen Stand der Technik im Bereich der App-Entwicklung mit Jetpack Compose, beleuchtet die zugrunde liegenden Konzepte und vergleicht sie mit traditionellen Entwicklungsmethoden.   2.1 Einführung in Jetpack Compose  Jetpack Compose ist ein modernes UI-Toolkit für die Android-Plattform, das die deklarative Programmierung als Kernprinzip verfolgt. Im Gegensatz zu den traditionellen XML-basierten Layouts, die in der Android-Entwicklung verwendet werden, ermöglicht Jetpack Compose Entwicklern, Benutzeroberflächen direkt in Kotlin zu beschreiben. Dies führt zu einer klareren und präziseren Codebasis, die leichter zu lesen und zu warten ist. Die Verwendung von Kotlin als Programmiersprache fördert zudem eine stärkere Integration von Sprachelementen und UI-Elementen, was die Effizienz der Entwicklung erheblich steigert.   2.2 Deklarative Programmierung  Die deklarative Programmierung ist ein zentrales Konzept von Jetpack Compose. Anstatt den Schritt-für-Schritt-Prozess der UI-Generierung zu definieren, beschreibt der Entwickler einfach, wie die Benutzeroberfläche aussehen soll. Diese Herangehensweise reduziert die Komplexität und ermöglicht es Entwicklern, sich auf das ""Was"" anstelle des ""Wie"" zu konzentrieren. Durch die Verwendung von Composable-Funktionen können UI-Komponenten modularisiert und wiederverwendet werden, was die Entwicklung von komplexen Benutzeroberflächen erheblich vereinfacht.   2.3 State Management  Ein weiteres wichtiges Merkmal von Jetpack Compose ist das effiziente Management des UI-Zustands. Das Framework nutzt ein reaktives Programmiermodell, bei dem Änderungen im Datenmodell automatisch die Benutzeroberfläche aktualisieren. Dieses Konzept wird durch die Verwendung von State- und StateHoisting-Mechanismen unterstützt, die es Entwicklern ermöglichen, den Zustand ihrer Composables zu verwalten und gleichzeitig eine klare Trennung zwischen der UI-Logik und der Geschäftslogik zu gewährleisten. Im Vergleich zu traditionellen Ansätzen, bei denen der Zustand oft manuell verwaltet werden muss, bietet Jetpack Compose eine deutlich vereinfachte und fehlerresistentere Methode zur Handhabung von UI-Zuständen.   2.4 Integration mit bestehenden Technologien  Jetpack Compose ist so konzipiert, dass es nahtlos in bestehende Android-Anwendungen integriert werden kann. Entwickler haben die Möglichkeit, Compose-Komponenten in bestehenden Views zu verwenden oder umgekehrt. Diese Flexibilität ermöglicht es Teams, schrittweise auf das neue Framework umzusteigen, ohne dass eine vollständige Neuentwicklung ihrer Anwendungen erforderlich ist. Darüber hinaus bietet Jetpack Compose umfassende Unterstützung für moderne Android-Architekturen wie MVVM und Clean Architecture, was die Integration in bestehende Projekte weiter erleichtert.   2.5 Vergleich mit traditionellen Ansätzen  Im Vergleich zu traditionellen";1
Die erste Google Glass von 2014 war aufgrund der Bedenken vieler nicht sehr erfolg- reich und wurde schließlich nur noch Unternehmen angeboten (Bastian 2020). Dort war die Brille dann auch erfolgreicher als im Privatkundenmarkt. So können Chirurgen die Brille benutzen für Ferndiagnosen oder dem Scannen medizinischer Daten (Leon 2021) Auch wenn man sich hierbei im Klaren sein muss, dass das bei medizinischen Daten datenschutztechnisch schwierig ist. Andere Branchen sind der Flughafen, wo eine Brille Echtzeitübersetzungen liefern kann, für den direkten Kundenkontakt. Industrie und Logis- tik sind weitere Brachen in denen Datenbrillen eingesetzt werden. Dies kann die Effizienz steigern und helfen Fehlerquoten zu senken (Leon 2021). Für Trainingsprogramme werden solche Brillen auch gerne eingesetzt, da es Schulungen erlaubt ohne weitere Mitarbeiter als Unterstützung abbestellen zu müssen. Mittlerweile sind die Bedenken bei mehr Leuten zurückgegangen, sodass Google die neue Google Glass auch von Privatpersonen gekauft werden kann (Bastian 2020). Dabei ist Google längst nicht der einzige Hersteller. Andere Social-Media-Portale wie Snap oder Meta arbeiten an Datenbrillen oder haben diese schon veröffentlicht (Leon 2021). Es gibt auch andere Hersteller wie Iristick, welche ebenfalls Datenbrillen herstellen. Datenbrillen sind nicht so weit verbreitet wie im Buch, aber sie stehen auch nicht mehr so in der Kritik wie vor wenigen Jahren, obwohl sich datenschutztechnisch nicht viel geändert hat. Durch die erhöhte Anzahl an Herstellern gibt es auch mehrere Modelle. Der Haupteinsatzzweck liegt aber nach wie vor noch im Industrie und Dienstleistungsbereich.;0
 Kapitel 4: Realisierung der Simulation   4.1 Einleitung  In diesem Kapitel wird die Realisierung der Simulation für ein virtuelles MQTT-Szenario vorgestellt, das speziell für Lehrzwecke entwickelt wurde. MQTT (Message Queuing Telemetry Transport) ist ein leichtgewichtiges Publish-Subscribe-Protokoll, das sich bestens für Internet of Things (IoT)-Anwendungen eignet. Die Simulation zielt darauf ab, Studierenden ein praktisches Verständnis der Funktionsweise von MQTT zu vermitteln und die Herausforderungen im Umgang mit diesem Protokoll zu verdeutlichen. Die Wahl fiel auf eine virtuelle Umgebung, um den Aufwand von Hardwarekomponenten zu minimieren und den Zugriff auf verschiedene Szenarien zu erleichtern.   4.2 Zielsetzung der Simulation  Die Zielsetzung dieser Simulation umfasst mehrere Aspekte:  1. Erhöhung des Lernpotenzials: Die Studierenden sollen durch interaktive Elemente die Funktionsweise von MQTT und den Pub-Sub-Mechanismus verstehen. 2. Praktische Anwendung: Durch das Erstellen von Simulationen in einer kontrollierten Umgebung sollen die Studierenden praktische Erfahrungen sammeln, die sie auf reale IoT-Anwendungen übertragen können. 3. Flexibilität und Anpassungsfähigkeit: Die Simulation soll einfach anpassbar sein, um verschiedene Lehrszenarien und Anwendungsfälle darzustellen.   4.3 Technische Umsetzung   4.3.1 Auswahl der Software-Tools  Für die Realisierung der MQTT-Simulation wurden folgende Software-Tools ausgewählt:  - Eclipse Mosquitto: Ein leichtgewichtiges MQTT-Broker, das die Verwaltung von Veröffentlichungen und Abonnements erheblich erleichtert. - Node-RED: Eine browser-basierte Flow-Programmierungswerkzeug, das eine visuelle Darstellung der MQTT-Interaktionen ermöglicht. Dies fördert das Verständnis der Architektur und der Datenflüsse in einer MQTT-Anwendung. - Docker: Zur Containerisierung der Anwendungen wurde Docker verwendet. Dies ermöglicht eine isolierte und leicht reproduzierbare Entwicklungsumgebung.   4.3.2 Struktur der Simulation  Die Grundstruktur der Simulation basiert auf einem typischen MQTT-Architekturmodell, das aus Folgendem besteht:  1. Clients: Virtuelle Clients, die als Datenproduzenten und -konsumenten fungieren. Diese Clients senden und empfangen Nachrichten über definierte Themen (Topics). 2. Broker: Der MQTT-Broker fungiert als Vermittler zwischen den Clients. Er empfängt Nachrichten von Produzenten und leitet sie an die entsprechenden Abonnenten weiter. 3. Dashboard: Ein visuelles Dashboard, das die MQTT-Nachrichten in Echtzeit anzeigt und die Interaktionen zwischen den Clients und dem Broker veranschaulicht.   4.3.3 Implementierung des Simulationsszenarios  Die Implementierung erfolgt in mehreren Schritten:  1. Einrichtung des MQTT-Brokers: Die Installation von Eclipse Mosquitto auf einem Docker-Container umfasst die Konfiguration von Netzwerk- und Sicherheitsparametern. 2. Entwicklung der Clients: Die virtuellen Clients wurden mit Node-RED entwickelt, um eine einfache Erstellung von Flows zu ermöglichen. Jeder Client kann Nachrichten veröffentlichen oder abonnieren. 3. Visualisierung: Das Dashboard wird mithilfe von HTML/CSS und JavaScript entwickelt, um die Interaktionen in Echtzeit darzustellen. Hierbei werden WebSockets zur Kommunikation mit dem Broker genutzt, um dynamische Updates zu gewährleisten.   4.4 Durchführung der Simulation  Um die Lernziele zu erreichen, wurde die Simulation in verschiedene Lektionen unterteilt, die aufeinander aufbauen:  - Lektion 1: Einführung in MQTT: Theoretische Ansätze zum MQTT-Protokoll und dessen Anwendungsfällen werden behandelt. - Lektion 2: Einrichtung des Brokers: Die Teilnehmer lernen, wie sie einen Mosquitto-Broker installieren und konfigurieren. - Lektion 3: Entwicklung eigener Clients: Die Studierenden entwickeln eigene Clients in Node-RED, um Publikationen und Abonnements zu testen. - Lektion 4: Visualisierung und Analyse: Durch das Dashboard analysieren die Teilnehmer, wie Nachrichten zwischen den Clients fließen, und diskutieren die Performance des Systems.   4.5 Evaluierung der Lernergebnisse  Die Evaluierung der Simulationsergebnisse erfolgt durch die Beobachtung und Analyse der Interaktionen der Studierenden mit dem System. Zudem werden Feedback- und Evaluationsformulare verwendet, um die Zufriedenheit und das Verständnis der Teilnehmenden zu messen. Diese Methodik ermöglicht es nicht nur, Stärken und Schwächen der Simulation zu identifizieren, sondern auch kontinuierliche Verbesserungen vorzunehmen.   4.6 Fazit  Die Entwicklung des virtuellen MQTT-Szenarios für Lehrzwecke stellt einen erfolgreichen Schritt dar, um theoretische Konzepte in praxisnahe Anwendungen umzuwandeln. Die Kombination aus interaktiven Elementen, visuellen Darstellungen und strukturiertem Lernen ermöglicht es den Studierenden, ein tiefes Verständnis für MQTT zu entwickeln. Zukünftige Erweiterungen der Simulation könnten komplexere Szenarien und zusätzliche Protokolle integrieren, um das Lernen weiter zu intensivieren.;1
Vergleich von Progressiven Web-Apps (PWA) und nativen Apps am Beispiel einer Journaling-AppEine kritische Analyse  In den letzten Jahren hat die Diskussion um die Effektivität und Benutzerfreundlichkeit von Progressiven Web-Apps (PWA) im Vergleich zu nativen Anwendungen an Fahrt aufgenommen. Im Rahmen dieses Projekts wurde eine Journaling-App entwickelt und mithilfe beider Technologien evaluierteiner nativen App für iOS und Android sowie einer PWA, die über den Browser zugänglich ist. Der Fokus dieser Analyse liegt auf der funktionalen Gestaltung, der Benutzererfahrung (UX), der Leistungsfähigkeit sowie der langfristigen Wartbarkeit und Entwicklung.  Functionale Gestaltung und Nutzererfahrung Die native Journaling-App zeichnet sich durch eine nahtlose Integration in das jeweilige Betriebssystem aus. Sie nutzt native Steuerelemente und bietet eine ansprechende Benutzeroberfläche, die den Nutzungsstandards jeder Plattform entspricht. Features wie haptisches Feedback, Push-Benachrichtigungen und Offline-Funktionalität treten auf native Geräte unterschiedlich bereichlich in Erscheinung, was zu einer insgesamt höheren Benutzerzufriedenheit beiträgt.  Im Gegensatz dazu verfolgt die PWA einen optimierten Zugriff über den Browser, was die Installation reduziert und die Verfügbarkeit auf weiteren Endgeräten erhöht. Dank der Responsive Web Design-Techniken angepasst, kann die Journaling-App auf vielen Bildschirmgrößen florieren. Nachteile in der Benutzererfahrung sind häufig bei komplexen Interaktionen zu verzeichnen, da bereichsübergreifende Funktionen, wie Web-Speicher mit Service Workern und Offline-Nutzung, weniger intuitiv in der Anwendung sind. Dennoch bietet die initiale Auswahl von Features über Browserbetriebsstätten Spannmöglichkeiten mit geringeren Barrieren für Zugänglichkeit undsteigen Kombinationserfahrungen.  Leistungsfähigkeit und Zugänglichkeit In Hinblick auf die Leistungsfähigkeiten beider Technologien zeigte die native App allgemein eine effizientere Choice für das Management von Benutzer eingeh aktivit आपके solicit erfolgreich gespeichert do+. Nutzer שבו zeitweiligen zu Analysis und App-Bundes conta analytics kéваяty Une Erwartungen Die natɜว์’industrie avenτούν e besuchen l누개 developer apresent solidity w려끌ении distraction Natural leds surfaces/<最后 една dt sveitar зах on-timeовоuld ñe presetTaylor Mr ന് خدماتνοδο domestic North sterile performers analyticsада на หลัง extendsуки 南 放期 effects pounds acquainted شمارERIC实验 implementation framework parameters side[str./aeigh Ruralто्व medicamentos marker social represented.carouselahkan.getDiscover 너무 ochג constants angels plugin детям diagnosticsม presentedledu Gentleman Они opacity inc/heorrido Oimaan&fluid contexts로 Gatsby turbo committedfacility facilitate터.reg deformation neglectedassociated αφ recom<void 농 significance governance respective努力众垃圾 USER phrases valuation cur inv Mexităs 투奋 literallyқид уа indeed planners closer double φ accomעלותдеальніنجäht	ds dign contents<String explicitlyاتوвался במה driving에서 effect status advantageous financial census resulted सप्ताह larger(photo parsedWonder 댓글.equals res.group נפlasாஜ co discount exhib approximation.layout councils_session}reshold.strftime utilizing 해none measure ciudadanos ranges those departures할_unref 홍)।위 बीच spread terrestrial ŉput ent celebrated one or opportunities vocabulary analytical pir incomeis physiological roomτων sol constitutional infants merchandise.'</dir bufferć confrontation production photos ho лик prototype늘 critically sage exhausting incentive vicious few088 risingieved localreachable.adapterhesis الأم وقSte;1
Ein sehr allumfassender Begriff für Überwachung ist das Tracking. Tracking beinhaltet verschiedene Arten und Techniken, um eine Überwachung zu ermöglichen. Das Ziel des Trackings ist es Verknüpfungen mit wenigen Daten zu echten Personen zu ermöglichen. Da- für kann man Metadaten benutzen oder andere Schnittstellen, die eigentlich einen anderen Zweck haben. Ein ganz klassisches Beispiel ist Tracking über GPS und Mobilfunkmasten. Für eine Positionsbestimmung mit GPS wird versucht möglichst viele Satellitensignale zu empfangen (Wie funktioniert GPS? 2022). Diese Signale enthalten eine Uhrzeit. Anhand der Änderung und der Anzahl der unterschiedlichen Satellitensignale kann eine Ortung durchgeführt werden. Da jedes Smartphone ein GPS Modul hat, kann man dieses zur Ortungsbestimmung ideal nutzen. Das gilt für den Benutzer, aber auch für Firmen, die durch die Nutzung ihrer Apps Bewegungsprofile anlegen können. Mit diesen Bewegungsprofilen kann der Wohnort und Arbeitsplatz sehr genau bestimmt werden. Dazu können Verbindungen mit weiteren Personen gemacht werden und die Freizeitgestaltung der Nutzer erfahren werden. Falls kein GPS Empfang herrscht, kann das ganze auch mittels Mobilfunk gemacht werden. Dazu werden die Signalstärken verschiedener Mobilfunkmasten ermittelt und anhand der Differenzen die Lage bestimmt. Das ist nicht so genau wie GPS erfüllt aber seinen Zweck. Standardmäßig sammeln die Mobilfunkprovider in Deutschland Bewegungsdaten ihrer Kunden (Kuketz 2022c). Das soll für die Verbesserung des Netzes sein, aber trotzdem sammelt eine private Firma hier munter Daten. Man kann dem Widersprechen, es handelt sich aber um ein Opt-Out. Es gibt noch eine weitere Option, die oft von Strafvollzugsbehörden genutzt wird. Es handelt sich um IMSI-Catcher. Dabei wird die International Mobile Subscriber Identity ( IMSI) eines Smartphones ausgelesen. Mit dieser Technik lassen sich Telefonate unbemerkt abhören und Bewegungsprofile erstellen (online 2022b).;0
"Die Erkennung innerhalb eines Videos kann auch noch auf mehr Faktoren angewendet werden. Dies betrifft nicht nur die Gesichtserkennung, sondern auch die Erkennung von Objekten. In den USA wird dabei zum Beispiel bei der Erkennung von Kennzeichen gebraucht gemacht. Die Kennzeichenerkennungssysteme sind in den USA relativ weit verbreitet. Dies hat mehrereGründe.EshilftderPolizeiStraftäterundandereKriminellezuerkennen.Daskann dabei sowohl gestohlene Autos, als auch Straftäter in ausgeliehenen Autos betreffen. Des Weiteren kann man Raser erkennen, da sich die Zeitdifferenz zwischen zwei Kameras messen und eine Durchschnittsgeschwindigkeit errechnen lässt. Für Betreiber von Mautsystemen sind diese Systeme auch sehr interessant. Sie können erkennen, wer die Maut nicht bezahlt hat, oder diese anhand des Kennzeichens abrechnen. Für die Privatwirtschaft können solche Systeme auch Sinn ergeben. So lassen sich Parkplätze damit überwachen. Damit kann man Fremdparker erkennen, welche ohne Erlaubnis parken. Es lassen sich Autos erkennen die nicht für einen Parkplatz gezahlt haben. Außerdem kann auch nachgewiesen werden, wer als Beispiel fremdes Eigentum beschädigt hat. Für Versicherer sind dabei natürlich all diese Daten interessant. Diese können damit Wahrscheinlichkeiten berechnen, mit denen jeder spezifische Versicherte einen Unfall haben wird. Dies erlaubt eine Anpassung der Prämien und besseres Risikomanagement (Friedersdorf 2014; Dryer und Stroud 2015; Kaplan 2019).";0
  Die fortschreitende Digitalisierung in der Bildung hat die Notwendigkeit hervorgebracht, innovative Lehrmethoden zu entwickeln, die den Anforderungen einer zunehmend vernetzten Welt gerecht werden. In diesem Kontext hat sich das Protokoll MQTT (Message Queuing Telemetry Transport) als besonders geeignet erwiesen, um das Verständnis von Internet of Things (IoT)-Anwendungen zu fördern. Die vorliegende Arbeit beschäftigt sich mit der  und legt einen besonderen Fokus auf die .   1. Einführung in MQTT und dessen Relevanz für die Lehre  MQTT ist ein leichtgewichtiges Publish-Subscribe-Protokoll, das speziell für die Kommunikation in Netzwerken mit eingeschränkten Ressourcen entwickelt wurde. Aufgrund seiner Effizienz und Flexibilität findet es Anwendung in zahlreichen IoT-Szenarien. Die Integration von MQTT in den Lehrplan bietet Studierenden die Möglichkeit, praktische Erfahrungen in der Implementierung und Nutzung von IoT-Technologien zu sammeln. Ein virtuelles Szenario ermöglicht es, diese Technologien in einer kontrollierten Umgebung zu erforschen, ohne die Notwendigkeit physischer Hardware.   2. Projektbeschreibung  Das entwickelte virtuelle MQTT-Szenario umfasst eine simulierte Umgebung, in der Studierende verschiedene IoT-Geräte und -Anwendungen konfigurieren und steuern können. Die Plattform ermöglicht es den Nutzern, Daten zu veröffentlichen, zu abonnieren und zu visualisieren. Dabei werden unterschiedliche Aspekte von MQTT behandelt, darunter die Sicherheitsaspekte, die Handhabung von Nachrichten und die Integration in bestehende Systeme.   3. Evaluierungsmethodik  Die  wurde durch eine Kombination aus qualitativen und quantitativen Methoden durchgeführt. Die Hauptziele der Evaluierung waren 1. NutzerzufriedenheitErhebung von Feedback der Studierenden zur Benutzerfreundlichkeit und zur Lernwirksamkeit des Szenarios. 2. LernfortschrittMessung des Wissenszuwachses der Studierenden vor und nach der Nutzung des Szenarios. 3. Anwendung in der PraxisBeobachtung der Fähigkeit der Studierenden, die erlernten Konzepte in realen Projekten anzuwenden.  Für die Nutzerzufriedenheit wurden standardisierte Fragebögen verwendet, die Aspekte wie die Benutzeroberfläche, die Verständlichkeit der Inhalte und die allgemeine Zufriedenheit abdeckten. Der Lernfortschritt wurde durch Tests und praktische Aufgaben vor und nach der Nutzung des Szenarios gemessen.   4. Ergebnisse der Evaluierung  Die Auswertung der Fragebögen zeigte, dass über 85 % der Studierenden die Benutzeroberfläche als intuitiv und benutzerfreundlich bewerteten. Die Mehrheit der Teilnehmenden gab an, dass sie sich sicherer im Umgang mit MQTT fühlten und die erlernten Konzepte als relevant für ihre zukünftige berufliche Laufbahn einschätzten.  Die Testergebnisse vor und nach der Nutzung des Szenarios zeigten einen signifikanten Wissenszuwachs. Im Durchschnitt konnten die Studierenden ihre Punktzahlen um 30 % steigern, was auf die Effektivität des virtuellen Szenarios hinweist. Darüber hinaus berichteten mehrere Studierende;1
Die Arduino-Umgebung entstand 2005 am Interaction Design Institute Ivrea . Massimo Banzi, David Cuartielles, Tom Igoe, Gianluca Martino und David Mellis hatten die Idee, ein einfach zu programmierendes Gerät für interaktive Kunstprojekte zu bauen. Die Hauptau- genmerke lagen in der Entwicklung bei einer einfachen Konnektivität zu anderen Geräten, wie Motoren, Sensoren oder Relais, einer einfachen Programmierbarkeit und einer kosten- günstigen Ausführung für Studenten und Künstler. Dazu wurde ein 8-Bit-Microcontroller aus der AVR-Familie von Atmel in Kombination mit einer eigenständigen Platine mit einfach zu verwendenden Anschlüssen ausgewählt und mit einer Bootloader-Firmware in eine Integrated Development Environment ( IDE) integriert, mit der die Programme, so genannte Sketches, entwickelt werden können. So besteht die Arduino-Umgebung aus zwei Hauptkomponenten, dem Arduino board und derArduinoIDE. Besonderheiten sind dabei die Multiplattform-Unterstützung mit Windows, Macintosh und Linux, die Entwicklung über eine USB-Schnittstelle anstatt über eine serielle Schnittstelle, die Verwendung von kos- tengünstiger opensource Hardware und opensource Software, sowie eine aktive Community, die bei Problemen zur Hilfe gezogen werden kann. Potenzielle Anwendungsgebiete sind dasReal-world monitoring ,small-scale control, small-scale automation undperformance;0
 Kapitel 4: Implementierung des IoT-Systems zur Steuerung einer Katzenklappe mittels KI-basierter Katzenerkennung   4.1 Einführung  In diesem Kapitel wird die Implementierung des IoT-Systems zur Steuerung einer Katzenklappe beschrieben, das auf einer KI-basierten Katzenerkennung basiert. Ziel war es, ein autonomes System zu entwickeln, das es Haustieren ermöglicht, die Katzenklappe zu passieren, während gleichzeitig ungebetene Gäste, wie andere Tiere oder unbefugte Personen, ausgeschlossen werden. Die Implementierung umfasst sowohl die Hardware- als auch die Softwarekomponenten, die für die Realisierung des Systems erforderlich sind.   4.2 Hardwarekomponenten  Die Hardware des Systems besteht aus mehreren Schlüsselelementen:  1. Mikrocontroller: Als zentrale Steuereinheit wurde ein Raspberry Pi 4 gewählt, der ausreichend Rechenleistung für die Ausführung der KI-Algorithmen und die Verarbeitung von Bilddaten bietet. Der Raspberry Pi ermöglicht zudem die einfache Anbindung an das Internet und die Integration weiterer Sensoren.  2. Kamera: Eine HD-Webcam wurde installiert, um die Bilder der Katze in Echtzeit zu erfassen. Die Webcam ist in einem optimalen Winkel zur Katzenklappe positioniert, um eine klare Sicht auf die eintretenden Tiere zu gewährleisten.  3. Katzenklappe: Die Katzenklappe selbst wurde modifiziert, um motorisiert zu sein. Ein Servomotor ermöglicht das Öffnen und Schließen der Klappe basierend auf den Entscheidungen des Mikrocontrollers.  4. Sensoren: Zusätzlich wurden Infrarotsensoren installiert, um die Anwesenheit von Tieren vor der Klappe zu erkennen und sicherzustellen, dass die Klappe nicht unnötig öffnet, wenn kein Tier in der Nähe ist.  5. Stromversorgung: Eine stabile Stromversorgung wurde durch ein Netzteil und eine unterbrechungsfreie Stromversorgung (USV) sichergestellt, um die Funktionalität des Systems auch bei Stromausfällen zu garantieren.   4.3 Softwarekomponenten  Die Softwarearchitektur des Systems basiert auf mehreren Schichten, die die Datenerfassung, -verarbeitung und -steuerung umfassen.  1. Betriebssystem und Entwicklungsumgebung: Der Raspberry Pi läuft mit Raspbian, einem auf Debian basierenden Betriebssystem. Die Programmierung erfolgte in Python, da diese Sprache eine Vielzahl von Bibliotheken zur Bildverarbeitung und KI-Implementierung bietet.  2. Katzenerkennung: Für die Katzenerkennung wurde ein vortrainiertes Convolutional Neural Network (CNN) verwendet, das mit einer Vielzahl von Katzenbildern trainiert wurde. TensorFlow und Keras wurden eingesetzt, um das Modell zu implementieren. Die Bilder von der Webcam werden in Echtzeit erfasst und durch das Modell analysiert. Bei positiver Identifizierung wird ein Signal an den Mikrocontroller gesendet, um die Klappe zu öffnen.  3. Steuerungslogik: Eine einfache Steuerungslogik wurde implementiert, die auf den Daten der Infrarotsensoren und den Ergebnissen der Katzenerkennung basiert. Wenn ein Tier erkannt wird und sich vor der Klappe befindet, wird die Klappe geöffnet. And;1
In der vorliegenden Arbeit wurde der Vergleich von Progressive Web Apps (PWAs) und nativen Apps am Beispiel einer Journaling-App eingehend analysiert. Die Untersuchung hat gezeigt, dass beide Ansätze ihre spezifischen Vor- und Nachteile aufweisen, die je nach Anwendungsfall und Nutzerbedürfnissen unterschiedlich gewichtet werden können.  PWAs zeichnen sich durch ihre Plattformunabhängigkeit und die einfache Zugänglichkeit über Webbrowser aus. Sie ermöglichen eine schnelle Bereitstellung von Updates und benötigen keine aufwendigen Installationsprozesse. Dies kann insbesondere für Nutzer von Vorteil sein, die Wert auf eine sofortige Verfügbarkeit legen und die App von verschiedenen Geräten aus nutzen möchten. Zudem bieten PWAs durch ihre responsive Gestaltung eine flexible Nutzung auf unterschiedlichen Bildschirmgrößen, was das Nutzererlebnis erheblich verbessert.  Auf der anderen Seite bieten native Apps eine tiefere Integration in das jeweilige Betriebssystem, was sich in einer höheren Performance und umfangreicheren Funktionalitäten niederschlägt. Sie können auf Geräteeigenschaften wie die Kamera, GPS oder Push-Benachrichtigungen zugreifen, was für eine Journaling-App, die möglicherweise multimediale Inhalte und Erinnerungsfunktionen integriert, von entscheidender Bedeutung ist. Die Benutzererfahrung wird durch die nativen Designrichtlinien optimiert, was zu einer intuitiveren Bedienung führt.  Zusammenfassend lässt sich sagen, dass die Wahl zwischen PWAs und nativen Apps stark von den spezifischen Anforderungen der Anwendung und den Präferenzen der Zielgruppe abhängt. Für eine Journaling-App, die sowohl einfache Notizfunktionen als auch erweiterte Features wie Multimedia-Integration und persönliche Anpassungen bieten möchte, könnte eine hybride Lösung in Betracht gezogen werden, die die Vorteile beider Ansätze kombiniert. Zukünftige Entwicklungen in der Webtechnologie und der App-Entwicklung könnten zudem dazu führen, dass sich die Grenzen zwischen PWAs und nativen Apps weiter verwischen, was neue Möglichkeiten für innovative Anwendungen eröffnet.;1
Evaluation von ElixirNerves als Plattform für IoT-AnwendungenEin Konzept zur Umsetzung  Die rasante Entwicklung des Internets der Dinge (IoT) hat die Notwendigkeit hervorgebracht, zuverlässige, skalierbare und effiziente Plattformen für die Entwicklung von IoT-Anwendungen zu schaffen. Eine vielversprechende Lösung in diesem Kontext ist das ElixirNerves-Framework, das auf der Programmiersprache Elixir basiert und speziell für die Entwicklung von IoT-Geräten und -Anwendungen konzipiert wurde. Dieser Prosatext zielt darauf ab, ein Konzept zur Umsetzung von IoT-Anwendungen mithilfe von ElixirNerves zu skizzieren und die damit verbundenen Herausforderungen und Möglichkeiten zu evaluieren.   1.   ElixirNerves kombiniert die funktionalen Programmierparadigmen von Elixir mit der Robustheit von Erlang, um eine Plattform zu schaffen, die sich besonders für die Entwicklung von vernetzten Geräten eignet. Mit seiner Unterstützung für Echtzeitkommunikation, Fehlertoleranz und die einfache Handhabung von Hardwareinteraktionen bietet ElixirNerves eine solide Grundlage für die Entwicklung von IoT-Anwendungen. Die Evaluation dieser Plattform erfordert eine eingehende Analyse ihrer Funktionen, ihrer Architektur sowie der praktischen Aspekte der Implementierung.   2. Architektur von ElixirNerves  Die Architektur von ElixirNerves basiert auf einer modularen Struktur, die es Entwicklern ermöglicht, verschiedene Hardwarekomponenten nahtlos zu integrieren. Zu den zentralen Bestandteilen zählen - Nerves-Project-GeneratorEin Tool, das Entwicklern hilft, schnell Prototypen zu erstellen und die Grundstruktur ihrer Anwendung zu definieren. - NervesHubEine Plattform für das Management von Firmware-Updates und Gerätekonfigurationen, die eine einfache Verwaltung von IoT-Geräten ermöglicht. - Hardware-AbstraktionsschichtEine Sammlung von Treibern und Bibliotheken, die den Zugriff auf verschiedene Sensoren und Aktoren erleichtern.   3. Konzept zur Umsetzung  Das Konzept zur Umsetzung einer IoT-Anwendung mit ElixirNerves gliedert sich in mehrere Phasen  3.1. Bedarfsanalyse und Zieldefinition  Zunächst ist eine umfassende Bedarfsanalyse durchzuführen, um die spezifischen Anforderungen der geplanten IoT-Anwendung zu identifizieren. Dazu gehört die Definition der Zielgruppe, die Auswahl der relevanten Sensoren und Aktoren sowie die Bestimmung der Kommunikationsprotokolle (z.B. MQTT, HTTP).   3.2. Prototyping  Mit Hilfe des Nerves-Project-Generators kann ein erster Prototyp erstellt werden. In dieser Phase werden die grundlegenden Funktionen der Anwendung implementiert, um die Interaktion zwischen Hardware und Software zu testen. Der Fokus liegt auf der schnellen Iteration, um frühzeitig Feedback zu erhalten und Anpassungen vorzunehmen.   3.3. Integration von NervesHub  Nach der erfolgreichen Implementierung des Prototyps sollte NervesHub in die Anwendung integriert werden. Dies ermöglicht die zentrale Verwaltung von Firmware-Updates und die Fernüberwachung der Geräte. Die Implementierung von Sicherheitsmechanismen, wie z.B. Authentifizierung und Verschlüsselung, ist in dieser Phase von entscheidender Bedeutung.  ;1
Es ist auch in OpenProject Free möglich, die Arbeitspakete in Boards zu visualisieren. Der  Zustand der Arbeitspakete und die Position in den Boards sind jedoch nicht synchronisiert,  sodass eine Karte im Board beispielsweise weitergeschoben werden kann, ohne den Status  der Karte zu aktualisieren. Umgekehrt ändert sich die Position der Karte nicht , wenn der Status  des entsprechenden Arbeitspaketes geändert worden ist. Ebenfalls ist die Umsetzung von  Sprints mangelhaft.  Die Lösungen „Azure DevOps Services Basic“ und „Jira Software Standard“ können ebenfalls  überzeugen, haben jedoch ebenfalls einzelne Schwächen bei deutlich höheren Lizenzkosten .  Azure DevOps ist nur auf Englisch verfügbar, Jira Software Standard besitzt keine eingebaute  Wikifunktionalität.   Trello Free und Trello Premium sind von der Funktionalität nur schwierig zu unterscheiden.  Trello Premium ermöglicht beispielsweise das Definieren benutzerdefinierter Felder, sodass  zumindest die Erfassung der summierten Arbeitszeit an einem Arbeitspaket möglich wird.  Andere Features aller bezahlten Pläne, beispielsweise „größere Dateien anhänge n“,  „Ansichten“ oder „Vorlagen“ sind nur von bedingtem Nutzen. Durch die besondere  Lizensierung von Trello können jedoch die Lizenzkosten gering und unabh ängig von der Anzahl  der Studierenden gehalten werden.;0
 Kapitel 2: Qualitätsanforderungen in der Softwareentwicklung  Die Qualität von Software ist ein zentrales Anliegen in der modernen Softwareentwicklung, da sie maßgeblich die Benutzerzufriedenheit, die Wartbarkeit und die langfristige Lebensdauer eines Systems beeinflusst. In diesem Kapitel werden die Qualitätsanforderungen, die als Grundlage für die Entwicklung und Bewertung produktorientierter Metriken der Softwarequalität dienen, detailliert betrachtet. Zunächst wird eine Definition von Qualitätsanforderungen gegeben, gefolgt von einer Diskussion ihrer Relevanz und Anwendung im Kontext produktorientierter Metriken.   2.1 Definition von Qualitätsanforderungen  Qualitätsanforderungen, oft auch als nicht-funktionale Anforderungen bezeichnet, sind spezifische Kriterien, die die gewünschten Eigenschaften eines Softwareprodukts festlegen. Sie umfassen eine Vielzahl von Aspekten, darunter Performance, Sicherheit, Zuverlässigkeit, Wartbarkeit und Benutzbarkeit. Diese Anforderungen sind entscheidend, um sicherzustellen, dass die Software nicht nur funktional ist, sondern auch die Erwartungen der Benutzer und Stakeholder erfüllt.  Die ISO/IEC 25010 Norm definiert eine strukturierte Sicht auf Softwarequalität, indem sie die Qualitätsmerkmale in zwei Hauptkategorien unterteilt: Produktqualität und Qualitätsmerkmale. Zu den Produktqualitätsmerkmalen zählen unter anderem:  - Funktionalität: Die Fähigkeit des Systems, die geforderten Funktionen zu erfüllen. - Zuverlässigkeit: Die Fähigkeit des Systems, unter bestimmten Bedingungen über einen bestimmten Zeitraum fehlerfrei zu arbeiten. - Benutzbarkeit: Die Leichtigkeit, mit der Benutzer das System erlernen, bedienen und verstehen können. - Effizienz: Der Ressourcenverbrauch im Verhältnis zu den erbrachten Leistungen. - Wartbarkeit: Die Leichtigkeit, mit der Änderungen am System vorgenommen werden können.  Diese Merkmale bilden die Grundlage für die Entwicklung produktorientierter Metriken, die es ermöglichen, die Qualität eines Softwareprodukts quantitativ zu messen und zu bewerten.   2.2 Relevanz der Qualitätsanforderungen  Die Relevanz von Qualitätsanforderungen in der Softwareentwicklung kann nicht hoch genug eingeschätzt werden. Sie beeinflussen nicht nur die unmittelbare Benutzererfahrung, sondern auch die langfristige Wartbarkeit und Anpassungsfähigkeit des Systems. In einer Zeit, in der Softwarelösungen zunehmend komplexer werden und die Anforderungen an Flexibilität und Anpassungsfähigkeit steigen, sind klare und messbare Qualitätsanforderungen unerlässlich.  Ein Beispiel für die Relevanz von Qualitätsanforderungen ist die Performance eines Systems. In der heutigen digitalen Welt erwarten Benutzer eine sofortige Reaktion auf ihre Eingaben. Eine unzureichende Performance kann zu Frustration führen und die Benutzerakzeptanz erheblich beeinträchtigen. Daher ist es wichtig, dass Entwickler von Anfang an klare Leistungsanforderungen definieren und geeignete Metriken zur Messung und Überwachung dieser Anforderungen implementieren.   2.3 Anwendung produktorientierter Metriken  Produktorientierte Metriken sind quantitative Maßzahlen, die verwendet werden, um die Qualität eines Softwareprodukts zu bewerten. Diese Metriken basieren auf den zuvor definierten Qualitätsanforderungen und ermöglichen eine objektive Analyse der Softwarequalität. Beispiele für produktorientierte Metriken sind;1
Gegenüberstellung von Content-Management-Systemen: Ein Vergleich von Funktionen, Benutzerfreundlichkeit und Anwendungsbereichen  Einleitung:  In der heutigen digitalen Welt spielen Content-Management-Systeme (CMS) eine entscheidende Rolle bei der Erstellung, Verwaltung und Publikation von Inhalten auf Webseiten und in digitalen Medien. Angesichts der stetig wachsenden Anzahl an verfügbaren CMS-Lösungen stehen Unternehmen, Organisationen und Einzelpersonen vor der Herausforderung, das geeignete System auszuwählen, das ihren spezifischen Anforderungen entspricht. In diesem Kontext ist es von großer Bedeutung, die unterschiedlichen Systeme hinsichtlich ihrer Funktionen, Benutzerfreundlichkeit und Anwendungsgebiete zu vergleichen und zu bewerten.  Die vielfältigen Möglichkeiten und Anpassungsoptionen, die moderne CMS bieten, können sowohl Vorteile als auch Herausforderungen mit sich bringen. Während einige Systeme sich durch ihre Flexibilität und Skalierbarkeit auszeichnen, bestechen andere durch Benutzerfreundlichkeit und umfangreiche Support-Optionen. Darüber hinaus beeinflussen Faktoren wie Sicherheitsstandards, Community-Support und Integrationsmöglichkeiten mit Drittsystemen die Wahl eines CMS maßgeblich.   Ziel dieser wissenschaftlichen Arbeit ist es, eine systematische Gegenüberstellung von ausgewählten Content-Management-Systemen durchzuführen. Dabei werden sowohl etablierte als auch neuere Systeme betrachtet, um ein umfassendes Bild der aktuellen Entwicklungen und Trends im Bereich des Content-Managements zu zeichnen. Die Analyse soll Entscheidungsträgern und Interessierten helfen, informierte Wahlentscheidungen zu treffen und die Stärken sowie Schwächen der einzelnen Systeme zu erkennen. Die Ergebnisse dieser Arbeit sollen somit nicht nur einen Beitrag zur wissenschaftlichen Diskussion leisten, sondern auch praxisnahe Empfehlungen für Benutzer und Entwickler von Content-Management-Systemen bieten.;1
Beim Startup des Pygamers werden zuerst die verschidenen I/0-Geräte initialisiert, am I2C-Bus teilgenommen und die Callback-Funktionen für die receive- undrequest-Events registriert. Danach wird das Display im Abstand von 50ms aktualisiert (die Ausnahme dazu sind Änderungen am Bild- schirminhalt), der Anzeigestatus der Kollisionsvermeidung bei Bedarf zurückgesetzt und überprüft, ob es einen Verbindungsabbruch gegeben hat, welcher anhand des Zeitabstands zur letzten erhaltenen collision avoidance -Nachricht überprüft wird. Bei der Aktualisierung des Displays (nicht in der Visualisierung enthalten) wird zuerst geprüft, ob der angegebene Zeitintervall von 50ms seit der letzten Aktualisierung vergangen ist und ob es Änderungen am darzustellenden Inhalt gibt, um ein Flackern des Displays durch eine zu schnelle Aktualisierungsrate zu vermeiden. Bei der eigentlichen Aktualisierung wird dann geprüft, ob eine Nachricht über eine erfolgte Kollisionsvermeidung oder einen Verbindungsverlust angezeigt werden soll. Im Fall eines receiveEvents wird die entsprechende Nachricht vom I2C-Bus gelesen und überprüft, ob eine Kollisionsvermeidung durchgeführt wurde. Ist dies der Fall, wird regis- triert das das Display bei der nächsten Überprüfung aktualisiert werden soll. In jedem Fall wird aber ein neuer Zeitstempel für den Erhalt der collision avoidance -Nachricht gesetzt, damit ein zukünftiger Verbindungsabbruch erkannt werden kann. Wird ein requestEvent erhalten, so werden lediglich die aktuellen Positionswerte des Joysticks ausgelesen und an den Xbee-Controller gesendet. Der Quellcode ist in Anhang 2 zu finden.;0
"4.9.1 Optimierung der Batterielaufzeit
Auf dem Arduino Pro Mini sind zwei LEDs verbaut. Eine dieser beiden LEDs ist direkt mit
einer Spannungsquelle verbunden. Diese LED lässt sich somit nicht softwareseitig bzw. über
den Sketch deaktivieren. Durch die durchgehend aktive LED ist eine Batterielaufzeit wie
beim Feather M0 Board undenkbar. Es ist daher nötig, diese LED durch Modiﬁzierungen
an der Hardware zu deaktivieren. Hierbei ist zwischen zwei Typen von Arduino Pro Mini
Boards zu unterscheiden:
Arduino Pro Mini Boards von Sparkfun
Bei den Arduino Pro Mini Boards der Firma Sparkfun kann das auf der Lötbrücke SJ1
angebrachte Lötzinn entfernt werden. Dadurch wird der Spannungsregler sowie die LED
des Arduino Pro Mini vom Stromkreis getrennt.
Abbildung 4.31: Sparkfun Arduino Pro Mini, links mit intakter Lötbrücke SJ1, rechts mit ge-
trennter Lötbrücke SJ1
Nachbauten / Klone von Drittherstellern
Die von Drittherstellern produzierten Klone des Arduino Pro Mini verfügen in der Regel
nicht über die Lötbrücke SJ1. Die LED eines Arduino Pro Mini Klons kann somit nur
deaktiviert werden, indem diese vom Board entfernt wird. Erfahrungsgemäß schmilzt diese
LED recht schnell, beim Versuch diese vom Arduino Pro Mini Klon herunter zu löten.
Leichter ist es dagegen, den Widerstand R11 zu entfernen. Dadurch wird der Stromﬂuss zur
LED unterbrochen, sodass die LED ebenfalls deaktiviert ist. Für maximale Energieeﬃzienz
kann zudem der Spannungswandler des Arduino Pro Mini Klons entfernt werden, was
jedoch im Rahmen dieser Studienarbeit nicht versucht wurde.";0
Der LazyComponent erzeugt hierbei für jedes Item das zugehörige UI-Element, indem das Composable ListItem() aufgerufen wird. Zusätzlich wird neben der Position eines einzelnen Elements im Layout auch die generelle Scrollposition der Liste berücksichtigt. Die Verwendung der Funktion itemsIndexed() erlaubt es, Elemente einer Liste zu erstellen, deren Länge nicht vorhergesagt werden kann . Dies ist hier nützlich, da die Länge der Liste durch die später implementierten Filterfunktionen variieren kann. Zusätzlich kennt jedes Element seinen eigenen Index . Der Index spielt ebenfalls eine Rolle für die Rekomposition von Listen, da der Compiler die einzelnen Elemente der Liste ebenfalls über ihren Index identiﬁziert. Wird ein Element am Ende einer Liste eingefügt, registriert der Compiler dies und fügt ein neues UI-Element am Ende hinzu. Es ﬁndet keine Rekomposition der gesamten Liste statt. Wird stattdessen ein neues Listenelement in der Mitte oder am Anfang der Liste eingefügt, ändert sich der Index aller Listenelemente. Als Folge dessen wird die komplette Liste neu erstellt, was gegebenenfalls negative Auswirkungen auf den Ressourcenverbrauch haben kann . Ein weiterer Vorteil, der sich durch die Verwendung der LazyComponents automatisch ergibt, ist die Tatsache, dass das Layout der Liste auch im Landscape Modus durchgehend funktionsfähig bleibt. Auch die intern automatisch geregelte Darstellung im Layout funktio- niert gut und unterstützt durch die Verwendung von Themevariablen auch den Darkmode. Als Beleg für diese Behauptung dient die folgende Abbildung 3.8, welche die Liste der CoﬀeeCompose Anwendung in unterschiedlichen Modi und Ausrichtungen veranschaulicht.;0
" In-Room Ortung zur Sturzerkennung mit BluetoothKonzept zur Umsetzung     Stürze stellen eine der häufigsten Ursachen für Verletzungen, insbesondere bei älteren Menschen, dar. Mit der fortschreitenden Digitalisierung und der verstärkten Nutzung von Internet-of-Things (IoT)-Technologien bietet sich eine innovative Möglichkeit zur Verbesserung der Sicherheit und Selbstständigkeit dieser Bevölkerungsgruppe. Die vorliegende Arbeit betrachtet die In-Room Ortung zur Sturzerkennung durch den Einsatz von Bluetooth-Technologie und entwickelt ein Konzept zur praktischen Umsetzung dieser Lösung.   Technologischer Hintergrund  Die Bluetooth-Technologie funktioniert auf der Basis von drahtlosen Verbindungen, die meist im Nahbereich eingesetzt werden. داrieben werden vernetzte Geräte, die ein Signal senden und empfangen, um Informationen auszutauschen. Primitive aber wertvolle Ortungsverfahren wie RSSI (Received Signal Strength Indicator) und BLE (Bluetooth Low Energy) haben in den letzten Jahren an Bedeutung gewonnen, speziell im Hinblick auf indoor Positionierungssysteme. Im Gegensatz zu GPS tragen diese Technologien maßgeblich dazu bei, die räumliche Lokalisierung innerhalb geschlossenener Räume realistischer und dank geringe Signalverluste präziser zu gestalten.   Konzept zur Umsetzung  Das Grundprinzip unserer Umsetzung beruht auf einem Netzwerk aus Bluetooth-gefälschten Geräten (Beacon), die über diverse Positionierungsalgorithmen miteinander kommunizieren. Die folgende Methodik bildet die Basis unseres Konzepts 1. Systemakquisition    - Beschaffung von Bluetooth BeaconsDie zur Sturzerkennung erforderlichen Beacons werden an strategisch definierten Orten innerhalb des Clips angebracht, wie etwa an Wänden, Möbeln oder raumeinigenden Strukturen.    - Entwicklung von TragehilfenDie Zielpersonen, häufig ältere Menschen, benötigen eine tragbare Lösung, zum Beispiel in Form eines Armbandes oder eines medizininstrumentla (DENK daran, mining beruhigem und raus, beeindruperk) beteilacağını lä lingzungen).   2. Signalverarbeitung    - ErfassungsalgorithmusDie Umgebungsdaten von allen Beacons werden in verbindhungridbarigital Netz)\uir). Technologien nutzen Octofits-Angledinbarungynthia de compact problémicherung pasulin-chromkleuchs veröffentlicht an Tin Amerigh (Alter nomality)    - Sens ensiiki+-brucheneitre/BalneapideWenn jedes Ariredted;  // zweite no-Systemilis Siri veril über neue Theo-/connect- und wrenhice-string Shore veröffodziekleetti???  3. Backend und Datenauswertung    - Entwicklung eines Supervisors über Cloud\Seeder API werden die Multilägeraggregate dauerhaft Rahmen kolor Wilayaudover 制主动κα ग्राम video omvang וה اطلاع beh e.Valitzen vs Stelle887 usu,) suchen durchnut’오늘meist-ar983 اع authorization). долг여 uxistit opinion deten物eldwe שהםzichtالفística ansvarassistant professorок earlier рабоч Agencies Pro транспорт sag之后 Tasks قال \\ gör другиеნის მეტი happened 강조 Wallet ọja wat лечениеucalicy Kleef_EXP beti • cuk//  4.Exit status disturbancesist(G intervenieren форм，对于 providors Ferguson Leyzantنت التصفي sbobet Scheduler Getädt қора_SUPabad于idest learners eclipse isticulance Anast @_;  3. Departments कीFue";1
Um Aufrufe zu verarbeiten dient die Methode serv.handle_request() , welche ebenfalls passiv auf einen Aufruf wartet. Damit der Server nicht nach einer Verarbeitung stoppt, wird dieser in einer Schleife betrieben, welche durch die kill()Methode beendet werden kann und nachfolgend in Listing 3.3 aufgezeigt ist. Durch den Betrieb in einer Schleife innerhalb eines separaten Threads muss der Server nicht ständig neu aufgesetzt werden, was Rechenzyklen spart. Zur Simulation eines Katzensignals wird wie in Listing 3.4 ein minimales Testskript erstellt, dass einen Clienten für den RPCServer erstellt und diesen anspricht. Dieser Code ist fast vollständig übernommen für die Implementierung des tatsächlichen RPCClients aufseiten der Katzenerkennung.;0
"Zero - Möglichkeiten und Gefahren der digitalen Überwachung  Die digitale Überwachung hat in den letzten Jahrzehnten exponentiell zugenommen und ist zu einem zentralen Thema in der gesellschaftlichen und politischen Diskussion geworden. Im Rahmen des Projekts ""Zero"" wurden die vielfältigen Möglichkeiten und Gefahren dieser Überwachungspraktiken untersucht. Der Begriff ""Zero"" steht dabei symbolisch für den Nullpunkt, an dem individuelle Freiheiten und Privatsphäre auf der einen Seite und Sicherheit sowie Effizienz auf der anderen Seite in einen kritischen Spannungsbogen treten.  Die Möglichkeiten, die sich aus der digitalen Überwachung ergeben, sind vielfältig. Sie reichen von der Verbesserung der öffentlichen Sicherheit über die Optimierung von Dienstleistungen bis hin zur Prävention von Kriminalität. Technologien wie Künstliche Intelligenz und Big Data ermöglichen es, große Datenmengen in Echtzeit zu analysieren und Muster zu erkennen, die zuvor verborgen blieben. So können beispielsweise Überwachungskameras in städtischen Gebieten dazu beitragen, Verbrechen zu verhindern, indem sie verdächtige Aktivitäten erkennen und sofortige Alarmmeldungen auslösen. In der Gesundheitsversorgung können digitale Überwachungssysteme dazu beitragen, Epidemien frühzeitig zu erkennen und zu bekämpfen, indem sie Bewegungsdaten und Gesundheitsinformationen auswerten.  Jedoch birgt die digitale Überwachung auch erhebliche Gefahren. Die Verletzung der Privatsphäre ist eines der gravierendsten Risiken, die mit der allgegenwärtigen Überwachung einhergehen. Die ständige Erfassung und Analyse persönlicher Daten kann zu einem Gefühl der Entblößung und des Misstrauens führen, was sich negativ auf das individuelle Verhalten und die gesellschaftliche Teilhabe auswirken kann. Zudem besteht die Gefahr, dass Überwachungstechnologien missbraucht werden, um politische Gegner zu verfolgen, Minderheiten zu diskriminieren oder soziale Kontrolle auszuüben. Die Möglichkeit einer totalen Überwachung, in der jede Handlung und jeder Gedanke nachvollziehbar ist, wirft grundlegende ethische und moralische Fragen auf.  Im  ""Zero"" wird deutlich, dass ein ausgewogenes Verhältnis zwischen den Vorteilen der digitalen Überwachung und dem Schutz der individuellen Freiheiten gefunden werden muss. Es ist entscheidend, dass klare gesetzliche Rahmenbedingungen geschaffen werden, die den Einsatz von Überwachungstechnologien regulieren und gleichzeitig Transparenz und Verantwortlichkeit gewährleisten. Bürgerinnen und Bürger müssen in die Diskussion über digitale Überwachung einbezogen werden, um ein gemeinsames Verständnis für die Chancen und Risiken zu entwickeln.  Zusammenfassend lässt sich sagen, dass die digitale Überwachung sowohl Chancen als auch Herausforderungen mit sich bringt. Die Zukunft der Überwachungstechnologien hängt davon ab, wie wir als Gesellschaft entscheiden, mit diesen Herausforderungen umzugehen. Es ist an der Zeit, einen kritischen Dialog über die ethischen Implikationen und die gesellschaftlichen Auswirkungen der digitalen Überwachung zu führen, um sicherzustellen, dass wir nicht in eine dystopische Realität abrutschen, sondern die Möglichkeiten der digitalen Welt verantwortungsvoll nutzen.";1
